<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R | msperlin</title>
    <link>https://www.msperlin.com/category/r/</link>
      <atom:link href="https://www.msperlin.com/category/r/index.xml" rel="self" type="application/rss+xml" />
    <description>R</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Marcelo S. Perlin © 2023</copyright><lastBuildDate>Thu, 09 Mar 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://www.msperlin.com/img/portrait.jpg</url>
      <title>R</title>
      <link>https://www.msperlin.com/category/r/</link>
    </image>
    
    <item>
      <title>Compiling book exercises</title>
      <link>https://www.msperlin.com/post/2023-03-09-compiling-exercises-afedr3/</link>
      <pubDate>Thu, 09 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2023-03-09-compiling-exercises-afedr3/</guid>
      <description>


&lt;p&gt;The third edition of &lt;a href=&#34;https://www.amazon.com/dp/B084LSNXMN&#34;&gt;Analyzing Financial and Economic Data with R&lt;/a&gt; provides a total of 98 end-of-chapter exercises. All activities are freely available in the &lt;a href=&#34;http://www.r-exams.org/&#34;&gt;&lt;code&gt;exams&lt;/code&gt; format&lt;/a&gt;, meaning that any R tutor can export the same exercises and solutions to use in their own class. In this post I’ll show how to compile exercises to pdf, html, &lt;em&gt;Moodle&lt;/em&gt; and &lt;em&gt;blackboard&lt;/em&gt;.&lt;/p&gt;
&lt;div id=&#34;installation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Installation&lt;/h1&gt;
&lt;p&gt;The first step is to install package &lt;code&gt;afedR3&lt;/code&gt; with &lt;code&gt;devtools&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if (!require(devtools)) install.packages(&amp;#39;devtools&amp;#39;)

devtools::install_github(&amp;#39;msperlin/afedR3&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another requirement is a working Latex instalation. For that, use &lt;code&gt;tinytex&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tinytex::install_tinytex()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;compiling-exercises&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Compiling Exercises&lt;/h1&gt;
&lt;div id=&#34;how-it-works&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How it works?&lt;/h2&gt;
&lt;p&gt;All book exercises are written in the &lt;code&gt;exams&lt;/code&gt; format: each exercise is a .Rmd file containing code, exercise text and solution. The files themselves can be found in the installation directory of the book package, and each folder contains the exercise for a particular chapter:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;eoc_dir &amp;lt;- afedR3::get_EOC_dir()

eoc_chapters &amp;lt;- fs::dir_ls(eoc_dir)
basename(eoc_chapters)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;CH01-intro&amp;quot;        &amp;quot;CH02-basic&amp;quot;        &amp;quot;CH03-research&amp;quot;    
##  [4] &amp;quot;CH04-imp-local&amp;quot;    &amp;quot;CH05-imp-internet&amp;quot; &amp;quot;CH06-df&amp;quot;          
##  [7] &amp;quot;CH07-basic&amp;quot;        &amp;quot;CH08-programming&amp;quot;  &amp;quot;CH09-cleaning&amp;quot;    
## [10] &amp;quot;CH10-figures&amp;quot;      &amp;quot;CH11-fin-econ&amp;quot;     &amp;quot;CH12-reporting&amp;quot;   
## [13] &amp;quot;CH13-optimizing&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s have a deeper look at the exercises of the first chapter:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;eoc_files &amp;lt;- fs::dir_ls(eoc_chapters[1])
basename(eoc_files)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;afedR_Chap-01_01_SPLUS.Rmd&amp;quot;            
##  [2] &amp;quot;afedR_Chap-01_02_Authors-R.Rmd&amp;quot;        
##  [3] &amp;quot;afedR_Chap-01_03_About-R.Rmd&amp;quot;          
##  [4] &amp;quot;afedR_Chap-01_04_name-R.Rmd&amp;quot;           
##  [5] &amp;quot;afedR_Chap-01_05_about-R.Rmd&amp;quot;          
##  [6] &amp;quot;afedR_Chap-01_06_Tecnology-R.Rmd&amp;quot;      
##  [7] &amp;quot;afedR_Chap-01_07_rtools.Rmd&amp;quot;           
##  [8] &amp;quot;afedR_Chap-01_08_Groups.Rmd&amp;quot;           
##  [9] &amp;quot;afedR_Chap-01_09_RBloggers.Rmd&amp;quot;        
## [10] &amp;quot;afedR_Chap-01_10_Infrastructure-TI.Rmd&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also read one of the files to show the structure of the exercise in code and text:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;readLines(eoc_files[1])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;```{r datageneration, echo = FALSE, results = \&amp;quot;hide\&amp;quot;}&amp;quot;                                                                                                                                
##  [2] &amp;quot;my_answers &amp;lt;- c(&amp;#39;S&amp;#39;, &amp;quot;                                                                                                                                                                  
##  [3] &amp;quot;                &amp;#39;C++&amp;#39;,&amp;quot;                                                                                                                                                                 
##  [4] &amp;quot;                &amp;#39;Python&amp;#39;,&amp;quot;                                                                                                                                                              
##  [5] &amp;quot;                &amp;#39;Julia&amp;#39;,&amp;quot;                                                                                                                                                               
##  [6] &amp;quot;                &amp;#39;Javascript&amp;#39;)&amp;quot;                                                                                                                                                          
##  [7] &amp;quot;&amp;quot;                                                                                                                                                                                       
##  [8] &amp;quot;#check_answers(my_answers)&amp;quot;                                                                                                                                                             
##  [9] &amp;quot;```&amp;quot;                                                                                                                                                                                    
## [10] &amp;quot;&amp;quot;                                                                                                                                                                                       
## [11] &amp;quot;Question&amp;quot;                                                                                                                                                                               
## [12] &amp;quot;========&amp;quot;                                                                                                                                                                               
## [13] &amp;quot;&amp;quot;                                                                                                                                                                                       
## [14] &amp;quot;The R language was developed based on what other programming language?&amp;quot;                                                                                                                 
## [15] &amp;quot;&amp;quot;                                                                                                                                                                                       
## [16] &amp;quot;```{r questionlist, echo = FALSE, results = \&amp;quot;asis\&amp;quot;}&amp;quot;                                                                                                                                  
## [17] &amp;quot;exams::answerlist(my_answers, markup = \&amp;quot;markdown\&amp;quot;)&amp;quot;                                                                                                                                   
## [18] &amp;quot;```&amp;quot;                                                                                                                                                                                    
## [19] &amp;quot;&amp;quot;                                                                                                                                                                                       
## [20] &amp;quot;Solution&amp;quot;                                                                                                                                                                               
## [21] &amp;quot;================&amp;quot;                                                                                                                                                                       
## [22] &amp;quot;&amp;quot;                                                                                                                                                                                       
## [23] &amp;quot;Straight from the book, section **What is R**: \&amp;quot;R is a modern version of S, a programming language originally created in Bell Laboratories (formerly AT&amp;amp;T, now Lucent Technologies).\&amp;quot;&amp;quot;
## [24] &amp;quot;&amp;quot;                                                                                                                                                                                       
## [25] &amp;quot;Meta-information&amp;quot;                                                                                                                                                                       
## [26] &amp;quot;================&amp;quot;                                                                                                                                                                       
## [27] &amp;quot;extype: schoice&amp;quot;                                                                                                                                                                        
## [28] &amp;quot;exsolution: `r mchoice2string(c(TRUE, FALSE, FALSE, FALSE, FALSE), single = TRUE)`&amp;quot;                                                                                                     
## [29] &amp;quot;exname: \&amp;quot;S PLUS\&amp;quot;&amp;quot;                                                                                                                                                                     
## [30] &amp;quot;exshuffle: TRUE&amp;quot;                                                                                                                                                                        
## [31] &amp;quot;&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In a nutshell, we define all sections of a question – text, solution, alternatives – using a .Rmd template. Again, you can find more details about using package &lt;strong&gt;{exams}&lt;/strong&gt; in its &lt;a href=&#34;http://www.r-exams.org/&#34;&gt;website&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;compiling-to-pdf&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Compiling to pdf&lt;/h2&gt;
&lt;p&gt;To help tutors compiling their own exercises, I wrote function &lt;strong&gt;afedR3&lt;/strong&gt;::&lt;strong&gt;compile_pdf_exercises()&lt;/strong&gt; . You’ll need the following information to use it:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(REQUIRED) name of students (will be printed in pdf)&lt;/li&gt;
&lt;li&gt;(OPTIONAL) students ids (I usually use their university card number)&lt;/li&gt;
&lt;li&gt;(OPTIONAL) Chapters to include (e.g 1:3)&lt;/li&gt;
&lt;li&gt;(OPTIONAL) Exercise name (e.g. Activity I, Exercise II, ..)&lt;/li&gt;
&lt;li&gt;(OPTIONAL) Course name (e.g. Tutorial in R)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here’s an example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(afedR3)

names_students &amp;lt;- c(&amp;#39;Michael Peterling&amp;#39;, &amp;#39;John Aspper&amp;#39;, &amp;#39;Mr. Beans&amp;#39;)
ids_students &amp;lt;- sample(1:1000, length(names_students)) # probably id card?
class_name &amp;lt;- &amp;quot;Introduction to R&amp;quot;
exercise_name &amp;lt;- &amp;quot;Activity 01&amp;quot;
chapters &amp;lt;- 1:3 # chapters from 1 to 13
dir_output &amp;lt;- fs::file_temp(&amp;#39;pdf-example_&amp;#39;)

df_exams &amp;lt;- compile_pdf_exercises(students_names = names_students, 
                                  students_ids = ids_students, 
                                  class_name = class_name,
                                  exercise_name = exercise_name,
                                  chapters_to_include = chapters,
                                  dir_out = dir_output)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output of &lt;code&gt;compile_pdf_exercises&lt;/code&gt; is a table with the correct answers for &lt;code&gt;schoice&lt;/code&gt; and &lt;code&gt;num&lt;/code&gt; type of questions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(df_exams)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 69
## Columns: 4
## $ i_name   &amp;lt;chr&amp;gt; &amp;quot;Michael Peterling&amp;quot;, &amp;quot;Michael Peterling&amp;quot;, &amp;quot;Michael Peterling&amp;quot;…
## $ i_ver    &amp;lt;int&amp;gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…
## $ i_q      &amp;lt;int&amp;gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…
## $ solution &amp;lt;chr&amp;gt; &amp;quot;b&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;e&amp;quot;, NA, &amp;quot;c&amp;quot;, NA, NA, NA, NA, NA, NA, NA,…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After compilation, all pdf files are available at folder &lt;code&gt;dir_output&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fs::dir_ls(dir_output)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## /tmp/Rtmpo8a1iU/pdf-example_7a710296d8801/Activity 01_Ver 01_Michael Peterling.pdf
## /tmp/Rtmpo8a1iU/pdf-example_7a710296d8801/Activity 01_Ver 02_John Aspper.pdf
## /tmp/Rtmpo8a1iU/pdf-example_7a710296d8801/Activity 01_Ver 03_Mr. Beans.pdf&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The final result will be as follows:&lt;/p&gt;
&lt;blockquote class=&#34;imgur-embed-pub&#34; lang=&#34;en&#34; data-id=&#34;a/LO9xafp&#34; data-context=&#34;false&#34;&gt;
&lt;a href=&#34;//imgur.com/a/LO9xafp&#34;&gt;&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;//s.imgur.com/min/embed.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div id=&#34;exporting-to-moodle&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exporting to Moodle&lt;/h2&gt;
&lt;p&gt;You can also export to &lt;em&gt;e-learning&lt;/em&gt; platforms such as Moodle. The process is quite simple as &lt;code&gt;exams&lt;/code&gt; package does all the heavy work:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(afedR3)

eoc_folders &amp;lt;- afedR3::get_EOC_dir()

available_chapters &amp;lt;- afedR3::exercises_dir_list()

exercises_folders &amp;lt;- purrr::map_chr(
  available_chapters[1:3],
  afedR3::exercises_dir_get
)

exercises_files &amp;lt;- fs::dir_ls(exercises_folders)

dir_output &amp;lt;- fs::file_temp(&amp;#39;moodle-test_&amp;#39;)

exams::exams2moodle(file = exercises_files, 
                    name = &amp;#39;MOODLE_afedR-eoc-chapters_01-03&amp;#39;, 
                    dir = dir_output)

fs::dir_ls(dir_output)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## /tmp/Rtmpo8a1iU/moodle-test_7a7101ff66451/MOODLE_afedR-eoc-chapters_01-03.xml&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The resulting .xml file can be imported in the database of any Moodle class you have access.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exporting-to-blackboard&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exporting to Blackboard&lt;/h2&gt;
&lt;p&gt;Likewise, exporting to &lt;a href=&#34;https://www.blackboard.com/&#34;&gt;Blackboard&lt;/a&gt; is simple:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(afedR3)
library(tth) # required for bb 

dir_output &amp;lt;- dir_output &amp;lt;- fs::file_temp(&amp;#39;blackboard-test_&amp;#39;)

exams::exams2blackboard(file = exercises_files, 
                        name = &amp;#39;BB_afedR-eoc-chapters_01-03&amp;#39;, 
                        dir = dir_output)

fs::dir_ls(dir_output)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## /tmp/Rtmpo8a1iU/blackboard-test_7a710dc108e0/BB_afedR-eoc-chapters_01-03.zip&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This .zip file contains all exercises of chapters 01, 02 and 3, and can be imported in your blackboard account.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Looking back at 2021-2022 and plans for 2023</title>
      <link>https://www.msperlin.com/post/2022-12-29-looking-back-2022/</link>
      <pubDate>Thu, 29 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2022-12-29-looking-back-2022/</guid>
      <description>


&lt;p&gt;Every end of year I write about what happened during the yearly cycle and what’s to come.&lt;/p&gt;
&lt;p&gt;This year was very special and impactful for me. I learned a lot about myself, about what I do and why. Here are the highlights.&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;highlights-of-2022-and-2021&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Highlights of 2022 and 2021&lt;/h1&gt;
&lt;div id=&#34;academic-papers&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Academic Papers&lt;/h2&gt;
&lt;p&gt;I published and co-authored several academic papers during this period:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://bibliotecadigital.fgv.br/ojs/index.php/rbfin/article/view/85378&#34;&gt;What drives the release of material facts for Brazilian stocks?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://doi.org/10.1016/j.joi.2022.101287&#34;&gt;The Academic Inbreeding Controversy: Analysis and Evidence from Brazil&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://dx.doi.org/10.1108/GM-06-2019-0088&#34;&gt;Board gender diversity: performance and risk of Brazilian firms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://doi.org/10.15728/bbr.2021.18.5.5&#34;&gt;O Impacto da Titulação Acadêmica de Conselheiros e Diretores sobre a Performance de Empresas Negociadas na B3&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;books&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Books&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The first edition of book &lt;a href=&#34;https://msperlin.com/vdr/&#34;&gt;Visualização de Dados com o R&lt;/a&gt; was published in October 2022. This was a great project and I had a great time and learned a lot doing it.&lt;/li&gt;
&lt;li&gt;The third edition of &lt;a href=&#34;http://www.msperlin.com/adfeR/&#34;&gt;Análise de Dados Financeiros e Econômicos com o R&lt;/a&gt; was published.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;r-packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;R Packages&lt;/h2&gt;
&lt;p&gt;Package &lt;a href=&#34;https://github.com/ropensci/yfR/&#34;&gt;yfR&lt;/a&gt; is the new iteration of BatchGetSymbols, with several new features and improvements. I had a very good experience submitting it for publication in &lt;a href=&#34;https://ropensci.org/&#34;&gt;ropensci&lt;/a&gt;. Both reviewers had great ideas that were implemented.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;checking-previous-plans&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Checking previous plans&lt;/h1&gt;
&lt;p&gt;At the end of 2020, my plans for 2021 and 2021 &lt;a href=&#34;https://msperlin.com/post/2020-12-22-looking-back-2020/&#34;&gt;were&lt;/a&gt;:&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;Publish new R/ggplot2 book (&lt;em&gt;Visualização de Dados com R&lt;/em&gt;)&lt;/dt&gt;
&lt;dd&gt;
Done! :)
&lt;/dd&gt;
&lt;dt&gt;Publish third edition of &lt;em&gt;Análise de Dados Financeiros e Econômicos com o R&lt;/em&gt;&lt;/dt&gt;
&lt;dd&gt;
Also done! :)
&lt;/dd&gt;
&lt;dt&gt;Publish board papers&lt;/dt&gt;
&lt;dd&gt;
Done! See it &lt;a href=&#34;https://msperlin.com/publication/&#34;&gt;here&lt;/a&gt;.
&lt;/dd&gt;
&lt;dt&gt;Publish paper about academic inbreeding&lt;/dt&gt;
&lt;dd&gt;
Done! The paper is available at &lt;a href=&#34;https://doi.org/10.1016/j.joi.2022.101287&#34;&gt;JOI&lt;/a&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;plans-for-2023&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Plans for 2023&lt;/h1&gt;
&lt;dl&gt;
&lt;dt&gt;Publish revision of &lt;em&gt;Analyzing Financial and Economic Data with R&lt;/em&gt;&lt;/dt&gt;
&lt;dd&gt;
I’m currently working on it. I’m implementing major changes in the background, on how the book is written and compiled. On a side note, it is great to have time to think about compiling books using Rmarkdown, and organizing it in a common framework. This will make it easier to update ALL books over time.
&lt;/dd&gt;
&lt;dt&gt;Publish revision of &lt;em&gt;Análise de Dados Financeiros e Econômicos com o R&lt;/em&gt;&lt;/dt&gt;
&lt;dd&gt;
Same as previous revision. Almost everything improved in the english version will also be done here.
&lt;/dd&gt;
&lt;dt&gt;Write and publish paper about research schollarships&lt;/dt&gt;
&lt;dd&gt;
This is is WIP (work in progress). I have no idea how it will turn out, but the main guideline is investigating the effects (or causes) of research schollarships (&lt;em&gt;Bolsas de Produtividade&lt;/em&gt;) in Brazil. Final version and publication is likelly to happen in 2024.
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>NEW BOOK: Visualização de Dados com o R (in portuguese)</title>
      <link>https://www.msperlin.com/post/2022-10-22-vdr-ed1-announcement/</link>
      <pubDate>Sat, 22 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2022-10-22-vdr-ed1-announcement/</guid>
      <description>


&lt;p&gt;It is with great pleasure that I officially announce the publication of my book &lt;strong&gt;Visualização de Dados com o R&lt;/strong&gt;. The content of the book is an extension of chapter 10 of &lt;a href=&#34;https://www.msperlin.com/afedR/&#34;&gt;afedR&lt;/a&gt;. The book is written in portuguese and available at Amazon and online:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com.br/dp/B0BK2V4HTB&#34;&gt;ebook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/dp/B0BJYJQ92Q&#34;&gt;paperback&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/dp/B0BJYMHWLN&#34;&gt;hardcover&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.msperlin.com/vdr/&#34;&gt;Online version (chapters 01-03)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can find more details in its own &lt;a href=&#34;https://www.msperlin.com/publication/2022_book-vdr/&#34;&gt;blog page&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Update of compiled datasets (2022)</title>
      <link>https://www.msperlin.com/post/2022-04-07-update-on-data/</link>
      <pubDate>Thu, 07 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2022-04-07-update-on-data/</guid>
      <description>


&lt;p&gt;Back in 2020 I started to compile and share financial data in &lt;a href=&#34;https://dataverse.harvard.edu/dataverse/msperlin&#34;&gt;dataverse&lt;/a&gt;. The data covers corporate finance events from the DFP and FRE systems. The available tables are the same I use for my research and teaching material, and will be updated once a year.&lt;/p&gt;
&lt;p&gt;Today I updated all datasets. The available data are:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;col width=&#34;18%&#34; /&gt;
&lt;col width=&#34;44%&#34; /&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;R Package&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Source of Data&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Direct Link&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Last Update&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;GetTDData&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Tesouro Nacional&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Prices and yields of brazilian sovereign bonds&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://doi.org/10.7910/DVN/SCSQUF&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2022-04-06&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;GetFREData&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;CVM&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Corporate dataset from FRE systems&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://doi.org/10.7910/DVN/QIMUNZ&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2022-04-06&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;GetDFPData2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;CVM&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Annual Financial Reports from DFP system&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://doi.org/10.7910/DVN/7VVX4J&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2022-04-06&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>New R package yfR</title>
      <link>https://www.msperlin.com/post/2022-03-31-yfr/</link>
      <pubDate>Thu, 31 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2022-03-31-yfr/</guid>
      <description>


&lt;p&gt;Package &lt;a href=&#34;https://github.com/msperlin/BatchGetSymbols&#34;&gt;BatchGetSymbols&lt;/a&gt; facilitates importation of Yahoo Finance data directly into R and is one of my most popular R packages, with over 100k installations since conception (around 2500 downloads per month). However, I developed BatchGetSymbols back in 2016, with many bad structural choices from my part.&lt;/p&gt;
&lt;p&gt;For years I wanted to improved the code but always restrained myself because I did not want to mess up the execution of other people’s code that was based on BatchGetSymbols. In order to implement all the breaking changes and move forward with the package, I decided to develop a &lt;strong&gt;new&lt;/strong&gt; (and fresh) package called yfR.&lt;/p&gt;
&lt;p&gt;Today I’m releasing the first version of yfR (not yeat in CRAN). This in a major upgrade on BatchGetSymbols, with many backwards-incompatible changes.&lt;/p&gt;
&lt;div id=&#34;motivation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Motivation&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;yfR&lt;/code&gt; is the second and backwards-incompatible version of &lt;a href=&#34;https://CRAN.R-project.org/package=BatchGetSymbols&#34;&gt;BatchGetSymbols&lt;/a&gt;. In a nutshell, it provides access to daily stock prices from &lt;a href=&#34;https://finance.yahoo.com/&#34;&gt;Yahoo Finance&lt;/a&gt;, a vast repository with financial data around the globe. Yahoo Finance cover a large number of markets and assets, being used extensively for importing price datasets used in academic research and teaching.&lt;/p&gt;
&lt;p&gt;Package &lt;code&gt;yfR&lt;/code&gt; is based on &lt;a href=&#34;https://www.quantmod.com/&#34;&gt;quantmod&lt;/a&gt; and used its main function for fetching data from Yahoo Finance. The main innovation in &lt;code&gt;yfR&lt;/code&gt; is in the organization of the imported financial data and using local caching system and parallel computing for speeding up large scale download of datasets from Yahoo Finance.&lt;/p&gt;
&lt;p&gt;See full documentation &lt;a href=&#34;https://github.com/msperlin/yfR&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;features&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Fetchs daily/weekly/monthly/annual stock prices/returns from yahoo finance and outputs a dataframe (tibble) in the long format (stacked data);&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A new feature called “collections” facilitates download of multiple tickers from a particular market/index. You can, for example, download data for all stocks in the SP500 index with a simple call to &lt;code&gt;yf_collection_get()&lt;/code&gt;;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A session-persistent smart cache system is available by default. This means that the data is saved locally and only missing portions are downloaded, if needed.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;All dates are compared to a benchmark ticker such as SP500 and, whenever an individual asset does not have a sufficient number of dates, the software drops it from the output. This means you can choose to ignore tickers with high number of missing dates.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A customized function called &lt;code&gt;yf_convert_to_wide()&lt;/code&gt; can transform the long dataframe into a wide format (tickers as columns), much used in portfolio optimization. The output is a list where each element is a different target variable (prices, returns, volumes).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Parallel computing with package &lt;code&gt;furrr&lt;/code&gt; is available, speeding up the data importation process.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;differences-from-batchgetsymbols&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Differences from &lt;a href=&#34;https://github.com/msperlin/BatchGetSymbols&#34;&gt;BatchGetSymbols&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Package &lt;code&gt;BatchgetSymbols&lt;/code&gt; was developed back in 2016, with many bad structural choices from my part. Since then, I learned more about R and its ecosystem, resulting in better and more maintainable code. However, it is impossible to keep compatibility with the changes I wanted to make, which is why I decided to develop a new (and fresh) package.&lt;/p&gt;
&lt;p&gt;Here are the main differences between &lt;code&gt;yfR&lt;/code&gt; (new) and &lt;code&gt;BatchGetSymbols&lt;/code&gt; (old):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;All input arguments are now formatted as “snake_case” and not “dot.case”. For example, the argument for the first date of data importation in &lt;code&gt;yfR::yf_get()&lt;/code&gt; is &lt;code&gt;first_date&lt;/code&gt;, and not &lt;code&gt;first.date&lt;/code&gt; as used in &lt;code&gt;BatchGetSymbols::BatchGetSymbols&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;All function have been renamed for a common API notation. For example, &lt;code&gt;BatchGetSymbols::BatchGetSymbols&lt;/code&gt; is now &lt;code&gt;yfR::yf_get()&lt;/code&gt;. Likewise, the function for fetching collections is &lt;code&gt;yfR::yf_collection_get()&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The output of &lt;code&gt;yfR::yf_get()&lt;/code&gt; is always a tibble with the price data (and not a list as in &lt;code&gt;BatchGetSymbols::BatchGetSymbols&lt;/code&gt;). If one wants the tibble with a summary of the importing process, it is available as an attribute of the output (see function &lt;code&gt;base::attributes&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A new feature called “collection”, which allows for easy download of a collection of tickers. For example, you can download price data for all components of the SP500 by simply calling &lt;code&gt;yfR::yf_collection_get(&#34;SP500&#34;)&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;New and prettier status messages using package &lt;code&gt;cli&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can find more details at its github repo:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/msperlin/yfR&#34; class=&#34;uri&#34;&gt;https://github.com/msperlin/yfR&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;installation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;# CRAN (not yet available)
#install.packages(&amp;#39;yfR&amp;#39;)

# Github (dev version)
devtools::install_github(&amp;#39;msperlin/yfR&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;examples&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Examples&lt;/h2&gt;
&lt;div id=&#34;fetching-a-single-stock-price&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fetching a single stock price&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(yfR)

# set options for algorithm
my_ticker &amp;lt;- &amp;#39;FB&amp;#39;
first_date &amp;lt;- Sys.Date() - 30
last_date &amp;lt;- Sys.Date()

# fetch data
df_yf &amp;lt;- yf_get(tickers = my_ticker, 
                first_date = first_date,
                last_date = last_date)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Running yfR for 1 stocks | 2022-03-01 --&amp;gt; 2022-03-31 (30 days) ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Downloading data for benchmark ticker ^GSPC&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ (1/1) Fetching data for &amp;#39;,
## &amp;#39;FB&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## !    - not cached&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - cache saved successfully&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 22 valid rows (2022-03-01 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 100% of valid prices -- Well done msperlin!&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Binding price data&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# output is a tibble with data
head(df_yf)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 × 10
##   ticker ref_date   price_open price_high price_low price_close   volume
##   &amp;lt;chr&amp;gt;  &amp;lt;date&amp;gt;          &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 FB     2022-03-01       210.       212.      202.        203. 27094900
## 2 FB     2022-03-02       205.       209.      202.        208. 29452100
## 3 FB     2022-03-03       209.       209.      201.        203. 27263500
## 4 FB     2022-03-04       202.       206.      199.        200. 32130900
## 5 FB     2022-03-07       201.       201.      187.        187. 38560600
## 6 FB     2022-03-08       188.       197.      186.        190. 37508100
## # … with 3 more variables: price_adjusted &amp;lt;dbl&amp;gt;, ret_adjusted_prices &amp;lt;dbl&amp;gt;,
## #   ret_closing_prices &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;fetching-many-stock-prices&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fetching many stock prices&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(yfR)
library(ggplot2)

my_ticker &amp;lt;- c(&amp;#39;FB&amp;#39;, &amp;#39;GM&amp;#39;, &amp;#39;MMM&amp;#39;)
first_date &amp;lt;- Sys.Date() - 100
last_date &amp;lt;- Sys.Date()

df_yf_multiple &amp;lt;- yf_get(tickers = my_ticker, 
                         first_date = first_date,
                         last_date = last_date)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Running yfR for 3 stocks | 2021-12-21 --&amp;gt; 2022-03-31 (100 days) ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Downloading data for benchmark ticker ^GSPC&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ (1/3) Fetching data for &amp;#39;,
## &amp;#39;FB&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - found cache file (2022-03-01 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## !    - need new data (cache doesnt match query)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 69 valid rows (2021-12-21 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 100% of valid prices -- All OK!&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ (2/3) Fetching data for &amp;#39;,
## &amp;#39;GM&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## !    - not cached&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - cache saved successfully&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 69 valid rows (2021-12-21 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 100% of valid prices -- Well done msperlin!&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ (3/3) Fetching data for &amp;#39;,
## &amp;#39;MMM&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## !    - not cached&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - cache saved successfully&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 69 valid rows (2021-12-21 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 100% of valid prices -- Youre doing good!&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Binding price data&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- ggplot(df_yf_multiple, 
            aes(x = ref_date, y = price_adjusted,
                color = ticker)) + 
  geom_line()

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2022-03-31-yfR_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fetching-collections-of-prices&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fetching collections of prices&lt;/h3&gt;
&lt;p&gt;Collections are just a bundle of tickers pre-organized in the package. For example, collection &lt;code&gt;SP500&lt;/code&gt; represents the current composition of the SP500 index.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(yfR)

df_yf &amp;lt;- yf_collection_get(&amp;quot;SP500&amp;quot;, 
                           first_date = Sys.Date() - 30,
                           last_date = Sys.Date())

head(df_yf)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;fetching-dailyweeklymonthlyyearly-price-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fetching daily/weekly/monthly/yearly price data&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(yfR)
library(ggplot2)
library(dplyr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;dplyr&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:stats&amp;#39;:
## 
##     filter, lag&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:base&amp;#39;:
## 
##     intersect, setdiff, setequal, union&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_ticker &amp;lt;- &amp;#39;GE&amp;#39;
first_date &amp;lt;- &amp;#39;2010-01-01&amp;#39;
last_date &amp;lt;- Sys.Date()

df_dailly &amp;lt;- yf_get(tickers = my_ticker, 
                    first_date, last_date, 
                    freq_data = &amp;#39;daily&amp;#39;) |&amp;gt;
  mutate(freq = &amp;#39;daily&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Running yfR for 1 stocks | 2010-01-01 --&amp;gt; 2022-03-31 (4472 days) ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Downloading data for benchmark ticker ^GSPC&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ (1/1) Fetching data for &amp;#39;,
## &amp;#39;GE&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## !    - not cached&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - cache saved successfully&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 3082 valid rows (2010-01-04 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 100% of valid prices -- Time for some tea?&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Binding price data&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_weekly &amp;lt;- yf_get(tickers = my_ticker, 
                    first_date, last_date, 
                    freq_data = &amp;#39;weekly&amp;#39;) |&amp;gt;
  mutate(freq = &amp;#39;weekly&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Running yfR for 1 stocks | 2010-01-01 --&amp;gt; 2022-03-31 (4472 days) ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Downloading data for benchmark ticker ^GSPC&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ (1/1) Fetching data for &amp;#39;,
## &amp;#39;GE&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - found cache file (2010-01-04 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 3082 valid rows (2010-01-04 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 100% of valid prices -- You got it msperlin!&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Binding price data&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_monthly &amp;lt;- yf_get(tickers = my_ticker, 
                     first_date, last_date, 
                     freq_data = &amp;#39;monthly&amp;#39;) |&amp;gt;
  mutate(freq = &amp;#39;monthly&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Running yfR for 1 stocks | 2010-01-01 --&amp;gt; 2022-03-31 (4472 days) ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Downloading data for benchmark ticker ^GSPC&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ (1/1) Fetching data for &amp;#39;,
## &amp;#39;GE&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - found cache file (2010-01-04 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 3082 valid rows (2010-01-04 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 100% of valid prices -- Good stuff!&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Binding price data&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_yearly &amp;lt;- yf_get(tickers = my_ticker, 
                    first_date, last_date, 
                    freq_data = &amp;#39;yearly&amp;#39;) |&amp;gt;
  mutate(freq = &amp;#39;yearly&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Running yfR for 1 stocks | 2010-01-01 --&amp;gt; 2022-03-31 (4472 days) ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Downloading data for benchmark ticker ^GSPC&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ (1/1) Fetching data for &amp;#39;,
## &amp;#39;GE&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - found cache file (2010-01-04 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 3082 valid rows (2010-01-04 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 100% of valid prices -- Good job msperlin!&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Binding price data&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_allfreq &amp;lt;- bind_rows(
  list(df_dailly, df_weekly, df_monthly, df_yearly)
) |&amp;gt;
  mutate(freq = factor(freq, 
                       levels = c(&amp;#39;daily&amp;#39;, 
                                  &amp;#39;weekly&amp;#39;,
                                  &amp;#39;monthly&amp;#39;,
                                  &amp;#39;yearly&amp;#39;))) # make sure the order in plot is right

p &amp;lt;- ggplot(df_allfreq, aes(x=ref_date, y = price_adjusted)) + 
  geom_point() + geom_line() + facet_grid(freq ~ ticker) + 
  theme_minimal() + 
  labs(x = &amp;#39;&amp;#39;, y = &amp;#39;Adjusted Prices&amp;#39;)

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2022-03-31-yfR_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;changing-format-to-wide&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Changing format to wide&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(yfR)
library(ggplot2)

my_ticker &amp;lt;- c(&amp;#39;FB&amp;#39;, &amp;#39;GM&amp;#39;, &amp;#39;MMM&amp;#39;)
first_date &amp;lt;- Sys.Date() - 100
last_date &amp;lt;- Sys.Date()

df_yf_multiple &amp;lt;- yf_get(tickers = my_ticker, 
                         first_date = first_date,
                         last_date = last_date)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Running yfR for 3 stocks | 2021-12-21 --&amp;gt; 2022-03-31 (100 days) ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Downloading data for benchmark ticker ^GSPC&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ (1/3) Fetching data for &amp;#39;,
## &amp;#39;FB&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - found cache file (2021-12-21 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 69 valid rows (2021-12-21 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 100% of valid prices -- Good job msperlin!&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ (2/3) Fetching data for &amp;#39;,
## &amp;#39;GM&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - found cache file (2021-12-21 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 69 valid rows (2021-12-21 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 100% of valid prices -- All OK!&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ (3/3) Fetching data for &amp;#39;,
## &amp;#39;MMM&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - found cache file (2021-12-21 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 69 valid rows (2021-12-21 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 100% of valid prices -- Well done msperlin!&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Binding price data&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;l_wide &amp;lt;- yf_convert_to_wide(df_yf_multiple)

prices_wide &amp;lt;- l_wide$price_adjusted

head(prices_wide)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 × 4
##   ref_date      FB    GM   MMM
##   &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 2021-12-21  334.  54.8  171.
## 2 2021-12-22  330.  56.1  171.
## 3 2021-12-23  335.  56.9  173.
## 4 2021-12-27  346.  57.4  175.
## 5 2021-12-28  346.  57.1  176.
## 6 2021-12-29  343.  57.2  177.&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A shiny interface to BatchGetSymbols</title>
      <link>https://www.msperlin.com/post/2021-05-26-bgs-shiny/</link>
      <pubDate>Wed, 26 May 2021 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2021-05-26-bgs-shiny/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Hadley Wickham recently released an online version of &lt;a href=&#34;https://mastering-shiny.org/&#34;&gt;Mastering Shiny&lt;/a&gt;. The book is great! If you haven’t read it, do it fast! On a side note, it is really amazing how much of &lt;strong&gt;good and curated content&lt;/strong&gt; you can get for free in R. When I started programming back in 2007, the first step was buying a brand new – and sometimes expensive – book about the language. There were blogs and other sites, but most content was very basic and not curated, meaning that the posted code most of the time did not work. The new generation probably have no idea of how easy it is to start fresh on new code these days [I fell quite old writing this sentence :)].&lt;/p&gt;
&lt;p&gt;Well, this was a great opportunity for me to brush up my shiny skills. I learned shiny back in 2016 and can report on the development of the technology. I’m really impressed by the current state of shiny today. It is becoming very competitive against other data based dashboard technologies such as those using Python.&lt;/p&gt;
&lt;p&gt;The result of this learning sprint is &lt;a href=&#34;https://www.msperlin.com/shiny/bgs/&#34;&gt;bgs-shiny&lt;/a&gt;, a shiny interface to package BatchGetSymbols. Within this application you can visualize and download price data from Yahoo Finance. In the background, every data point is live feed, fetched from Yahoo Finance. As usual, all code is available in &lt;a href=&#34;https://github.com/msperlin/BatchGetSymbols-Shiny&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Update of compiled datasets</title>
      <link>https://www.msperlin.com/post/2021-04-09-update-on-data/</link>
      <pubDate>Fri, 09 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2021-04-09-update-on-data/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Back in 2020 I started to compile and share financial data in &lt;a href=&#34;https://dataverse.harvard.edu/dataverse/msperlin&#34;&gt;dataverse&lt;/a&gt;. The data covers corporate finance events from the DFP and FRE systems. The available tables are the same I use for my research and teaching material, and will be updated once a year.&lt;/p&gt;
&lt;p&gt;Today I updated all datasets. The available data are:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;col width=&#34;18%&#34; /&gt;
&lt;col width=&#34;44%&#34; /&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;R Package&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Source of Data&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Direct Link&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Last Update&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;GetTDData&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Tesouro Nacional&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Prices and yields of brazilian sovereign bonds&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://doi.org/10.7910/DVN/SCSQUF&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2021-04-09&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;GetFREData&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;CVM&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Corporate dataset from FRE systems&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://doi.org/10.7910/DVN/QIMUNZ&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2021-04-09&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;BatchGetSymbols&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Yahoo Finance&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Daily adjusted and unadjusted prices and trading volumes of stocks&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://doi.org/10.7910/DVN/7NAG08&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2021-04-09&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;GetDFPData2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;CVM&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Annual Financial Reports from DFP system&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://doi.org/10.7910/DVN/7VVX4J&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2021-04-09&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>GetFREData available in CRAN!</title>
      <link>https://www.msperlin.com/post/2021-04-06-getfredata-on-cran/</link>
      <pubDate>Tue, 06 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2021-04-06-getfredata-on-cran/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I’m happy to report that package &lt;code&gt;GetFREData&lt;/code&gt; is now available in CRAN. This R package serves as an interface to &lt;strong&gt;all&lt;/strong&gt; corporate datasets available in the FRE system, a vast and &lt;strong&gt;official&lt;/strong&gt; repository of information about many different corporate events. All companies listed at B3 – Brazilian stock exchange – must report to FRE any significant change in their corporate structure. You can find more details about what is available in FRE in its &lt;a href=&#34;https://www.rad.cvm.gov.br/ENETCONSULTA/frmGerenciaPaginaFRE.aspx?NumeroSequencialDocumento=102618&amp;amp;CodigoTipoInstituicao=2&#34;&gt;web interface&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The R package fetches data from the &lt;a href=&#34;http://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/FRE/&#34;&gt;CVM ftp&lt;/a&gt;, downloads and parses the xml files, and output several tables as a &lt;code&gt;list&lt;/code&gt;. The corporate data includes (since 2010):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;List of stockholders&lt;/li&gt;
&lt;li&gt;All capital issues&lt;/li&gt;
&lt;li&gt;Stock value over years&lt;/li&gt;
&lt;li&gt;Compensation of boards and directors&lt;/li&gt;
&lt;li&gt;Composition of boards and committees&lt;/li&gt;
&lt;li&gt;Family relations within the company&lt;/li&gt;
&lt;li&gt;List of companies related to family members&lt;/li&gt;
&lt;li&gt;Stock details&lt;/li&gt;
&lt;li&gt;Intangible details&lt;/li&gt;
&lt;li&gt;Auditing details&lt;/li&gt;
&lt;li&gt;Dividends details&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Historical parsed data between 2010 and 2019 is available for download in my &lt;a href=&#34;https://www.msperlin.com/data/&#34;&gt;personal site&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;installation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# CRAN (stable)
install.packages(&amp;#39;GetFREData&amp;#39;)

# github (development)
if (!require(devtools)) install.packages(&amp;#39;devtools&amp;#39;)
if (!require(GetFREData)) devtools::install_github(&amp;#39;msperlin/GetFREData&amp;#39;) &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;example-of-usage&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example of usage&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(GetFREData)
library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓ ggplot2 3.3.3     ✓ purrr   0.3.4
## ✓ tibble  3.1.0     ✓ dplyr   1.0.5
## ✓ tidyr   1.1.3     ✓ stringr 1.4.0
## ✓ readr   1.4.0     ✓ forcats 0.5.1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;search_company(&amp;#39;grendene&amp;#39;, 
               cache_folder = tempdir())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Fetching info on B3 companies&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Dowloading file from CVM&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Reading file from CVM&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Saving cache data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Got 2331 lines for 2290 companies [Actives = 648 Inactives = 1653]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Found 1 companies:&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## GRENDENE SA | situation = ATIVO | sector = Têxtil e Vestuário | CD_CVM = 19615&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 44
##   CD_CVM DENOM_SOCIAL DENOM_COMERC SETOR_ATIV    PF_PJ CNPJ     DT_REG  DT_CONST
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;        &amp;lt;chr&amp;gt;        &amp;lt;chr&amp;gt;         &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;   
## 1  19615 GRENDENE SA  GRENDENE SA  Têxtil e Ves… PJ    8985034… 26/10/… 25/02/1…
## # … with 36 more variables: DT_CANCEL &amp;lt;chr&amp;gt;, MOTIVO_CANCEL &amp;lt;chr&amp;gt;,
## #   SIT_REG &amp;lt;chr&amp;gt;, DT_INI_SIT &amp;lt;chr&amp;gt;, SIT_EMISSOR &amp;lt;chr&amp;gt;,
## #   DT_INI_SIT_EMISSOR &amp;lt;chr&amp;gt;, CATEG_REG &amp;lt;chr&amp;gt;, DT_INI_CATEG &amp;lt;chr&amp;gt;,
## #   AUDITOR &amp;lt;chr&amp;gt;, CNPJ_AUDITOR &amp;lt;dbl&amp;gt;, TP_ENDER &amp;lt;chr&amp;gt;, LOGRADOURO &amp;lt;chr&amp;gt;,
## #   COMPL &amp;lt;chr&amp;gt;, BAIRRO &amp;lt;chr&amp;gt;, CIDADE &amp;lt;chr&amp;gt;, UF &amp;lt;chr&amp;gt;, PAIS &amp;lt;chr&amp;gt;,
## #   CD_POSTAL &amp;lt;lgl&amp;gt;, TEL &amp;lt;chr&amp;gt;, FAX &amp;lt;chr&amp;gt;, EMAIL &amp;lt;chr&amp;gt;, TP_RESP &amp;lt;chr&amp;gt;,
## #   RESP &amp;lt;chr&amp;gt;, DT_INI_RESP &amp;lt;chr&amp;gt;, LOGRADOURO_RESP &amp;lt;chr&amp;gt;, COMPL_RESP &amp;lt;chr&amp;gt;,
## #   BAIRRO_RESP &amp;lt;chr&amp;gt;, CIDADE_RESP &amp;lt;chr&amp;gt;, UF_RESP &amp;lt;chr&amp;gt;, PAIS_RESP &amp;lt;chr&amp;gt;,
## #   CEP_RESP &amp;lt;dbl&amp;gt;, TEL_RESP &amp;lt;chr&amp;gt;, FAX_RESP &amp;lt;chr&amp;gt;, EMAIL_RESP &amp;lt;chr&amp;gt;,
## #   TP_MERC &amp;lt;chr&amp;gt;, cnpj_number &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;l_fre &amp;lt;- get_fre_data(companies_cvm_codes = 19615,
                      fre_to_read = &amp;#39;last&amp;#39;,
                      first_year = 2020,
                      last_year = 2020, 
                      cache_folder = tempdir())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Fetching ftp contents&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  * Reading fre_cia_aberta_2020.zip&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Found 1 FRE docs to read&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Starting Downloads:&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## -&amp;gt; Company 19615 | fre file 100932 (ver 9) | 2020-01-01 | reading and saving cache&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(l_fre)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 21
##  $ df_stockholders            :&amp;#39;data.frame&amp;#39;: 10 obs. of  18 variables:
##   ..$ CNPJ_CIA               : chr [1:10] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; ...
##   ..$ DENOM_CIA              : chr [1:10] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; ...
##   ..$ DT_REFER               : Date[1:10], format: &amp;quot;2020-01-01&amp;quot; &amp;quot;2020-01-01&amp;quot; ...
##   ..$ CD_CVM                 : num [1:10] 19615 19615 19615 19615 19615 ...
##   ..$ ID_DOC                 : num [1:10] 100932 100932 100932 100932 100932 ...
##   ..$ VERSAO                 : num [1:10] 9 9 9 9 9 9 9 9 9 9
##   ..$ type.register          : chr [1:10] &amp;quot;Acionista&amp;quot; &amp;quot;Acionista&amp;quot; &amp;quot;Acionista&amp;quot; &amp;quot;Acionista&amp;quot; ...
##   ..$ id.person              : chr [1:10] &amp;quot;37071813833   &amp;quot; &amp;quot;09867597087   &amp;quot; &amp;quot;09864784072   &amp;quot; &amp;quot;68595743053   &amp;quot; ...
##   ..$ id.nationality         : chr [1:10] &amp;quot;Brasileira&amp;quot; &amp;quot;Brasileiro&amp;quot; &amp;quot;Brasileiro&amp;quot; &amp;quot;Brasileiro&amp;quot; ...
##   ..$ id.state               : chr [1:10] &amp;quot;São Paulo&amp;quot; &amp;quot;Rio Grande do Sul&amp;quot; &amp;quot;Rio Grande do Sul&amp;quot; &amp;quot;Rio Grande do Sul&amp;quot; ...
##   ..$ id.country             : logi [1:10] NA NA NA NA NA NA ...
##   ..$ name.stockholder       : chr [1:10] &amp;quot;Gabriella de Camargo Bartelle&amp;quot; &amp;quot;Alexandre Grendene Bartelle&amp;quot; &amp;quot;Pedro Grendene Bartelle&amp;quot; &amp;quot;Pedro Bartelle&amp;quot; ...
##   ..$ type.stockholder       : chr [1:10] &amp;quot;Fisica&amp;quot; &amp;quot;Fisica&amp;quot; &amp;quot;Fisica&amp;quot; &amp;quot;Fisica&amp;quot; ...
##   ..$ qtd.ord.shares         : chr [1:10] &amp;quot;28912677&amp;quot; &amp;quot;371651807&amp;quot; &amp;quot;125312376&amp;quot; &amp;quot;35557397&amp;quot; ...
##   ..$ perc.ord.shares        : chr [1:10] &amp;quot;3.200000&amp;quot; &amp;quot;41.200000&amp;quot; &amp;quot;13.890000&amp;quot; &amp;quot;3.940000&amp;quot; ...
##   ..$ qtd.pref.shares        : chr [1:10] &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; ...
##   ..$ perc.pref.shares       : chr [1:10] &amp;quot;0.000000&amp;quot; &amp;quot;0.000000&amp;quot; &amp;quot;0.000000&amp;quot; &amp;quot;0.000000&amp;quot; ...
##   ..$ controlling.stockholder: logi [1:10] TRUE TRUE TRUE TRUE TRUE TRUE ...
##  $ df_capital                 :&amp;#39;data.frame&amp;#39;: 2 obs. of  9 variables:
##   ..$ CNPJ_CIA   : chr [1:2] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot;
##   ..$ DENOM_CIA  : chr [1:2] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot;
##   ..$ DT_REFER   : Date[1:2], format: &amp;quot;2020-01-01&amp;quot; &amp;quot;2020-01-01&amp;quot;
##   ..$ CD_CVM     : num [1:2] 19615 19615
##   ..$ ID_DOC     : num [1:2] 100932 100932
##   ..$ VERSAO     : num [1:2] 9 9
##   ..$ stock.type : chr [1:2] &amp;quot;ON&amp;quot; &amp;quot;PN&amp;quot;
##   ..$ stock.class: chr [1:2] &amp;quot;0&amp;quot; &amp;quot;0&amp;quot;
##   ..$ qtd.issued : num [1:2] 9.02e+08 0.00
##  $ df_stock_values            :&amp;#39;data.frame&amp;#39;: 2 obs. of  13 variables:
##   ..$ CNPJ_CIA              : chr [1:2] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot;
##   ..$ DENOM_CIA             : chr [1:2] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot;
##   ..$ DT_REFER              : Date[1:2], format: &amp;quot;2020-01-01&amp;quot; &amp;quot;2020-01-01&amp;quot;
##   ..$ CD_CVM                : num [1:2] 19615 19615
##   ..$ ID_DOC                : num [1:2] 100932 100932
##   ..$ VERSAO                : num [1:2] 9 9
##   ..$ stock.class           : chr [1:2] &amp;quot;0&amp;quot; &amp;quot;0&amp;quot;
##   ..$ stock.type            : chr [1:2] &amp;quot;ON&amp;quot; &amp;quot;PN&amp;quot;
##   ..$ max.price             : num [1:2] 12.7 0
##   ..$ min.price             : num [1:2] 7.94 0
##   ..$ avg.price             : num [1:2] 10.5 0
##   ..$ flag.missing.avg.price: logi [1:2] FALSE NA
##   ..$ qtd.issued            : num [1:2] 9.02e+08 0.00
##  $ df_mkt_value               :&amp;#39;data.frame&amp;#39;: 1 obs. of  9 variables:
##   ..$ CNPJ_CIA     : chr &amp;quot;89.850.341/0001-60&amp;quot;
##   ..$ DENOM_CIA    : chr &amp;quot;GRENDENE S.A.&amp;quot;
##   ..$ DT_REFER     : Date[1:1], format: &amp;quot;2020-01-01&amp;quot;
##   ..$ CD_CVM       : num 19615
##   ..$ ID_DOC       : num 100932
##   ..$ VERSAO       : num 9
##   ..$ mkt.avg.value: num 9.44e+09
##   ..$ mkt.min.value: num 7.16e+09
##   ..$ mkt.max.value: num 1.14e+10
##  $ df_increase_capital        :&amp;#39;data.frame&amp;#39;: 0 obs. of  0 variables
##  $ df_capital_reduction       :&amp;#39;data.frame&amp;#39;: 0 obs. of  0 variables
##  $ df_compensation            :&amp;#39;data.frame&amp;#39;: 1 obs. of  22 variables:
##   ..$ CNPJ_CIA                          : chr &amp;quot;89.850.341/0001-60&amp;quot;
##   ..$ DENOM_CIA                         : chr &amp;quot;GRENDENE S.A.&amp;quot;
##   ..$ DT_REFER                          : Date[1:1], format: &amp;quot;2020-01-01&amp;quot;
##   ..$ CD_CVM                            : num 19615
##   ..$ ID_DOC                            : num 100932
##   ..$ VERSAO                            : num 9
##   ..$ level.remuneration                : chr &amp;quot;Management Council&amp;quot;
##   ..$ qtd.members                       : num 6
##   ..$ qtd.remunerated.members           : num 6
##   ..$ total.value.remuneration          : num 1188000
##   ..$ fixed.salary                      : num 1188000
##   ..$ fixed.benefits                    : num 0
##   ..$ fixed.participations              : num 0
##   ..$ fixed.others                      : num 0
##   ..$ variable.bonus                    : num 0
##   ..$ variable.results.participation    : num 0
##   ..$ variable.meetings.participation   : num 0
##   ..$ variable.commissions.participation: num 0
##   ..$ variable.others                   : num 0
##   ..$ post.job.compensation             : num 0
##   ..$ ceasing.job.compensation          : num 0
##   ..$ stocks.options.benefits           : num 0
##  $ df_compensation_summary    :&amp;#39;data.frame&amp;#39;: 3 obs. of  13 variables:
##   ..$ CNPJ_CIA               : chr [1:3] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot;
##   ..$ DENOM_CIA              : chr [1:3] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot;
##   ..$ DT_REFER               : Date[1:3], format: &amp;quot;2020-01-01&amp;quot; &amp;quot;2020-01-01&amp;quot; ...
##   ..$ CD_CVM                 : num [1:3] 19615 19615 19615
##   ..$ ID_DOC                 : num [1:3] 100932 100932 100932
##   ..$ VERSAO                 : num [1:3] 9 9 9
##   ..$ level.remuneration     : chr [1:3] &amp;quot;Management Council&amp;quot; &amp;quot;Statutory Directors&amp;quot; &amp;quot;Fiscal Council&amp;quot;
##   ..$ qtd.members            : num [1:3] 6 3 3
##   ..$ qtd.remunerated.members: num [1:3] 6 3 3
##   ..$ max.remuneration       : num [1:3] 198000 2520995 148740
##   ..$ mean.remuneration      : num [1:3] 198000 1988385 148740
##   ..$ min.remuneration       : num [1:3] 198000 1210729 148740
##   ..$ observations           : logi [1:3] NA NA NA
##  $ df_transactions_related    :&amp;#39;data.frame&amp;#39;: 41 obs. of  17 variables:
##   ..$ CNPJ_CIA                      : chr [1:41] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; ...
##   ..$ DENOM_CIA                     : chr [1:41] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; ...
##   ..$ DT_REFER                      : Date[1:41], format: &amp;quot;2020-01-01&amp;quot; &amp;quot;2020-01-01&amp;quot; ...
##   ..$ CD_CVM                        : num [1:41] 19615 19615 19615 19615 19615 ...
##   ..$ ID_DOC                        : num [1:41] 100932 100932 100932 100932 100932 ...
##   ..$ VERSAO                        : num [1:41] 9 9 9 9 9 9 9 9 9 9 ...
##   ..$ id.transaction                : chr [1:41] &amp;quot;1944&amp;quot; &amp;quot;1945&amp;quot; &amp;quot;1946&amp;quot; &amp;quot;1947&amp;quot; ...
##   ..$ name.related.part             : chr [1:41] &amp;quot;Dall&amp;#39;Onder Viagens &amp;amp; Turismo Ltda&amp;quot; &amp;quot;Grendene UK Limited&amp;quot; &amp;quot;Grendene Italy SRL&amp;quot; &amp;quot;MHL Calçados Ltda&amp;quot; ...
##   ..$ date.transaction              : Date[1:41], format: &amp;quot;2017-12-31&amp;quot; &amp;quot;2019-12-31&amp;quot; ...
##   ..$ description.related.part      : chr [1:41] &amp;quot;Empresa pertencente a família de um dos administradores&amp;quot; &amp;quot;Empresa controlada&amp;quot; &amp;quot;Empresa controlada indireta&amp;quot; &amp;quot;Empresa controlada&amp;quot; ...
##   ..$ description.transaction       : chr [1:41] &amp;quot;Serviços de assessoria e agenciamento de viagens aéreas&amp;quot; &amp;quot;Venda de calçados para abastecimento do mercado onde a mesma está sediada&amp;quot; &amp;quot;Venda de calçados para abastecimento do mercado onde a mesma está sediada&amp;quot; &amp;quot;Venda de insumos&amp;quot; ...
##   ..$ value.transaction             : chr [1:41] &amp;quot;479000.00&amp;quot; &amp;quot;832000.00&amp;quot; &amp;quot;1605000.00&amp;quot; &amp;quot;795000.00&amp;quot; ...
##   ..$ description.guarantees        : chr [1:41] &amp;quot;Não aplicável&amp;quot; &amp;quot;Não aplicável&amp;quot; &amp;quot;Não aplicável&amp;quot; &amp;quot;Não aplicável&amp;quot; ...
##   ..$ description.transaction.period: chr [1:41] &amp;quot;Prazo indeterminado&amp;quot; &amp;quot;Prazo indeterminado&amp;quot; &amp;quot;Prazo indeterminado&amp;quot; &amp;quot;Prazo indeterminado&amp;quot; ...
##   ..$ description.rescision         : chr [1:41] &amp;quot;Encerramento das atividades&amp;quot; &amp;quot;Encerramento das atividades&amp;quot; &amp;quot;Encerramento das atividades&amp;quot; &amp;quot;Encerramento das atividades&amp;quot; ...
##   ..$ interest.rate                 : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
##   ..$ value.balance                 : chr [1:41] &amp;quot;R$ 0,00&amp;quot; &amp;quot;R$483.000,00&amp;quot; &amp;quot;R$1.318.000,00&amp;quot; &amp;quot;R$1.000,00&amp;quot; ...
##  $ df_other_events            :&amp;#39;data.frame&amp;#39;: 1 obs. of  12 variables:
##   ..$ CNPJ_CIA              : chr &amp;quot;89.850.341/0001-60&amp;quot;
##   ..$ DENOM_CIA             : chr &amp;quot;GRENDENE S.A.&amp;quot;
##   ..$ DT_REFER              : Date[1:1], format: &amp;quot;2020-01-01&amp;quot;
##   ..$ CD_CVM                : num 19615
##   ..$ ID_DOC                : num 100932
##   ..$ VERSAO                : num 9
##   ..$ approval.date         : Date[1:1], format: &amp;quot;2018-04-23&amp;quot;
##   ..$ type.event            : chr &amp;quot;Desdobramento&amp;quot;
##   ..$ qtd.ord.shares.before : num 3.01e+08
##   ..$ qtd.ord.shares.after  : num 9.02e+08
##   ..$ qtd.pref.shares.before: num 0
##   ..$ qtd.pref.shares.after : num 0
##  $ df_stock_repurchases       :&amp;#39;data.frame&amp;#39;: 4 obs. of  16 variables:
##   ..$ CNPJ_CIA                     : chr [1:4] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot;
##   ..$ DENOM_CIA                    : chr [1:4] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot;
##   ..$ DT_REFER                     : Date[1:4], format: &amp;quot;2020-01-01&amp;quot; &amp;quot;2020-01-01&amp;quot; ...
##   ..$ CD_CVM                       : num [1:4] 19615 19615 19615 19615
##   ..$ ID_DOC                       : num [1:4] 100932 100932 100932 100932
##   ..$ VERSAO                       : num [1:4] 9 9 9 9
##   ..$ date.decision                : Date[1:4], format: &amp;quot;2020-03-25&amp;quot; &amp;quot;2019-04-25&amp;quot; ...
##   ..$ date.start.repurchase        : Date[1:4], format: &amp;quot;2020-03-25&amp;quot; &amp;quot;2019-04-25&amp;quot; ...
##   ..$ date.end.repurchase          : Date[1:4], format: &amp;quot;2021-09-16&amp;quot; &amp;quot;2020-03-25&amp;quot; ...
##   ..$ available.capital.repurchase : num [1:4] 25205940 29188481 14563536 16117227
##   ..$ type.stock                   : chr [1:4] &amp;quot;Ordinária&amp;quot; &amp;quot;Ordinária&amp;quot; &amp;quot;Ordinária&amp;quot; &amp;quot;Ordinária&amp;quot;
##   ..$ qtd.stocks.repurchased       : num [1:4] 0 1467613 1312343 1185681
##   ..$ qtd.stocks.predicted         : num [1:4] 2.5e+07 6.0e+06 2.0e+06 1.5e+06
##   ..$ average.price                : num [1:4] 0 11.1 26.8 17.6
##   ..$ percent.stock.float.purchased: num [1:4] 0 24.5 65.6 79
##   ..$ percent.stock.float.predicted: chr [1:4] &amp;quot;9.220000&amp;quot; &amp;quot;2.220000&amp;quot; &amp;quot;2.380000&amp;quot; &amp;quot;1.820000&amp;quot;
##  $ df_debt_composition        :&amp;#39;data.frame&amp;#39;: 2 obs. of  13 variables:
##   ..$ CNPJ_CIA               : chr [1:2] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot;
##   ..$ DENOM_CIA              : chr [1:2] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot;
##   ..$ DT_REFER               : Date[1:2], format: &amp;quot;2020-01-01&amp;quot; &amp;quot;2020-01-01&amp;quot;
##   ..$ CD_CVM                 : num [1:2] 19615 19615
##   ..$ ID_DOC                 : num [1:2] 100932 100932
##   ..$ VERSAO                 : num [1:2] 9 9
##   ..$ type.debt              : chr [1:2] &amp;quot;Empréstimo&amp;quot; &amp;quot;Financiamento&amp;quot;
##   ..$ type.debt.guarantee    : chr [1:2] &amp;quot;Garantia Real&amp;quot; &amp;quot;Quirografárias&amp;quot;
##   ..$ debt.value.under.1.year: num [1:2] 1.04e+07 2.88e+08
##   ..$ debt.value.1.to.3.years: num [1:2] 10340527 72663044
##   ..$ debt.value.3.to.5.years: num [1:2] 0 1064371
##   ..$ debt.value.more.5.years: num [1:2] 0 0
##   ..$ debt.total             : num [1:2] 2.07e+07 3.61e+08
##  $ df_board_composition       :&amp;#39;data.frame&amp;#39;: 16 obs. of  22 variables:
##   ..$ CNPJ_CIA                : chr [1:16] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; ...
##   ..$ DENOM_CIA               : chr [1:16] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; ...
##   ..$ DT_REFER                : Date[1:16], format: &amp;quot;2020-01-01&amp;quot; &amp;quot;2020-01-01&amp;quot; ...
##   ..$ CD_CVM                  : num [1:16] 19615 19615 19615 19615 19615 ...
##   ..$ ID_DOC                  : num [1:16] 100932 100932 100932 100932 100932 ...
##   ..$ VERSAO                  : num [1:16] 9 9 9 9 9 9 9 9 9 9 ...
##   ..$ person.name             : chr [1:16] &amp;quot;Gelson Luis Rostirolla&amp;quot; &amp;quot;Rudimar Dall Onder&amp;quot; &amp;quot;Alceu Demartini de Albuquerque&amp;quot; &amp;quot;Alexandre Grendene Bartelle&amp;quot; ...
##   ..$ person.cpf              : num [1:16] 1.48e+10 2.55e+10 9.56e+10 9.87e+09 4.30e+09 ...
##   ..$ person.profession       : chr [1:16] &amp;quot;Administrador de Empresas&amp;quot; &amp;quot;Engenheiro Mecânico&amp;quot; &amp;quot;Administrador de Empresas&amp;quot; &amp;quot;Industrial&amp;quot; ...
##   ..$ person.cv               : chr [1:16] &amp;quot;Formação: Administração de Empresas (1977) e Ciências Contábeis (1979) pela UNOESC – Universidade do Oeste Cata&amp;quot;| __truncated__ &amp;quot;Formação: Engenharia Mecânica (1981) pela Universidade de Caxias do SUL (UCS). Iniciou suas atividades na Compa&amp;quot;| __truncated__ &amp;quot;Formação: Master of Business Administration. University of Illinois, conclusão julho 2019. Pós-graduado em Rela&amp;quot;| __truncated__ &amp;quot;Fundador da Companhia e Presidente do Conselho de Administração desde 18 de agosto de 2004. \n\nFormação: Bacha&amp;quot;| __truncated__ ...
##   ..$ person.dob              : Date[1:16], format: NA NA ...
##   ..$ code.type.board         : chr [1:16] &amp;quot;1&amp;quot; &amp;quot;1&amp;quot; &amp;quot;1&amp;quot; &amp;quot;2&amp;quot; ...
##   ..$ desc.type.board         : chr [1:16] &amp;quot;Director&amp;quot; &amp;quot;Director&amp;quot; &amp;quot;Director&amp;quot; &amp;quot;Management Council&amp;quot; ...
##   ..$ desc.type.board2        : logi [1:16] NA NA NA NA NA NA ...
##   ..$ code.type.job           : chr [1:16] &amp;quot;11&amp;quot; &amp;quot;10&amp;quot; &amp;quot;12&amp;quot; &amp;quot;20&amp;quot; ...
##   ..$ desc.job                : chr [1:16] &amp;quot;Não ocupa outras funções no emissor.&amp;quot; &amp;quot;Diretor Administrativo Financeiro, Membro do Comitê de Investimentos e Membro do Comitê de Partes Relacionadas&amp;quot; &amp;quot;Membro do Comitê de Investimentos e Membro do Comitê de Partes Relacionadas&amp;quot; &amp;quot;Presidente do comitê de gestão do programa de stock option e membro do Comitê de Investimentos&amp;quot; ...
##   ..$ date.election           : Date[1:16], format: &amp;quot;2019-02-14&amp;quot; &amp;quot;2019-02-14&amp;quot; ...
##   ..$ date.effective          : Date[1:16], format: &amp;quot;2019-02-14&amp;quot; &amp;quot;2019-02-14&amp;quot; ...
##   ..$ mandate.duration        : chr [1:16] &amp;quot;3 anos&amp;quot; &amp;quot;3 anos&amp;quot; &amp;quot;3 anos&amp;quot; &amp;quot;2 anos&amp;quot; ...
##   ..$ ellected.by.controller  : logi [1:16] TRUE TRUE TRUE TRUE TRUE TRUE ...
##   ..$ qtd.consecutive.mandates: num [1:16] 6 6 1 9 9 9 9 9 8 1 ...
##   ..$ percentage.participation: num [1:16] 0 0 0 100 100 100 100 100 100 0 ...
##  $ df_committee_composition   :&amp;#39;data.frame&amp;#39;: 13 obs. of  22 variables:
##   ..$ CNPJ_CIA                : chr [1:13] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; ...
##   ..$ DENOM_CIA               : chr [1:13] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; ...
##   ..$ DT_REFER                : Date[1:13], format: &amp;quot;2020-01-01&amp;quot; &amp;quot;2020-01-01&amp;quot; ...
##   ..$ CD_CVM                  : num [1:13] 19615 19615 19615 19615 19615 ...
##   ..$ ID_DOC                  : num [1:13] 100932 100932 100932 100932 100932 ...
##   ..$ VERSAO                  : num [1:13] 9 9 9 9 9 9 9 9 9 9 ...
##   ..$ person.name             : chr [1:13] &amp;quot;Carlos Augusto Leone Piani&amp;quot; &amp;quot;Alceu Demartini de Albuquerque&amp;quot; &amp;quot;Rudimar Dall Onder&amp;quot; &amp;quot;Rafael Vieira Grazziotin&amp;quot; ...
##   ..$ person.cpf              : num [1:13] 2.53e+09 9.56e+10 2.55e+10 7.00e+10 3.54e+10 ...
##   ..$ person.profession       : chr [1:13] &amp;quot;Administrador de Empresas&amp;quot; &amp;quot;Administrador de Empresas&amp;quot; &amp;quot;Engenheiro Mecânico&amp;quot; &amp;quot;Advogado&amp;quot; ...
##   ..$ person.cv               : chr [1:13] &amp;quot;O Sr. Carlos Augusto Leone Piani é presidente da divisão canadense da Kraft Heinz Company, tendo sido diretor d&amp;quot;| __truncated__ &amp;quot;Formação: Master of Business Administration. University of Illinois, conclusão julho 2019. Pós-graduado em Rela&amp;quot;| __truncated__ &amp;quot;Formação: Engenharia Mecânica (1981) pela Universidade de Caxias do SUL (UCS). Iniciou suas atividades na Compa&amp;quot;| __truncated__ &amp;quot;O Sr. Rafael Vieira Grazziotin, advogado graduado pela Universidade de Caxias do Sul, com pós graduação em Dire&amp;quot;| __truncated__ ...
##   ..$ person.dob              : Date[1:13], format: NA NA ...
##   ..$ code.type.committee     : chr [1:13] &amp;quot;9&amp;quot; &amp;quot;9&amp;quot; &amp;quot;9&amp;quot; &amp;quot;9&amp;quot; ...
##   ..$ desc.type.committee     : chr [1:13] &amp;quot;Other Committee&amp;quot; &amp;quot;Other Committee&amp;quot; &amp;quot;Other Committee&amp;quot; &amp;quot;Other Committee&amp;quot; ...
##   ..$ code.type.job           : chr [1:13] &amp;quot;3&amp;quot; &amp;quot;3&amp;quot; &amp;quot;3&amp;quot; &amp;quot;3&amp;quot; ...
##   ..$ desc.committee          : chr [1:13] &amp;quot;Comitê de Investimentos&amp;quot; &amp;quot;Comitê de Partes Relacionadas&amp;quot; &amp;quot;Comitê de Partes Relacionadas&amp;quot; &amp;quot;Comitê de Partes Relacionadas&amp;quot; ...
##   ..$ desc.job                : chr [1:13] &amp;quot;Não ocupa outros cargos/funções no emissor.&amp;quot; &amp;quot;Diretor de Relações com Investidores e Membro do Comitê de Investimentos&amp;quot; &amp;quot;Diretor Presidente, Diretor Administrativo Financeiro, Membro do Comitê de Investimentos&amp;quot; &amp;quot;Não ocupa outros cargos/funções no emissor.&amp;quot; ...
##   ..$ date.election           : Date[1:13], format: &amp;quot;2020-08-13&amp;quot; &amp;quot;2020-08-13&amp;quot; ...
##   ..$ date.effective          : Date[1:13], format: &amp;quot;2020-08-13&amp;quot; &amp;quot;2020-08-13&amp;quot; ...
##   ..$ mandate.duration        : chr [1:13] &amp;quot;3 anos&amp;quot; &amp;quot;2 anos&amp;quot; &amp;quot;2 anos&amp;quot; &amp;quot;2 anos&amp;quot; ...
##   ..$ qtd.consecutive.mandates: num [1:13] 1 1 1 1 1 1 1 1 1 1 ...
##   ..$ percentage.participation: num [1:13] 100 100 100 100 100 100 100 100 100 100 ...
##   ..$ other.committes         : chr [1:13] &amp;quot;Comitê de Investimentos&amp;quot; &amp;quot;Comitê de Partes Relacionadas&amp;quot; &amp;quot;Comitê de Partes Relacionadas&amp;quot; &amp;quot;Comitê de Partes Relacionadas&amp;quot; ...
##  $ df_family_relations        :&amp;#39;data.frame&amp;#39;: 6 obs. of  14 variables:
##   ..$ CNPJ_CIA           : chr [1:6] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; ...
##   ..$ DENOM_CIA          : chr [1:6] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; ...
##   ..$ DT_REFER           : Date[1:6], format: &amp;quot;2020-01-01&amp;quot; &amp;quot;2020-01-01&amp;quot; ...
##   ..$ CD_CVM             : num [1:6] 19615 19615 19615 19615 19615 ...
##   ..$ ID_DOC             : num [1:6] 100932 100932 100932 100932 100932 ...
##   ..$ VERSAO             : num [1:6] 9 9 9 9 9 9
##   ..$ person.name        : chr [1:6] &amp;quot;Pedro Grendene Bartelle&amp;quot; &amp;quot;Alexandre Grendene Bartelle&amp;quot; &amp;quot;Pedro Grendene Bartelle&amp;quot; &amp;quot;Pedro Grendene Bartelle&amp;quot; ...
##   ..$ person.cpf         : num [1:6] 9.86e+09 9.87e+09 9.86e+09 9.86e+09 9.86e+09 ...
##   ..$ person.job         : chr [1:6] &amp;quot;Vice Presidente do Conselho de Administração&amp;quot; &amp;quot;Presidente do Conselho de Administração&amp;quot; &amp;quot;Vice Presidente do Conselho de Administração&amp;quot; &amp;quot;Vice Presidente do Conselho de Administração&amp;quot; ...
##   ..$ related.person.name: chr [1:6] &amp;quot;Alexandre Grendene Bartelle&amp;quot; &amp;quot;Pedro Grendene Bartelle&amp;quot; &amp;quot;Pedro Bartelle&amp;quot; &amp;quot;Giovana Bartelle Velloso&amp;quot; ...
##   ..$ related.person.cpf : num [1:6] 9.87e+09 9.86e+09 6.86e+10 6.86e+10 3.54e+10 ...
##   ..$ related.person.job : chr [1:6] &amp;quot;Presidente do Conselho de Administração&amp;quot; &amp;quot;Vice Presidente do Conselho de Administração&amp;quot; &amp;quot;Acionista&amp;quot; &amp;quot;Acionista&amp;quot; ...
##   ..$ code.relationship  : chr [1:6] &amp;quot;2&amp;quot; &amp;quot;2&amp;quot; &amp;quot;3&amp;quot; &amp;quot;3&amp;quot; ...
##   ..$ desc.relationship  : chr [1:6] &amp;quot;Irmão ou Irmã (1º grau por consangüinidade)&amp;quot; &amp;quot;Irmão ou Irmã (1º grau por consangüinidade)&amp;quot; &amp;quot;Filho ou Filha (1º grau por consangüinidade)&amp;quot; &amp;quot;Filho ou Filha (1º grau por consangüinidade)&amp;quot; ...
##  $ df_family_related_companies:&amp;#39;data.frame&amp;#39;: 15 obs. of  15 variables:
##   ..$ CNPJ_CIA            : chr [1:15] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; ...
##   ..$ DENOM_CIA           : chr [1:15] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; ...
##   ..$ DT_REFER            : Date[1:15], format: &amp;quot;2020-01-01&amp;quot; &amp;quot;2020-01-01&amp;quot; ...
##   ..$ CD_CVM              : num [1:15] 19615 19615 19615 19615 19615 ...
##   ..$ ID_DOC              : num [1:15] 100932 100932 100932 100932 100932 ...
##   ..$ VERSAO              : num [1:15] 9 9 9 9 9 9 9 9 9 9 ...
##   ..$ person.name         : chr [1:15] &amp;quot;Pedro Grendene Bartelle&amp;quot; &amp;quot;Pedro Grendene Bartelle&amp;quot; &amp;quot;Maílson Ferreira da Nóbrega&amp;quot; &amp;quot;Renato Ochman&amp;quot; ...
##   ..$ person.cpf          : num [1:15] 9.86e+09 9.86e+09 4.30e+09 3.76e+10 3.76e+10 ...
##   ..$ person.job          : chr [1:15] &amp;quot;Vice-Presidente do Conselho de Administração&amp;quot; &amp;quot;Vice-Presidente do Conselho de Administração&amp;quot; &amp;quot;Conselheiro de Administração&amp;quot; &amp;quot;Conselheiro de Administração&amp;quot; ...
##   ..$ type.related.person : chr [1:15] &amp;quot;Cliente&amp;quot; &amp;quot;Cliente&amp;quot; &amp;quot;Fornecedor&amp;quot; &amp;quot;Fornecedor&amp;quot; ...
##   ..$ type.relationship   : chr [1:15] &amp;quot;Controle&amp;quot; &amp;quot;Controle&amp;quot; &amp;quot;Controle&amp;quot; &amp;quot;Controle&amp;quot; ...
##   ..$ observations        : chr [1:15] &amp;quot;Venda de insumos e matrizes - Prazo médio de recebimento 21 dias&amp;quot; &amp;quot;Venda de matrizes - Prazo médio de recebimento 43 dias&amp;quot; &amp;quot;Assessoria&amp;quot; &amp;quot;Assessoria&amp;quot; ...
##   ..$ related.company.name: chr [1:15] &amp;quot;Vulcabras|azaleia – CE, Calçados e Artigos Esportivos S.A.&amp;quot; &amp;quot;Vulcabras|azaleia – BA, Calçados e Artigos Esportivos S.A.&amp;quot; &amp;quot;Mailson da Nóbrega Consultoria S/C Ltda&amp;quot; &amp;quot;Ochman, Real Amadeo Advogados Associados&amp;quot; ...
##   ..$ related.company.cnpj: num [1:15] 9.54e+11 7.34e+11 1.58e+12 6.24e+13 6.24e+13 ...
##   ..$ related.company.job : chr [1:15] &amp;quot;Acionista Controlador&amp;quot; &amp;quot;Acionista controlador&amp;quot; &amp;quot;Sócio proprietário&amp;quot; &amp;quot;Sócio proprietário&amp;quot; ...
##  $ df_auditing                :&amp;#39;data.frame&amp;#39;: 1 obs. of  14 variables:
##   ..$ CNPJ_CIA                  : chr &amp;quot;89.850.341/0001-60&amp;quot;
##   ..$ DENOM_CIA                 : chr &amp;quot;GRENDENE S.A.&amp;quot;
##   ..$ DT_REFER                  : Date[1:1], format: &amp;quot;2020-01-01&amp;quot;
##   ..$ CD_CVM                    : num 19615
##   ..$ ID_DOC                    : num 100932
##   ..$ VERSAO                    : num 9
##   ..$ auditor.name              : chr &amp;quot;Ernst &amp;amp; Young Auditores Independentes S/S&amp;quot;
##   ..$ auditor.cnpj              : chr &amp;quot;61366936001105&amp;quot;
##   ..$ contract.first.date       : Date[1:1], format: NA
##   ..$ contract.last.date        : Date[1:1], format: NA
##   ..$ description.contract      : chr &amp;quot;Revisão dos ITR&amp;#39;s (controladora e Consolidado) e auditoria anual de balanço da Controladora e Consolidado.&amp;quot;
##   ..$ compensation              : chr &amp;quot;Para o exercício encerrado em 31/12/2017 - R$409,2 mil, referente a serviços de auditoria prestados e R$131,1 m&amp;quot;| __truncated__
##   ..$ justification.substitution: logi NA
##   ..$ reason.discordance        : logi NA
##  $ df_responsible_docs        :&amp;#39;data.frame&amp;#39;: 2 obs. of  9 variables:
##   ..$ CNPJ_CIA   : chr [1:2] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot;
##   ..$ DENOM_CIA  : chr [1:2] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot;
##   ..$ DT_REFER   : Date[1:2], format: &amp;quot;2020-01-01&amp;quot; &amp;quot;2020-01-01&amp;quot;
##   ..$ CD_CVM     : num [1:2] 19615 19615
##   ..$ ID_DOC     : num [1:2] 100932 100932
##   ..$ VERSAO     : num [1:2] 9 9
##   ..$ person.cod : chr [1:2] &amp;quot;50&amp;quot; &amp;quot;51&amp;quot;
##   ..$ person.name: chr [1:2] &amp;quot;Rudimar Dall Onder&amp;quot; &amp;quot;Alceu Demartini de Albuquerque&amp;quot;
##   ..$ person.job : chr [1:2] &amp;quot;Diretor Presidente&amp;quot; &amp;quot;Diretor de Relações com Investidores&amp;quot;
##  $ df_stocks_details          :&amp;#39;data.frame&amp;#39;: 1 obs. of  16 variables:
##   ..$ CNPJ_CIA           : chr &amp;quot;89.850.341/0001-60&amp;quot;
##   ..$ DENOM_CIA          : chr &amp;quot;GRENDENE S.A.&amp;quot;
##   ..$ DT_REFER           : Date[1:1], format: &amp;quot;2020-01-01&amp;quot;
##   ..$ CD_CVM             : num 19615
##   ..$ ID_DOC             : num 100932
##   ..$ VERSAO             : num 9
##   ..$ type.stock.id      : chr &amp;quot;1&amp;quot;
##   ..$ type.stock.text    : chr &amp;quot;Ordinária&amp;quot;
##   ..$ tag.along          : num 100
##   ..$ preferential.code  : chr &amp;quot;0&amp;quot;
##   ..$ preferential.text  : logi NA
##   ..$ dividend.text      : chr &amp;quot;Conforme o Estatuto Social da Companhia, art.32, os acionistas fazem jus a dividendo obrigatório anual equivale&amp;quot;| __truncated__
##   ..$ flag.voting.rights : chr &amp;quot;1&amp;quot;
##   ..$ flag.voting.text   : chr &amp;quot;Pleno&amp;quot;
##   ..$ flag.conversibility: chr &amp;quot;Não&amp;quot;
##   ..$ other.info.text    : chr &amp;quot;Não existem características relevantes adicionais.&amp;quot;
##  $ df_dividends_details       :&amp;#39;data.frame&amp;#39;: 1 obs. of  11 variables:
##   ..$ CNPJ_CIA            : chr &amp;quot;89.850.341/0001-60&amp;quot;
##   ..$ DENOM_CIA           : chr &amp;quot;GRENDENE S.A.&amp;quot;
##   ..$ DT_REFER            : Date[1:1], format: &amp;quot;2020-01-01&amp;quot;
##   ..$ CD_CVM              : num 19615
##   ..$ ID_DOC              : num 100932
##   ..$ VERSAO              : num 9
##   ..$ net.profit          : num 4.95e+08
##   ..$ distributed.dividend: num 2.76e+08
##   ..$ retained.profit     : num 2.19e+08
##   ..$ payout              : num 55.7
##   ..$ div.yeild.on.equity : num 14.3
##  $ df_intangible_details      :&amp;#39;data.frame&amp;#39;: 13 obs. of  10 variables:
##   ..$ CNPJ_CIA   : chr [1:13] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; ...
##   ..$ DENOM_CIA  : chr [1:13] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; ...
##   ..$ DT_REFER   : Date[1:13], format: &amp;quot;2020-01-01&amp;quot; &amp;quot;2020-01-01&amp;quot; ...
##   ..$ CD_CVM     : num [1:13] 19615 19615 19615 19615 19615 ...
##   ..$ ID_DOC     : num [1:13] 100932 100932 100932 100932 100932 ...
##   ..$ VERSAO     : num [1:13] 9 9 9 9 9 9 9 9 9 9 ...
##   ..$ id         : num [1:13] 1033 1034 1035 1036 1037 ...
##   ..$ id.type    : num [1:13] 2 2 2 2 2 2 2 2 2 2 ...
##   ..$ patent.desc: chr [1:13] &amp;quot;Mel&amp;quot; &amp;quot;Nuar&amp;quot; &amp;quot;Pega Forte&amp;quot; &amp;quot;Galeria Melissa&amp;quot; ...
##   ..$ duration   : Date[1:13], format: NA NA ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>GetDFPData2 available in CRAN!</title>
      <link>https://www.msperlin.com/post/2021-04-02-getdfpdata2-on-cran/</link>
      <pubDate>Fri, 02 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2021-04-02-getdfpdata2-on-cran/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;After testing the package extensivelly, &lt;code&gt;GetDFPData2&lt;/code&gt; is finally available in CRAN. &lt;code&gt;GetDFPData2&lt;/code&gt; is the second and backwards incompatible version of &lt;code&gt;GetDPFData&lt;/code&gt;, a R package for downloading annual financial reports from B3, the Brazilian financial exchange. Unlike its first iteration, &lt;code&gt;GetDFPData2&lt;/code&gt; imports data using a database of csv files from &lt;a href=&#34;http://dados.cvm.gov.br/dados/CIA_ABERTA/&#34;&gt;CVM&lt;/a&gt;, which makes it execution much faster than its predecessor. However, the output is slightly different.&lt;/p&gt;
&lt;p&gt;A shiny app – web interface – is also available at &lt;a href=&#34;https://www.msperlin.com/shiny/GetDFPData2/&#34;&gt;https://www.msperlin.com/shiny/GetDFPData2/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The previous version, &lt;code&gt;GetDFPData&lt;/code&gt;, is deprecated and will not be developed any further. &lt;a href=&#34;https://www.msperlin.com/post/2020-07-18-new_packages-getfredata-getdfpdata2/&#34;&gt;All efforts&lt;/a&gt; goes to &lt;code&gt;GetDFPData2&lt;/code&gt; and &lt;code&gt;GetFREData&lt;/code&gt; (soon in CRAN).&lt;/p&gt;
&lt;div id=&#34;installation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Installation&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# available in cran (stable)
install.packages(&amp;#39;GetDFPData2&amp;#39;)

# github (dev version)
devtools::install_github(&amp;#39;msperlin/GetDFPData2&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;examples-of-usage&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Examples of Usage&lt;/h1&gt;
&lt;div id=&#34;information-about-available-companies&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Information about available companies&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(GetDFPData2)

# information about companies
df_info &amp;lt;- get_info_companies(tempdir())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Fetching info on B3 companies&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Dowloading file from CVM&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  File not found, downloading it..&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Success&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Reading file from CVM&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Saving cache data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Got 2331 lines for 2290 companies [Actives = 648 Inactives = 1653]&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(df_info )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2,331 x 44
##    CD_CVM DENOM_SOCIAL    DENOM_COMERC   SETOR_ATIV  PF_PJ CNPJ  DT_REG DT_CONST
##     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;           &amp;lt;chr&amp;gt;          &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;   
##  1  25224 2W ENERGIA S.A. &amp;lt;NA&amp;gt;           Construção… PJ    8773… 29/10… 23/03/2…
##  2  21954 3A COMPANHIA S… TRIPLO A  COM… Securitiza… PJ    1139… 08/03… 03/11/2…
##  3  25291 3R PETROLEUM O… &amp;lt;NA&amp;gt;           Petróleo e… PJ    1209… 09/11… 08/06/2…
##  4  16330 521 PARTICIPAÇ… 521 PARTICIPA… Emp. Adm. … PJ    1547… 11/07… 30/07/1…
##  5  16284 524 PARTICIPAÇ… 524 PARTICIPA… Emp. Adm. … PJ    1851… 30/05… 02/04/1…
##  6  16349 525 PARTICIPAÇ… 525 PARTICIPA… Emp. Adm. … PJ    1919… 16/07… 02/04/1…
##  7     35 A J RENNER SA … A J RENNER     Emp. Adm. … PJ    9265… 24/06… &amp;lt;NA&amp;gt;    
##  8  16802 A.P. PARTICIPA… A.P. PARTICIP… Emp. Adm. … PJ    2288… 21/01… 14/12/1…
##  9  13307 ABC DADOS E IN… ABC COMPUTADO… Máquinas, … PJ    2164… 03/06… &amp;lt;NA&amp;gt;    
## 10  16934 ABC SUPERMERCA… ABC SUPERMERC… Comércio (… PJ    2258… 27/02… 30/09/1…
## # … with 2,321 more rows, and 36 more variables: DT_CANCEL &amp;lt;chr&amp;gt;,
## #   MOTIVO_CANCEL &amp;lt;chr&amp;gt;, SIT_REG &amp;lt;chr&amp;gt;, DT_INI_SIT &amp;lt;chr&amp;gt;, SIT_EMISSOR &amp;lt;chr&amp;gt;,
## #   DT_INI_SIT_EMISSOR &amp;lt;chr&amp;gt;, CATEG_REG &amp;lt;chr&amp;gt;, DT_INI_CATEG &amp;lt;chr&amp;gt;,
## #   AUDITOR &amp;lt;chr&amp;gt;, CNPJ_AUDITOR &amp;lt;dbl&amp;gt;, TP_ENDER &amp;lt;chr&amp;gt;, LOGRADOURO &amp;lt;chr&amp;gt;,
## #   COMPL &amp;lt;chr&amp;gt;, BAIRRO &amp;lt;chr&amp;gt;, CIDADE &amp;lt;chr&amp;gt;, UF &amp;lt;chr&amp;gt;, PAIS &amp;lt;chr&amp;gt;,
## #   CD_POSTAL &amp;lt;lgl&amp;gt;, TEL &amp;lt;chr&amp;gt;, FAX &amp;lt;chr&amp;gt;, EMAIL &amp;lt;chr&amp;gt;, TP_RESP &amp;lt;chr&amp;gt;,
## #   RESP &amp;lt;chr&amp;gt;, DT_INI_RESP &amp;lt;chr&amp;gt;, LOGRADOURO_RESP &amp;lt;chr&amp;gt;, COMPL_RESP &amp;lt;chr&amp;gt;,
## #   BAIRRO_RESP &amp;lt;chr&amp;gt;, CIDADE_RESP &amp;lt;chr&amp;gt;, UF_RESP &amp;lt;chr&amp;gt;, PAIS_RESP &amp;lt;chr&amp;gt;,
## #   CEP_RESP &amp;lt;dbl&amp;gt;, TEL_RESP &amp;lt;chr&amp;gt;, FAX_RESP &amp;lt;chr&amp;gt;, EMAIL_RESP &amp;lt;chr&amp;gt;,
## #   TP_MERC &amp;lt;chr&amp;gt;, cnpj_number &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;searching-for-companies&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Searching for companies&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;search_company(&amp;#39;grendene&amp;#39;, cache_folder = tempdir())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Fetching info on B3 companies&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Found cache file. Loading data..&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Got 2331 lines for 2290 companies [Actives = 648 Inactives = 1653]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Found 1 companies:&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## GRENDENE SA | situation = ATIVO | sector = Têxtil e Vestuário | CD_CVM = 19615&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;downloading-annual-financial-reports&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Downloading Annual Financial Reports&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# downloading DFP data
l_dfp &amp;lt;- get_dfp_data(companies_cvm_codes = 19615, 
                      use_memoise = FALSE,
                      clean_data = TRUE,
                      cache_folder = tempdir(), # use local folder in live code
                      type_docs = c(&amp;#39;DRE&amp;#39;), 
                      type_format = &amp;#39;con&amp;#39;,
                      first_year = 2019, 
                      last_year = 2020)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Dowloading dfp_cia_aberta_2019.zip&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  File not found, downloading it..&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Success&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Unzipping&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Reading dfp_cia_aberta_DRE_con_2019.csv | Cleaning table
##      Got 30 rows | 1 companies
##  Dowloading dfp_cia_aberta_2020.zip
##  File not found, downloading it..
##  Success
##      Unzipping
##      Reading dfp_cia_aberta_DRE_con_2020.csv | Cleaning table
##      Got 32 rows | 1 companies&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(l_dfp)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 1
##  $ DF Consolidado - Demonstração do Resultado: tibble[,16] [62 × 16] (S3: tbl_df/tbl/data.frame)
##   ..$ CNPJ_CIA    : chr [1:62] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; ...
##   ..$ CD_CVM      : num [1:62] 19615 19615 19615 19615 19615 ...
##   ..$ DT_REFER    : Date[1:62], format: &amp;quot;2019-12-31&amp;quot; &amp;quot;2019-12-31&amp;quot; ...
##   ..$ DT_INI_EXERC: Date[1:62], format: &amp;quot;2019-01-01&amp;quot; &amp;quot;2019-01-01&amp;quot; ...
##   ..$ DT_FIM_EXERC: Date[1:62], format: &amp;quot;2019-12-31&amp;quot; &amp;quot;2019-12-31&amp;quot; ...
##   ..$ DENOM_CIA   : chr [1:62] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; ...
##   ..$ VERSAO      : num [1:62] 2 2 2 2 2 2 2 2 2 2 ...
##   ..$ GRUPO_DFP   : chr [1:62] &amp;quot;DF Consolidado - Demonstração do Resultado&amp;quot; &amp;quot;DF Consolidado - Demonstração do Resultado&amp;quot; &amp;quot;DF Consolidado - Demonstração do Resultado&amp;quot; &amp;quot;DF Consolidado - Demonstração do Resultado&amp;quot; ...
##   ..$ MOEDA       : chr [1:62] &amp;quot;REAL&amp;quot; &amp;quot;REAL&amp;quot; &amp;quot;REAL&amp;quot; &amp;quot;REAL&amp;quot; ...
##   ..$ ESCALA_MOEDA: chr [1:62] &amp;quot;MIL&amp;quot; &amp;quot;MIL&amp;quot; &amp;quot;MIL&amp;quot; &amp;quot;MIL&amp;quot; ...
##   ..$ ORDEM_EXERC : chr [1:62] &amp;quot;ÚLTIMO&amp;quot; &amp;quot;ÚLTIMO&amp;quot; &amp;quot;ÚLTIMO&amp;quot; &amp;quot;ÚLTIMO&amp;quot; ...
##   ..$ CD_CONTA    : chr [1:62] &amp;quot;3.01&amp;quot; &amp;quot;3.02&amp;quot; &amp;quot;3.03&amp;quot; &amp;quot;3.04&amp;quot; ...
##   ..$ DS_CONTA    : chr [1:62] &amp;quot;Receita de Venda de Bens e/ou Serviços&amp;quot; &amp;quot;Custo dos Bens e/ou Serviços Vendidos&amp;quot; &amp;quot;Resultado Bruto&amp;quot; &amp;quot;Despesas/Receitas Operacionais&amp;quot; ...
##   ..$ VL_CONTA    : num [1:62] 2071034 -1126511 944523 -590995 -530825 ...
##   ..$ COLUNA_DF   : logi [1:62] NA NA NA NA NA NA ...
##   ..$ source_file : chr [1:62] &amp;quot;dfp_cia_aberta_DRE_con_2019.csv&amp;quot; &amp;quot;dfp_cia_aberta_DRE_con_2019.csv&amp;quot; &amp;quot;dfp_cia_aberta_DRE_con_2019.csv&amp;quot; &amp;quot;dfp_cia_aberta_DRE_con_2019.csv&amp;quot; ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A clever bash script for R Users</title>
      <link>https://www.msperlin.com/post/2021-03-23-ultimate-bash-script/</link>
      <pubDate>Tue, 23 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2021-03-23-ultimate-bash-script/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Back in 2017 I wrote a &lt;a href=&#34;https://www.r-craft.org/r-news/simple-bash-script-for-a-fresh-install-of-r-and-its-dependencies-in-linux/&#34;&gt;blog post&lt;/a&gt; describing a simple bash script for installing R in a Ubuntu setup. The problem with this script, and many others found in the internet, is that they quickly become &lt;strong&gt;obsolete&lt;/strong&gt; due to changes in Ubuntu, R and RStudio. For example, if Ubuntu version changes from “trusty” to “focal”, the link to the CRAN ppa also changes. The same is true with RStudio, which does not provide installation by apt, only downloadable .deb files from its &lt;a href=&#34;https://rstudio.com/products/rstudio/download/&#34;&gt;website&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Today I manage to develop a clever &lt;a href=&#34;https://github.com/msperlin/UBUNTU-Fresh-Install/&#34;&gt;bash script&lt;/a&gt; that uses the internet and local files to find out the current version of all software. Using three different methods – apt, snap and custom bash scripts – the script installs all required software in its latest version. The script also installs &lt;strong&gt;R packages&lt;/strong&gt; set in a .txt file and configures RStudio to a dark theme. The best part is that all code is &lt;strong&gt;modular&lt;/strong&gt; and you can easily customize your installs by changing .txt files in each sub-folder.&lt;/p&gt;
&lt;p&gt;You can find the bash script in &lt;a href=&#34;https://github.com/msperlin/UBUNTU-Fresh-Install&#34;&gt;https://github.com/msperlin/UBUNTU-Fresh-Install&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;how-to-use-it&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How to use it&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Download the github repository as a &lt;a href=&#34;https://github.com/msperlin/UBUNTU-Fresh-Install/archive/refs/heads/main.zip&#34;&gt;zip file&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Unpack the zip file and check all .txt files in all sub-folders. Remove or add software/R packages as needed.&lt;/li&gt;
&lt;li&gt;Within a terminal, execute the main script:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;./UBUNTU_Install-Bash.sh&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;type your sudo password and wait…&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;installed-software&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Installed Software&lt;/h1&gt;
&lt;p&gt;The bash script includes the following software:&lt;/p&gt;
&lt;div id=&#34;using-apt&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using apt&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;libreoffice (&lt;a href=&#34;https://www.libreoffice.org/&#34;&gt;lastest&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;texstudio (&lt;a href=&#34;https://www.texstudio.org/&#34;&gt;latest&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;obstudio (&lt;a href=&#34;https://obsproject.com/wiki/install-instructions#linux&#34;&gt;latest&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;many others (see file &lt;code&gt;apt-to-install/list_to_install.txt)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;using-custom-bash-scripts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using custom bash scripts&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;R (&lt;a href=&#34;https://www.r-project.org/&#34;&gt;latest&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;R Packages
&lt;ul&gt;
&lt;li&gt;See file &lt;code&gt;R-pkgs/pkgs_to_install.txt&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;RStudio (&lt;a href=&#34;https://rstudio.com/&#34;&gt;latest&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;RStudio configuration – color scheme, size font, .. (see file &lt;code&gt;Rstudio-Config/my-rstudio-prefs.json&lt;/code&gt;). You can get your own Rstudio preference file locally at &lt;code&gt;~/.config/rstudio/rstudio-pref.json&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Google Chrome (&lt;a href=&#34;https://www.google.com/chrome/&#34;&gt;latest&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;using-snap&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using snap&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Microsoft code (&lt;a href=&#34;https://snapcraft.io/code&#34;&gt;latest by snap&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;generating-r-package-list&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Generating R package list&lt;/h1&gt;
&lt;p&gt;You can generate your own list of used R packages based on your existing code. For that, use the R code below, which will scan your files and retrieve all calls to existing packages. Do notice you’ll need to change the base folder in &lt;code&gt;renv::dependencies&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(dplyr)

my_r_dir &amp;lt;- &amp;#39;YOUR-FOLDER-HERE&amp;#39;
df &amp;lt;- renv::dependencies(my_r_dir)

n_to_colect &amp;lt;- 50 # number of pkgs to collect (most to least frequent)

tbl_pkgs &amp;lt;- df %&amp;gt;%
  group_by(Package) %&amp;gt;%
  count() %&amp;gt;%
  arrange(-n) %&amp;gt;%
  #view() %&amp;gt;%
  ungroup() %&amp;gt;%
  slice(1:n_to_colect)

tbl_pkgs&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>bookdown &#43; exams &#43; webex</title>
      <link>https://www.msperlin.com/post/2021-03-18-bookdown_and_exams/</link>
      <pubDate>Thu, 18 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2021-03-18-bookdown_and_exams/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;It’s been three years since I’ve been using package &lt;code&gt;bookdown&lt;/code&gt; for compiling and distributing &lt;a href=&#34;https://www.msperlin.com/publication/#5&#34;&gt;three different books&lt;/a&gt; in Amazon and the &lt;a href=&#34;https://www.msperlin.com/afedR/&#34;&gt;web&lt;/a&gt;. It helped me greatly in all my book projects and I’m always &lt;strong&gt;grateful&lt;/strong&gt; to Yihui Xie for providing such a useful tool at the &lt;a href=&#34;https://www.msperlin.com/post/2017-02-16-writing-a-book/&#34;&gt;right time&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;However, &lt;code&gt;bookdown&lt;/code&gt; offers no support for chapter exercises of any sort. While you can write exercises in plain RMarkdown, it is not a good solution for a long term project such as a technical book. When writing the latest edition of &lt;a href=&#34;https://www.msperlin.com/afedR/&#34;&gt;Analyzing Financial and Economical Data with R&lt;/a&gt;, I aimed for a work cycle where the 100 plus exercises and their solutions were reproducible and easier to maintain.&lt;/p&gt;
&lt;p&gt;Meanwhile, package &lt;code&gt;exams&lt;/code&gt; provides a &lt;a href=&#34;http://www.r-exams.org/&#34;&gt;framework&lt;/a&gt; to produce exercises in a reproducible setup, making it possible to export the exercises to any given format such as pdf or html, or even &lt;em&gt;e-learning&lt;/em&gt; platforms such as Moodle and Blackboard. I use &lt;code&gt;exams&lt;/code&gt; extensively in all my university classes and it works like a charm!&lt;/p&gt;
&lt;p&gt;So, while writing afedR, I worked towards finding a way to bring the two technologies closer to each other, which is what I’ll report in this blog post. Here are the main advantages of this setup:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The content of book exercises, their solution and explanation in a single location (no more fidling with different folders).&lt;/li&gt;
&lt;li&gt;Dynamic output for html, with buttons and solutions available at a single click.&lt;/li&gt;
&lt;li&gt;Exportable exercises for classes (see this &lt;a href=&#34;https://www.msperlin.com/post/2021-02-28-dynamic-exercises-afedr/&#34;&gt;blog post&lt;/a&gt;). You can export the same exercises to pdf or Moodle, for example.&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;bookdown-exams-webex&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;bookdown&lt;/code&gt; + &lt;code&gt;exams&lt;/code&gt; + &lt;code&gt;webex&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;First and foremost, the main part of the hack is to realize that any exercises in a .Rmd file &lt;a href=&#34;https://stackoverflow.com/questions/62315622/using-r-exams-in-bookdown-document-especially-for-html-output/66012008#66012008&#34;&gt;can be broken&lt;/a&gt; into a list using &lt;code&gt;exams::xexams&lt;/code&gt;. Let’s use an example from the book, with the first three exercises of chapter 01:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# example from book 
afedR::copy_book_files(path_to_copy = tempdir())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Copying data files files to /tmp/RtmpIs4EpM/afedR files/data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  37 files copied&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Copying end-of-chapter (eoc) exercises with solutions to /tmp/RtmpIs4EpM/afedR files/eoc-exercises/&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  99 files copied&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Copying R code to /tmp/RtmpIs4EpM/afedR files/R-code&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  15 files copied&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# temp folder with exercises
eoc_dir &amp;lt;- file.path(tempdir(), &amp;#39;afedR files/eoc-exercises/&amp;#39;)

# select exercises
my_exercises &amp;lt;- list.files(eoc_dir, pattern = &amp;#39;*.Rmd&amp;#39;, full.names = TRUE)
my_exercises &amp;lt;- my_exercises[1:3]

# break it down
my_l &amp;lt;- exams::xexams(my_exercises)

# check it
dplyr::glimpse(my_l)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 1
##  $ exam1:List of 3
##   ..$ exercise1:List of 6
##   .. ..$ question    : chr [1:3] &amp;quot;&amp;quot; &amp;quot;The R language was developed based on what other programming language?&amp;quot; &amp;quot;&amp;quot;
##   .. ..$ questionlist: chr [1:5] &amp;quot;C++&amp;quot; &amp;quot;Python&amp;quot; &amp;quot;Julia&amp;quot; &amp;quot;Javascript&amp;quot; ...
##   .. ..$ solution    : chr [1:2] &amp;quot;&amp;quot; &amp;quot;Straight from the book, section **What is R**: \&amp;quot;R is a modern version of S, a programming language originally &amp;quot;| __truncated__
##   .. ..$ solutionlist: NULL
##   .. ..$ metainfo    :List of 18
##   .. ..$ supplements : Named chr(0) 
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr(0) 
##   .. .. ..- attr(*, &amp;quot;dir&amp;quot;)= chr &amp;quot;/tmp/RtmpIs4EpM/file4e094f974499/exam1/exercise1&amp;quot;
##   ..$ exercise2:List of 6
##   .. ..$ question    : chr [1:3] &amp;quot;&amp;quot; &amp;quot;What are the names of the two authors of R?&amp;quot; &amp;quot;&amp;quot;
##   .. ..$ questionlist: chr [1:5] &amp;quot;Linus Torvalds and Richard Stallman&amp;quot; &amp;quot;John Chambers and Robert Engle&amp;quot; &amp;quot;Roger Federer and Rafael Nadal&amp;quot; &amp;quot;Guido van Rossum and Bjarne Stroustrup&amp;quot; ...
##   .. ..$ solution    : chr [1:3] &amp;quot;&amp;quot; &amp;quot;Straight from the book: \&amp;quot;... The base code of R was developed by two academics, **Ross Ihaka** and **Robert Ge&amp;quot;| __truncated__ &amp;quot;&amp;quot;
##   .. ..$ solutionlist: NULL
##   .. ..$ metainfo    :List of 18
##   .. ..$ supplements : Named chr(0) 
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr(0) 
##   .. .. ..- attr(*, &amp;quot;dir&amp;quot;)= chr &amp;quot;/tmp/RtmpIs4EpM/file4e094f974499/exam1/exercise2&amp;quot;
##   ..$ exercise3:List of 6
##   .. ..$ question    : chr [1:4] &amp;quot;&amp;quot; &amp;quot;Why is R special when comparing to other programming languages, such as Python, C++, javascript and others?&amp;quot; &amp;quot;&amp;quot; &amp;quot;&amp;quot;
##   .. ..$ questionlist: chr [1:5] &amp;quot;It was designed for analyzing data and producing statistical output&amp;quot; &amp;quot;Easy to use&amp;quot; &amp;quot;Works on any plataform such as Windows, Unix, MacOS&amp;quot; &amp;quot;Makes it easy to write mobile apps&amp;quot; ...
##   .. ..$ solution    : chr [1:2] &amp;quot;&amp;quot; &amp;quot;Undoubtedly, the main differential of the R language is the ease with which data can be analyzed on the platfor&amp;quot;| __truncated__
##   .. ..$ solutionlist: NULL
##   .. ..$ metainfo    :List of 18
##   .. ..$ supplements : Named chr(0) 
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr(0) 
##   .. .. ..- attr(*, &amp;quot;dir&amp;quot;)= chr &amp;quot;/tmp/RtmpIs4EpM/file4e094f974499/exam1/exercise3&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As an example, in this list you can see the main text of the question 01 in slot &lt;code&gt;l_out$exam1$exercise1$question&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_l$exam1$exercise1$question&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;&amp;quot;                                                                      
## [2] &amp;quot;The R language was developed based on what other programming language?&amp;quot;
## [3] &amp;quot;&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the solution at &lt;code&gt;my_l$exam1$exercise1$solution&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_l$exam1$exercise1$solution&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;&amp;quot;                                                                                                                                                                                       
## [2] &amp;quot;Straight from the book, section **What is R**: \&amp;quot;R is a modern version of S, a programming language originally created in Bell Laboratories (formerly AT&amp;amp;T, now Lucent Technologies).\&amp;quot;&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In my case, I wanted the html version of the book to have all the solutions hidden by a clickable button – just like in &lt;code&gt;webex&lt;/code&gt; – while the pdf and ebook would only have the text of the questions. Here are the functions I used:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;compile_eoc_exercises &amp;lt;- function(files_in, type_doc) {
  my_counter &amp;lt;&amp;lt;- 1

  if (is.null(type_doc)) {
    type_doc = &amp;#39;html&amp;#39;
    #type_doc = &amp;#39;latex&amp;#39;
  }

  for (i_ex in files_in) {
    exercise_to_html(i_ex, my_counter = my_counter,
                     type_doc)

    my_counter &amp;lt;&amp;lt;- my_counter +1
  }

  return(invisible(TRUE))
}

exercise_to_html &amp;lt;- function(f_in, my_counter, type_doc) {

  require(exams)
  require(webex)
  require(tidyverse)

  text_pre_solution &amp;lt;- paste0(&amp;#39;To reach the same result, you must execute the code below. &amp;#39;,
                           &amp;#39;For that, open a new R script in RStudio (Control+shift+N), &amp;#39;,
                           &amp;#39;copy and paste the code, and execute it whole by pressing &amp;#39;,
                           &amp;#39;Control+Shift+Enter or line by line with shortcut &amp;#39;,
                           &amp;#39;Control+Enter.&amp;#39;)

  my_dir &amp;lt;- file.path(tempdir(), basename(tempfile()))
  dir.create(my_dir)

  suppressMessages({
  l_out &amp;lt;- exams::xexams(f_in, driver = list(sweave = list(png = TRUE)),
                         dir = my_dir)

  })

  exercise_text &amp;lt;- paste0(l_out$exam1$exercise1$question, collapse = &amp;#39;\n&amp;#39;)
  alternatives &amp;lt;- l_out$exam1$exercise1$questionlist
  correct &amp;lt;- l_out$exam1$exercise1$metainfo$solution
  solution &amp;lt;- paste0(l_out$exam1$exercise1$solution,
                     collapse = &amp;#39;\n&amp;#39;)
  ex_type &amp;lt;- l_out$exam1$exercise1$metainfo$type

  if (type_doc %in% c(&amp;#39;latex&amp;#39;, &amp;#39;epub3&amp;#39;)) {

    my_str &amp;lt;- str_glue(&amp;#39;\n\n {sprintf(&amp;quot;%02d&amp;quot;, my_counter)} - {exercise_text} \n\n &amp;#39;)

    if (ex_type == &amp;#39;schoice&amp;#39;) {
      n_alternatives &amp;lt;- length(alternatives)

      for (i_alt in seq(1, n_alternatives)) {
        my_str &amp;lt;- paste0(my_str,
                         letters[i_alt],&amp;#39;) &amp;#39;, alternatives[i_alt],
                         &amp;#39;\n&amp;#39;)
      }

    }

    cat(my_str)

    return(invisible(TRUE))

  } else if (type_doc == &amp;#39;html&amp;#39;) {

    if (ex_type == &amp;#39;schoice&amp;#39;) {
      vec_mcq &amp;lt;- sample(
        c(alternatives[!correct],
          answer = alternatives[correct])
      )

      my_answers_text &amp;lt;- str_glue(&amp;#39;&amp;lt;br&amp;gt; Solution: {mcq(vec_mcq)}&amp;#39;)
      numeric_sol &amp;lt;- alternatives[correct]
      text_sol &amp;lt;- str_glue(&amp;#39;The solution is {numeric_sol}. {text_pre_solution}&amp;#39;)

    } else if (ex_type == &amp;#39;num&amp;#39;) {

      numeric_sol &amp;lt;- correct
      my_answers_text &amp;lt;- str_glue(&amp;#39;&amp;lt;br&amp;gt;&amp;lt;br&amp;gt; Your Answer: {fitb(correct)}&amp;#39;)
      text_sol &amp;lt;- str_glue(&amp;#39;The solution is {numeric_sol}. {text_pre_solution}&amp;#39;)

    } else if (ex_type == &amp;#39;string&amp;#39;) {
      my_answers_text &amp;lt;- &amp;#39;&amp;#39;
      numeric_sol &amp;lt;- &amp;#39;&amp;#39;

      if (stringr::str_detect(solution,
                              &amp;#39;```text&amp;#39;)) {
        text_sol &amp;lt;- paste0(&amp;#39;In order to execute the code, open a new R script in RStudio (Control+shift+N), &amp;#39;,
                           &amp;#39;copy and paste the code, and execute it whole by pressing &amp;#39;,
                           &amp;#39;Control+Shift+Enter or line by line with shortcut &amp;#39;,
                           &amp;#39;Control+Enter.&amp;#39;)

      } else {
        text_sol &amp;lt;- &amp;#39;&amp;#39;
      }

    }

    my_str &amp;lt;- paste0(&amp;#39;\n\n &amp;lt;hr&amp;gt; \n&amp;#39;,
                     webex::total_correct(), &amp;#39;\n&amp;#39;,
                     &amp;#39;### Q.&amp;#39;, my_counter, &amp;#39;{-} \n&amp;#39;,
                     exercise_text, &amp;#39;\n&amp;#39;,
                       my_answers_text)

    temp_id &amp;lt;- basename(tempfile(pattern = &amp;#39;collapse_&amp;#39;))
    sol_str &amp;lt;- str_glue(
      &amp;#39; &amp;lt;div style=&amp;quot;text-align: left; margin-top: 2px; padding: 13px 0 10px 0;&amp;quot;&amp;gt;&amp;lt;p&amp;gt;&amp;lt;button class=&amp;quot;btn btn-primary&amp;quot; type=&amp;quot;button&amp;quot; data-toggle=&amp;quot;collapse&amp;quot; data-target=&amp;quot;#{temp_id}&amp;quot; aria-expanded=&amp;quot;false&amp;quot; aria-controls=&amp;quot;collapseExample&amp;quot;&amp;gt;
    Solution
  &amp;lt;/button&amp;gt; &amp;lt;/p&amp;gt; &amp;lt;/div&amp;gt;

&amp;lt;div class=&amp;quot;collapse&amp;quot; id=&amp;quot;{temp_id}&amp;quot;&amp;gt;
{text_sol}
  &amp;lt;div class=&amp;quot;card card-body&amp;quot;&amp;gt;
    {solution}
  &amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;&amp;#39;)

    cat(paste0(my_str, &amp;#39;\n&amp;#39; ,
               sol_str))

  }

  return(invisible(TRUE))

}&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;html-exercises&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Html Exercises&lt;/h3&gt;
&lt;p&gt;The html output for the selected three exercises is given next. Do notice that the correct solution is &lt;strong&gt;not highlighted&lt;/strong&gt; in this blog post due to the lack of css and javascript. In the &lt;a href=&#34;https://www.msperlin.com/afedR/introduction.html#exercises&#34;&gt;final result&lt;/a&gt; you’ll see that it works correctly. Also, you’ll need to set &lt;code&gt;results=&#39;asis&#39;&lt;/code&gt; in the knitr options of the chunk (the code output pure html).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;compile_eoc_exercises(my_exercises, type_doc = &amp;#39;html&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;&lt;span id=&#34;total_correct&#34;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;q.1&#34; class=&#34;section level3 unnumbered&#34;&gt;
&lt;h3&gt;Q.1&lt;/h3&gt;
&lt;p&gt;The R language was developed based on what other programming language?&lt;/p&gt;
&lt;br&gt; Solution: &lt;select class=&#39;solveme&#39; data-answer=&#39;[&#34;S&#34;]&#39;&gt; &lt;option&gt;&lt;/option&gt; &lt;option&gt;Julia&lt;/option&gt; &lt;option&gt;Javascript&lt;/option&gt; &lt;option&gt;C++&lt;/option&gt; &lt;option&gt;S&lt;/option&gt; &lt;option&gt;Python&lt;/option&gt;&lt;/select&gt;
&lt;div style=&#34;text-align: left; margin-top: 2px; padding: 13px 0 10px 0;&#34;&gt;
&lt;p&gt;
&lt;button class=&#34;btn btn-primary&#34; type=&#34;button&#34; data-toggle=&#34;collapse&#34; data-target=&#34;#collapse_4e096b9ef65&#34; aria-expanded=&#34;false&#34; aria-controls=&#34;collapseExample&#34;&gt;
Solution
&lt;/button&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;collapse_4e096b9ef65&#34; class=&#34;collapse&#34;&gt;
The solution is S. To reach the same result, you must execute the code below. For that, open a new R script in RStudio (Control+shift+N), copy and paste the code, and execute it whole by pressing Control+Shift+Enter or line by line with shortcut Control+Enter.
&lt;div class=&#34;card card-body&#34;&gt;
Straight from the book, section &lt;strong&gt;What is R&lt;/strong&gt;: “R is a modern version of S, a programming language originally created in Bell Laboratories (formerly AT&amp;amp;T, now Lucent Technologies).”
&lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;p&gt;&lt;span id=&#34;total_correct&#34;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;q.2&#34; class=&#34;section level3 unnumbered&#34;&gt;
&lt;h3&gt;Q.2&lt;/h3&gt;
&lt;p&gt;What are the names of the two authors of R?&lt;/p&gt;
&lt;br&gt; Solution: &lt;select class=&#39;solveme&#39; data-answer=&#39;[&#34;Ross Ihaka and Robert Gentleman&#34;]&#39;&gt; &lt;option&gt;&lt;/option&gt; &lt;option&gt;Linus Torvalds and Richard Stallman&lt;/option&gt; &lt;option&gt;John Chambers and Robert Engle&lt;/option&gt; &lt;option&gt;Roger Federer and Rafael Nadal&lt;/option&gt; &lt;option&gt;Guido van Rossum and Bjarne Stroustrup&lt;/option&gt; &lt;option&gt;Ross Ihaka and Robert Gentleman&lt;/option&gt;&lt;/select&gt;
&lt;div style=&#34;text-align: left; margin-top: 2px; padding: 13px 0 10px 0;&#34;&gt;
&lt;p&gt;
&lt;button class=&#34;btn btn-primary&#34; type=&#34;button&#34; data-toggle=&#34;collapse&#34; data-target=&#34;#collapse_4e0956ac53c2&#34; aria-expanded=&#34;false&#34; aria-controls=&#34;collapseExample&#34;&gt;
Solution
&lt;/button&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;collapse_4e0956ac53c2&#34; class=&#34;collapse&#34;&gt;
The solution is Ross Ihaka and Robert Gentleman. To reach the same result, you must execute the code below. For that, open a new R script in RStudio (Control+shift+N), copy and paste the code, and execute it whole by pressing Control+Shift+Enter or line by line with shortcut Control+Enter.
&lt;div class=&#34;card card-body&#34;&gt;
&lt;p&gt;Straight from the book: “… The base code of R was developed by two academics, &lt;strong&gt;Ross Ihaka&lt;/strong&gt; and &lt;strong&gt;Robert Gentleman&lt;/strong&gt;, resulting in the programming platform we have today.”.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;p&gt;&lt;span id=&#34;total_correct&#34;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;q.3&#34; class=&#34;section level3 unnumbered&#34;&gt;
&lt;h3&gt;Q.3&lt;/h3&gt;
&lt;p&gt;Why is R special when comparing to other programming languages, such as Python, C++, javascript and others?&lt;/p&gt;
&lt;br&gt; Solution: &lt;select class=&#39;solveme&#39; data-answer=&#39;[&#34;It was designed for analyzing data and producing statistical output&#34;]&#39;&gt; &lt;option&gt;&lt;/option&gt; &lt;option&gt;Easy to use&lt;/option&gt; &lt;option&gt;It was designed for analyzing data and producing statistical output&lt;/option&gt; &lt;option&gt;Makes it easy to write mobile apps&lt;/option&gt; &lt;option&gt;Quick code execution&lt;/option&gt; &lt;option&gt;Works on any plataform such as Windows, Unix, MacOS&lt;/option&gt;&lt;/select&gt;
&lt;div style=&#34;text-align: left; margin-top: 2px; padding: 13px 0 10px 0;&#34;&gt;
&lt;p&gt;
&lt;button class=&#34;btn btn-primary&#34; type=&#34;button&#34; data-toggle=&#34;collapse&#34; data-target=&#34;#collapse_4e0916478a7b&#34; aria-expanded=&#34;false&#34; aria-controls=&#34;collapseExample&#34;&gt;
Solution
&lt;/button&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;collapse_4e0916478a7b&#34; class=&#34;collapse&#34;&gt;
The solution is It was designed for analyzing data and producing statistical output. To reach the same result, you must execute the code below. For that, open a new R script in RStudio (Control+shift+N), copy and paste the code, and execute it whole by pressing Control+Shift+Enter or line by line with shortcut Control+Enter.
&lt;div class=&#34;card card-body&#34;&gt;
Undoubtedly, the main differential of the R language is the ease with which data can be analyzed on the platform. Although other languages also allow data analysis, it is in R where this process is supported by a wide range of specialized packages.
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;pdfebook-exercises&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Pdf/Ebook Exercises&lt;/h3&gt;
&lt;p&gt;And for latex (pdf) and epub3 (ebook), the result is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;compile_eoc_exercises(my_exercises, type_doc = &amp;#39;latex&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;01 -
The R language was developed based on what other programming language?&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;C++&lt;/li&gt;
&lt;li&gt;S&lt;/li&gt;
&lt;li&gt;Javascript&lt;/li&gt;
&lt;li&gt;Julia&lt;/li&gt;
&lt;li&gt;Python&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;02 -
What are the names of the two authors of R?&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;Guido van Rossum and Bjarne Stroustrup&lt;/li&gt;
&lt;li&gt;John Chambers and Robert Engle&lt;/li&gt;
&lt;li&gt;Roger Federer and Rafael Nadal&lt;/li&gt;
&lt;li&gt;Ross Ihaka and Robert Gentleman&lt;/li&gt;
&lt;li&gt;Linus Torvalds and Richard Stallman&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;03 -
Why is R special when comparing to other programming languages, such as Python, C++, javascript and others?&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;Works on any plataform such as Windows, Unix, MacOS&lt;/li&gt;
&lt;li&gt;Easy to use&lt;/li&gt;
&lt;li&gt;Quick code execution&lt;/li&gt;
&lt;li&gt;Makes it easy to write mobile apps&lt;/li&gt;
&lt;li&gt;It was designed for analyzing data and producing statistical output&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;As you can see, it works great. So, at the end of each chapter I simply called function &lt;code&gt;compile_eoc_exercises()&lt;/code&gt; with the knit chunk options &lt;code&gt;results=&#39;asis&#39;&lt;/code&gt; and &lt;code&gt;echo=FALSE&lt;/code&gt;. Moreover, object &lt;code&gt;my_engine&lt;/code&gt; is set as &lt;code&gt;my_engine &amp;lt;- knitr:::pandoc_to()&lt;/code&gt;, which will figure out the format within the compilation of the book:&lt;/p&gt;
&lt;blockquote class=&#34;imgur-embed-pub&#34; lang=&#34;en&#34; data-id=&#34;a/lCDuvZg&#34; data-context=&#34;false&#34;&gt;
&lt;a href=&#34;//imgur.com/a/lCDuvZg&#34;&gt;&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;//s.imgur.com/min/embed.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Its is amazing how much we can accomplish by learning and mixing different technologies. In this case, I used R, Latex, html, javascript and css to bundle reproducible and dynamic exercises for my book. You can find examples of the final output in &lt;a href=&#34;https://www.msperlin.com/afedR/introduction.html#exercises&#34;&gt;html&lt;/a&gt;, &lt;a href=&#34;https://www.msperlin.com/afedR/afedR_ed02-ONLINE.pdf&#34;&gt;pdf&lt;/a&gt; and &lt;a href=&#34;https://www.msperlin.com/afedR/afedR_ed02-ONLINE.epub&#34;&gt;ebook&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you’re trying it for you own book, make sure to add the correct .js and .css files to the html compilation. In my case, I used &lt;a href=&#34;https://www.msperlin.com/post/my_javascript.js&#34;&gt;my_javascript.js&lt;/a&gt; and &lt;a href=&#34;https://www.msperlin.com/post/style_html.css&#34;&gt;style_html.css&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Ten years as a professor -- six advices to young academics</title>
      <link>https://www.msperlin.com/post/2021-03-10-advices-young-academics/</link>
      <pubDate>Wed, 10 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2021-03-10-advices-young-academics/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;In the 18th of march 2021 I’ll complete exactly ten years since finishing my PhD and taking a professorship position at UFRGS, south of Brazil. In this post I’ll write about what I learned during this period and, hopefully, help other academics that are just starting out.&lt;/p&gt;
&lt;p&gt;This post is the summary of a talk I had with a former PhD student. I’m fully aware that academic work can be very different across countries and institutions. I don’t claim to have all the answers to all the problems. But, these are a couple of advice that would certainly help me in my starting years.&lt;/p&gt;
&lt;div id=&#34;find-a-hobby&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;1) Find a hobby&lt;/h3&gt;
&lt;p&gt;First and foremost, find a hobby. Yes, sounds weird as a first advice but you would be surprised how a hobby – or anything that takes your mind of work – can give you a great boost in quality of life and work, specially in academia.&lt;/p&gt;
&lt;p&gt;A good hobby should not be related to work, or driven by its consequences. For example, I usually go to the gym twice a week. Not because I enjoy it, but due to the fact that it helps me keeping my body healthy. Honestly, I don’t like gyms, but I go anyway.&lt;/p&gt;
&lt;p&gt;Said that, sports are a good example of hobbies. You do it for its own sake. So, find a sport you like and invest time in it. You’ll thank me later.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;plan-for-the-long-term&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;2) Plan for the long term&lt;/h3&gt;
&lt;p&gt;One repeated mistake I made in my starting years is to enroll in many different projects. In hindsight, I can see that most of them were doomed to fail before even starting. At first, everyone is excited to join and do something new, but few remain if their motivation is not right. Moreover, students have a tendency to say yes to the teacher, which makes them to agree to projects that they might not be really interested. Everyone will stay in the project until time becomes scarce or something new shows up.&lt;/p&gt;
&lt;p&gt;Incentives play a key role in everything we do and I learned this the hard way. For example, if a student works 8 hours in a bank, he is not taking a weekend off to review the econometrics of that scientific paper we wrote together months ago. And there is nothing wrong with that. The mistake was from my part for 1) not making it clear of how much work a paper needs and 2) assuming the student and I would share the same incentives, which is simply not true.&lt;/p&gt;
&lt;p&gt;When playing for the long term academic game, focus on things that you are likely to continue doing in 5, 10, 15 years:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Make a personal website (yes, many people still don’t). Without it, how will people see your work?&lt;/li&gt;
&lt;li&gt;Find a research topic that you’re passionate about; this way will be much easier to write, teach and code about the topic.&lt;/li&gt;
&lt;li&gt;Find colleagues that are also playing the long term game and work with them.&lt;/li&gt;
&lt;li&gt;Use open software in data analysis and teaching, preferably Python or R. Its smart to keep your workflow reproducible and license-free. This way you’ll be able to take your work anywhere, if necessary;&lt;/li&gt;
&lt;li&gt;Don’t ever compromise your reputation. A famous quote: “it takes years to build a reputations and a few minutes to lose it”.&lt;/li&gt;
&lt;li&gt;Learn new tools: linux, server-side scripting, building websites, editing videos, using YouTube, using e-learning platforms, and so on. Whatever it takes to deliver your work to society. Don’t let other people do it for you. You have the time, just site down and learn it.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;quantity-beats-quality&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;3) Quantity beats quality&lt;/h3&gt;
&lt;p&gt;One statistic that few people know is that, for a reputable, high ranking journal such as &lt;em&gt;Journal of Finance&lt;/em&gt;, the median number of citations per article is close to zero. This means that, what drives the high impact factors of such journals is a couple of papers that become popular in their field of expertise. This means that few articles get all the glory.&lt;/p&gt;
&lt;p&gt;Also know as the &lt;em&gt;tail effect&lt;/em&gt; or &lt;em&gt;Pareto rule&lt;/em&gt;, this is a common pattern in business. As an example, there were many search engines before Google but none with its success. The high scalability of business in digital commodities, such as search engines, makes it so that a couple of companies gets all the sales (or search queries). Likewise, if you invest in a portfolio of companies over a long period of time, your total performance would be due to a handful of companies. Those winners with the highest returns will easily compensate for losers, and still give you a handsome financial reward.&lt;/p&gt;
&lt;p&gt;This is also true for your research work. If you write ten papers, be glad that one of them does well and attracts citations. This might also just be good luck, due to right timing. This means that you should focus your research in quality, but also &lt;strong&gt;quantity&lt;/strong&gt;. The more papers, higher the likelihood of hitting the spot and getting recognition.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;its-not-all-about-papers-but-it-helps&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;4) Its not all about papers, but it helps&lt;/h3&gt;
&lt;p&gt;Papers have historically been the main output of academics. I certainly felt that way when starting out. Today, the university work can take many different shapes and colors. You can contribute to society not just by writing research papers but also:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;writing and publishing code&lt;/li&gt;
&lt;li&gt;writing books&lt;/li&gt;
&lt;li&gt;writing news articles&lt;/li&gt;
&lt;li&gt;writing blog posts&lt;/li&gt;
&lt;li&gt;releasing videos on YouTube&lt;/li&gt;
&lt;li&gt;local lectures&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My suggestion is to try as many as possible and see which type of output you like best.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;you-have-freedom-and-autonomy-use-it..&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;5) You have freedom and autonomy, use it..&lt;/h3&gt;
&lt;p&gt;Academics generally have the autonomy to define their workflow and control their environment. Use and abuse of that freedom. Very few people have that kind of autonomy and some would probably be willing to pay a good amount of money for it, if they could. With that in mind:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Its not about the number of hours, but what you do with them. No one cares about how many hours you are at the university, but what you are producing to society, whether it is research articles, lectures or code.&lt;/li&gt;
&lt;li&gt;Change your working hours as needed. For example, if you live in a large city, why do you need to get from/to work at rush hours? Likewise, why not working on the weekend and taking Monday off? (I’ve done this countless times – its fun..)&lt;/li&gt;
&lt;li&gt;Don’t work with people you don’t like. Easier said than done, but keep in mind that you always have that choice.&lt;/li&gt;
&lt;li&gt;Learn to say no, constantly.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;academia-is-changing-fast..&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;6) Academia is changing, fast..&lt;/h3&gt;
&lt;p&gt;And you should be worried. Historically, universities always had the prestige of being knowledge centers. In contrast, knowledge is now abundant in the digital world. My students are no longer learning by reading books, but by watching YouTube videos or using other platforms. It seems we distanced ourselves from the real world and that is starting to backfire. A reliable sign is a &lt;a href=&#34;https://www.cnbc.com/2018/08/16/15-companies-that-no-longer-require-employees-to-have-a-college-degree.html&#34;&gt;trend&lt;/a&gt; in the hiring process of companies of not requiring a college degree, but only proof of work.&lt;/p&gt;
&lt;p&gt;The change is coming and we have not clue of how universities will adapt in the next 5, 10 years. The only thing you can control is how much you learn and do. So, do more and learn more. Be prepared.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Update on the Shiny/Web Interface of GetDFPData2</title>
      <link>https://www.msperlin.com/post/2021-03-06-getdfpdata2-web/</link>
      <pubDate>Sat, 06 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2021-03-06-getdfpdata2-web/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;&lt;code&gt;GetDFPData&lt;/code&gt; is an academic project to provide free and unrestricted access to financial reports from B3, the brazilian exchange.
&lt;a href=&#34;https://www.msperlin.com/post/2020-07-18-new_packages-getfredata-getdfpdata2/&#34;&gt;Back in 2020&lt;/a&gt; I split the code of &lt;code&gt;GetDFDData&lt;/code&gt; into two distinct packages: &lt;code&gt;GetDFPData2&lt;/code&gt; and &lt;code&gt;GetFREData&lt;/code&gt;. In short, I’ve found a new data source at CVM (comissão valores mobiliários) that is much easier to work than B3’s site. While the code in &lt;code&gt;GetDFPData2&lt;/code&gt; is becoming stable and will soon be released in CRAN, the &lt;a href=&#34;https://www.msperlin.com/shiny/GetDFPData/&#34;&gt;shiny app&lt;/a&gt; was missing this important update.&lt;/p&gt;
&lt;p&gt;Finally got some free time to work on the shinny app once again. The main change is that the underlying code is fully based on GetDFPData2, i.e., the data output is exactly the same as using an R session. Previous version used cached data from &lt;code&gt;GetDFPData&lt;/code&gt;, which meant that every year I had to recompile and feed the new data to the app. This choice was not accidental as previous version of the package took a long time to parse all xml files from B3. The new version executes data importation very quickly, allowing for a web interface in a modest server such as mine.&lt;/p&gt;
&lt;p&gt;The app is hosted at &lt;a href=&#34;https://www.msperlin.com/shiny/GetDFPData/&#34;&gt;link_shiny&lt;/a&gt;. See a peek below:&lt;/p&gt;
&lt;iframe src=&#34;https://www.msperlin.com/shiny/GetDFPData2/?showcase=0&#34; width=&#34;672&#34; height=&#34;550px&#34;&gt;
&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>Compiling Book Exercises to pdf | html | Moodle | Blackboard</title>
      <link>https://www.msperlin.com/post/2021-02-28-dynamic-exercises-afedr/</link>
      <pubDate>Sun, 28 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2021-02-28-dynamic-exercises-afedr/</guid>
      <description>


&lt;p&gt;The revised second edition of &lt;a href=&#34;https://www.msperlin.com/afedr/&#34;&gt;Analyzing Financial and Economic Data with R&lt;/a&gt; presents more than 100 exercises at the end section of all chapters. All exercises are freely available in the &lt;a href=&#34;http://www.r-exams.org/&#34;&gt;&lt;code&gt;exams&lt;/code&gt; format&lt;/a&gt;, meaning that any R tutor can export the same exercises to pdf, html or &lt;em&gt;e-learning&lt;/em&gt; platforms. In this post I’ll show how to compile exercises to pdf, html, &lt;em&gt;Moodle&lt;/em&gt; and &lt;em&gt;blackboard&lt;/em&gt;.&lt;/p&gt;
&lt;div id=&#34;installation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Installation&lt;/h1&gt;
&lt;p&gt;The first step is to install package &lt;code&gt;afedR&lt;/code&gt; with &lt;code&gt;devtools&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;#39;msperlin/afedR&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another requirement is a working Latex instalation. For that, use &lt;code&gt;tinytex&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tinytex::install_tinytex()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;compiling-exercises&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Compiling Exercises&lt;/h1&gt;
&lt;div id=&#34;how-it-works&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How it works?&lt;/h2&gt;
&lt;p&gt;All book exercises in the &lt;code&gt;exams&lt;/code&gt; format: each exercise is a .Rmd file containing code, exercise text and solution. The files themselves can be found in the installation directory of the package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;eoc_dir &amp;lt;- afedR::get_EOC_dir()

eoc_chapters &amp;lt;- fs::dir_ls(eoc_dir)
basename(eoc_chapters)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Chapter01-Introduction&amp;quot;             &amp;quot;Chapter02-Basic-Operations&amp;quot;        
##  [3] &amp;quot;Chapter03-Research-Scripts&amp;quot;         &amp;quot;Chapter04-Import-Local&amp;quot;            
##  [5] &amp;quot;Chapter05-Import-Internet&amp;quot;          &amp;quot;Chapter06-Dataframes-and-Others&amp;quot;   
##  [7] &amp;quot;Chapter07-Basic-Classes&amp;quot;            &amp;quot;Chapter08-Programming&amp;quot;             
##  [9] &amp;quot;Chapter09-Cleaning-and-Structuring&amp;quot; &amp;quot;Chapter10-Figures&amp;quot;                 
## [11] &amp;quot;Chapter11-FinEcon&amp;quot;                  &amp;quot;Chapter12-Reporting&amp;quot;               
## [13] &amp;quot;Chapter13-Optimizing-Code&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Each folder will have several exercises. Let’s try one out:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;eoc_files &amp;lt;- fs::dir_ls(eoc_chapters[1])
basename(eoc_files)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;afedR_Chap-01_01_SPLUS.Rmd&amp;quot;            
##  [2] &amp;quot;afedR_Chap-01_02_Authors-R.Rmd&amp;quot;        
##  [3] &amp;quot;afedR_Chap-01_03_About-R.Rmd&amp;quot;          
##  [4] &amp;quot;afedR_Chap-01_04_name-R.Rmd&amp;quot;           
##  [5] &amp;quot;afedR_Chap-01_05_about-R.Rmd&amp;quot;          
##  [6] &amp;quot;afedR_Chap-01_06_Tecnology-R.Rmd&amp;quot;      
##  [7] &amp;quot;afedR_Chap-01_07_rtools.Rmd&amp;quot;           
##  [8] &amp;quot;afedR_Chap-01_08_Groups.Rmd&amp;quot;           
##  [9] &amp;quot;afedR_Chap-01_09_RBloggers.Rmd&amp;quot;        
## [10] &amp;quot;afedR_Chap-01_10_Infrastructure-TI.Rmd&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also read one of the files to show the strucuture of the exercise in code and text:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;readLines(eoc_files[1])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;```{r datageneration, echo = FALSE, results = \&amp;quot;hide\&amp;quot;}&amp;quot;                                                                                                                                
##  [2] &amp;quot;my_answers &amp;lt;- c(&amp;#39;S&amp;#39;, &amp;quot;                                                                                                                                                                  
##  [3] &amp;quot;                &amp;#39;C++&amp;#39;,&amp;quot;                                                                                                                                                                 
##  [4] &amp;quot;                &amp;#39;Python&amp;#39;,&amp;quot;                                                                                                                                                              
##  [5] &amp;quot;                &amp;#39;Julia&amp;#39;,&amp;quot;                                                                                                                                                               
##  [6] &amp;quot;                &amp;#39;Javascript&amp;#39;)&amp;quot;                                                                                                                                                          
##  [7] &amp;quot;&amp;quot;                                                                                                                                                                                       
##  [8] &amp;quot;#check_answers(my_answers)&amp;quot;                                                                                                                                                             
##  [9] &amp;quot;```&amp;quot;                                                                                                                                                                                    
## [10] &amp;quot;&amp;quot;                                                                                                                                                                                       
## [11] &amp;quot;Question&amp;quot;                                                                                                                                                                               
## [12] &amp;quot;========&amp;quot;                                                                                                                                                                               
## [13] &amp;quot;&amp;quot;                                                                                                                                                                                       
## [14] &amp;quot;The R language was developed based on what other programming language?&amp;quot;                                                                                                                 
## [15] &amp;quot;&amp;quot;                                                                                                                                                                                       
## [16] &amp;quot;```{r questionlist, echo = FALSE, results = \&amp;quot;asis\&amp;quot;}&amp;quot;                                                                                                                                  
## [17] &amp;quot;exams::answerlist(my_answers, markup = \&amp;quot;markdown\&amp;quot;)&amp;quot;                                                                                                                                   
## [18] &amp;quot;```&amp;quot;                                                                                                                                                                                    
## [19] &amp;quot;&amp;quot;                                                                                                                                                                                       
## [20] &amp;quot;Solution&amp;quot;                                                                                                                                                                               
## [21] &amp;quot;================&amp;quot;                                                                                                                                                                       
## [22] &amp;quot;&amp;quot;                                                                                                                                                                                       
## [23] &amp;quot;Straight from the book, section **What is R**: \&amp;quot;R is a modern version of S, a programming language originally created in Bell Laboratories (formerly AT&amp;amp;T, now Lucent Technologies).\&amp;quot;&amp;quot;
## [24] &amp;quot;&amp;quot;                                                                                                                                                                                       
## [25] &amp;quot;Meta-information&amp;quot;                                                                                                                                                                       
## [26] &amp;quot;================&amp;quot;                                                                                                                                                                       
## [27] &amp;quot;extype: schoice&amp;quot;                                                                                                                                                                        
## [28] &amp;quot;exsolution: `r mchoice2string(c(TRUE, FALSE, FALSE, FALSE, FALSE), single = TRUE)`&amp;quot;                                                                                                     
## [29] &amp;quot;exname: \&amp;quot;S PLUS\&amp;quot;&amp;quot;                                                                                                                                                                     
## [30] &amp;quot;exshuffle: TRUE&amp;quot;                                                                                                                                                                        
## [31] &amp;quot;&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Basically, we define all sections of a question – text, solution, alternatives – using a .Rmd template. Again, you can find more details about using package &lt;code&gt;exams&lt;/code&gt; in its own &lt;a href=&#34;http://www.r-exams.org/&#34;&gt;website&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Be aware that, all exams .rmd files available within &lt;code&gt;afedR&lt;/code&gt; are self contained and you can export and compile them directly from &lt;code&gt;exams&lt;/code&gt;. An easy way to copy all exercise files to your local folder is using function &lt;code&gt;afedR::path_to_copy&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# copy to &amp;quot;documents&amp;quot; folder
afedR::copy_book_files(path_to_copy = &amp;#39;~&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Copying data files files to ~/afedR files/data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 	37 files copied&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Copying end-of-chapter (eoc) exercises with solutions to ~/afedR files/eoc-exercises/&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 	99 files copied&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Copying R code to ~/afedR files/R-code&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 	15 files copied&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All book files – data, code and exercises – are now available at your “Documents” folder (shorcut of &lt;code&gt;~&lt;/code&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;compiling-to-pdf&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Compiling to pdf&lt;/h2&gt;
&lt;p&gt;For pdf compilation, you’ll need:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;name of students (will be printed in pdf)&lt;/li&gt;
&lt;li&gt;students ids (I usually use their university card number)&lt;/li&gt;
&lt;li&gt;Chapters to include&lt;/li&gt;
&lt;li&gt;Exercise name&lt;/li&gt;
&lt;li&gt;Course name&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And use the following code&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(afedR)

names_students &amp;lt;- c(&amp;#39;Michael Peterling&amp;#39;, &amp;#39;John Aspper&amp;#39;, &amp;#39;Mr. Beans&amp;#39;)
ids_students &amp;lt;- 1:length(names_students) # probably id card?
chapters &amp;lt;- 1:3 # chapters from 1 to 13
dir_output &amp;lt;- file.path(tempdir(), &amp;#39;pdf-example&amp;#39;)


df_exams &amp;lt;- compile_pdf_exercises(students_names = names_students, 
                                  students_ids = ids_students, 
                                  chapters_to_include = chapters,
                                  dir_out = dir_output)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output of &lt;code&gt;compile_pdf_exercises&lt;/code&gt; is a table with the correct answers for &lt;code&gt;schoice&lt;/code&gt; and &lt;code&gt;num&lt;/code&gt; type of questions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(df_exams)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 69
## Columns: 4
## $ i_name   &amp;lt;chr&amp;gt; &amp;quot;Michael Peterling&amp;quot;, &amp;quot;Michael Peterling&amp;quot;, &amp;quot;Michael Peterling&amp;quot;…
## $ i_ver    &amp;lt;int&amp;gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…
## $ i_q      &amp;lt;int&amp;gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…
## $ solution &amp;lt;chr&amp;gt; &amp;quot;b&amp;quot;, &amp;quot;e&amp;quot;, &amp;quot;e&amp;quot;, &amp;quot;c&amp;quot;, &amp;quot;a&amp;quot;, NA, &amp;quot;c&amp;quot;, NA, NA, NA, NA, NA, NA, NA,…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After compilation, all pdf files are available at folder &lt;code&gt;dir_output&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fs::dir_ls(dir_output)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## /tmp/RtmpANdrK1/pdf-example/Sample Exercise_Ver 01_Michael Peterling.pdf
## /tmp/RtmpANdrK1/pdf-example/Sample Exercise_Ver 02_John Aspper.pdf
## /tmp/RtmpANdrK1/pdf-example/Sample Exercise_Ver 03_Mr. Beans.pdf&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The final result will be as follows:&lt;/p&gt;
&lt;blockquote class=&#34;imgur-embed-pub&#34; lang=&#34;en&#34; data-id=&#34;a/wVAd8Xr&#34; data-context=&#34;false&#34;&gt;
&lt;a href=&#34;//imgur.com/a/wVAd8Xr&#34;&gt;&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;//s.imgur.com/min/embed.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div id=&#34;compiling-to-html&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Compiling to html&lt;/h2&gt;
&lt;p&gt;You can also compile to a html file using &lt;code&gt;afedR::compile_html_exercises&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(afedR)

names_students &amp;lt;- c(&amp;#39;Michael Peterling&amp;#39;, &amp;#39;John Aspper&amp;#39;, &amp;#39;Mr. Beans&amp;#39;)
ids_students &amp;lt;- 1:length(names_students) # probably id card?
chapters &amp;lt;- 1:3 # chapters from 1 to 13
dir_output &amp;lt;- file.path(tempdir(), &amp;#39;html-example&amp;#39;)

df_exams &amp;lt;- compile_html_exercises(students_names = names_students, 
                                   students_ids = ids_students, 
                                   chapters_to_include = chapters,
                                   dir_out = dir_output)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Exams generation initialized.
## 
## Output directory: /tmp/RtmpANdrK1/exams files file6c348a93b03
## Exercise directory: /home/msperlin/GitRepo/03-sites/msperlin-blog/content/post
## Supplement directory: /tmp/RtmpANdrK1/file6c345c25c3b7
## Temporary directory: /tmp/RtmpANdrK1/file6c342a56b7e1
## Exercises: /home/msperlin/R/x86_64-pc-linux-gnu-library/4.2/afedR/extdata/exams_files/02-EOCE-Rmd/Chapter01-Introduction/afedR_Chap-01_01_SPLUS, /home/msperlin/R/x86_64-pc-linux-gnu-library/4.2/afedR/extdata/exams_files/02-EOCE-Rmd/Chapter01-Introduction/afedR_Chap-01_02_Authors-R, /home/msperlin/R/x86_64-pc-linux-gnu-library/4.2/afedR/extdata/exams_files/02-EOCE-Rmd/Chapter01-Introduction/afedR_Chap-01_03_About-R, /home/msperlin/R/x86_64-pc-linux-gnu-library/4.2/afedR/extdata/exams_files/02-EOCE-Rmd/Chapter01-Introduction/afedR_Chap-01_04_name-R, /home/msperlin/R/x86_64-pc-linux-gnu-library/4.2/afedR/extdata/exams_files/02-EOCE-Rmd/Chapter01-Introduction/afedR_Chap-01_05_about-R, /home/msperlin/R/x86_64-pc-linux-gnu-library/4.2/afedR/extdata/exams_files/02-EOCE-Rmd/Chapter01-Introduction/afedR_Chap-01_06_Tecnology-R, /home/msperlin/R/x86_64-pc-linux-gnu-library/4.2/afedR/extdata/exams_files/02-EOCE-Rmd/Chapter01-Introduction/afedR_Chap-01_07_rtools, /home/msperlin/R/x86_64-pc-linux-gnu-library/4.2/afedR/extdata/exams_files/02-EOCE-Rmd/Chapter01-Introduction/afedR_Chap-01_08_Groups, /home/msperlin/R/x86_64-pc-linux-gnu-library/4.2/afedR/extdata/exams_files/02-EOCE-Rmd/Chapter01-Introduction/afedR_Chap-01_09_RBloggers, /home/msperlin/R/x86_64-pc-linux-gnu-library/4.2/afedR/extdata/exams_files/02-EOCE-Rmd/Chapter01-Introduction/afedR_Chap-01_10_Infrastructure-TI, /home/msperlin/R/x86_64-pc-linux-gnu-library/4.2/afedR/extdata/exams_files/02-EOCE-Rmd/Chapter02-Basic-Operations/afedR_Chap-02_01_Basic, /home/msperlin/R/x86_64-pc-linux-gnu-library/4.2/afedR/extdata/exams_files/02-EOCE-Rmd/Chapter02-Basic-Operations/afedR_Chap-02_02_Basic, /home/msperlin/R/x86_64-pc-linux-gnu-library/4.2/afedR/extdata/exams_files/02-EOCE-Rmd/Chapter02-Basic-Operations/afedR_Chap-02_03_getwd, /home/msperlin/R/x86_64-pc-linux-gnu-library/4.2/afedR/extdata/exams_files/02-EOCE-Rmd/Chapter02-Basic-Operations/afedR_Chap-02_04_download, /home/msperlin/R/x86_64-pc-linux-gnu-library/4.2/afedR/extdata/exams_files/02-EOCE-Rmd/Chapter02-Basic-Operations/afedR_Chap-02_05_unzip, /home/msperlin/R/x86_64-pc-linux-gnu-library/4.2/afedR/extdata/exams_files/02-EOCE-Rmd/Chapter02-Basic-Operations/afedR_Chap-02_06_installpkgs, /home/msperlin/R/x86_64-pc-linux-gnu-library/4.2/afedR/extdata/exams_files/02-EOCE-Rmd/Chapter02-Basic-Operations/afedR_Chap-02_07_filespkgs, /home/msperlin/R/x86_64-pc-linux-gnu-library/4.2/afedR/extdata/exams_files/02-EOCE-Rmd/Chapter02-Basic-Operations/afedR_Chap-02_08_installpkgs2, /home/msperlin/R/x86_64-pc-linux-gnu-library/4.2/afedR/extdata/exams_files/02-EOCE-Rmd/Chapter02-Basic-Operations/afedR_Chap-02_09_installpkgs3-cranlogs, /home/msperlin/R/x86_64-pc-linux-gnu-library/4.2/afedR/extdata/exams_files/02-EOCE-Rmd/Chapter02-Basic-Operations/afedR_Chap-02_10_devtools, /home/msperlin/R/x86_64-pc-linux-gnu-library/4.2/afedR/extdata/exams_files/02-EOCE-Rmd/Chapter02-Basic-Operations/afedR_Chap-02_11_files-in-computer, /home/msperlin/R/x86_64-pc-linux-gnu-library/4.2/afedR/extdata/exams_files/02-EOCE-Rmd/Chapter03-Research-Scripts/afedR_Chap-03_01_pesquisa, /home/msperlin/R/x86_64-pc-linux-gnu-library/4.2/afedR/extdata/exams_files/02-EOCE-Rmd/Chapter03-Research-Scripts/afedR_Chap-03_02_folders
## 
## Generation of individual exams.
## Exam 1: _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_01_SPLUS (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_02_Authors-R (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_03_About-R (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_04_name-R (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_05_about-R (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_06_Tecnology-R (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_07_rtools (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_08_Groups (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_09_RBloggers (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_10_Infrastructure-TI (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_01_Basic (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_02_Basic (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_03_getwd (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_04_download (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_05_unzip (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_06_installpkgs (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_07_filespkgs (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_08_installpkgs2 (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_09_installpkgs3-cranlogs (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_10_devtools (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_11_files-in-computer (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter03-Research-Scripts_afedR_Chap-03_01_pesquisa (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter03-Research-Scripts_afedR_Chap-03_02_folders (srt) ... w ... done.
## Exam 2: _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_01_SPLUS (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_02_Authors-R (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_03_About-R (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_04_name-R (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_05_about-R (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_06_Tecnology-R (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_07_rtools (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_08_Groups (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_09_RBloggers (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_10_Infrastructure-TI (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_01_Basic (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_02_Basic (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_03_getwd (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_04_download (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_05_unzip (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_06_installpkgs (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_07_filespkgs (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_08_installpkgs2 (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_09_installpkgs3-cranlogs (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_10_devtools (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_11_files-in-computer (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter03-Research-Scripts_afedR_Chap-03_01_pesquisa (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter03-Research-Scripts_afedR_Chap-03_02_folders (srt) ... w ... done.
## Exam 3: _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_01_SPLUS (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_02_Authors-R (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_03_About-R (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_04_name-R (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_05_about-R (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_06_Tecnology-R (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_07_rtools (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_08_Groups (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_09_RBloggers (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter01-Introduction_afedR_Chap-01_10_Infrastructure-TI (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_01_Basic (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_02_Basic (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_03_getwd (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_04_download (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_05_unzip (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_06_installpkgs (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_07_filespkgs (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_08_installpkgs2 (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_09_installpkgs3-cranlogs (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_10_devtools (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter02-Basic-Operations_afedR_Chap-02_11_files-in-computer (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter03-Research-Scripts_afedR_Chap-03_01_pesquisa (srt) _home_msperlin_R_x86_64-pc-linux-gnu-library_4.2_afedR_extdata_exams_files_02-EOCE-Rmd_Chapter03-Research-Scripts_afedR_Chap-03_02_folders (srt) ... w ... done.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An example of full compiled html file is available &lt;a href=&#34;https://www.msperlin.com/files/afedr-files/Introduction%20to%20R_Robert%20Engle_Ver%2003.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exporting-to-moodle&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exporting to Moodle&lt;/h2&gt;
&lt;p&gt;You can also export to &lt;em&gt;e-learning&lt;/em&gt; platforms such as Moodle. The process is quite simple as &lt;code&gt;exams&lt;/code&gt; package does the heavy work:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;require(afedR)
my_eoc_dir &amp;lt;- afedR::get_EOC_dir()

available_chapters &amp;lt;- fs::dir_ls(my_eoc_dir)
exercise_files &amp;lt;- fs::dir_ls(available_chapters[1])
dir_output &amp;lt;- file.path(tempdir(), &amp;#39;moodle-test&amp;#39;)

exams::exams2moodle(file = exercise_files, 
                    name = &amp;#39;TestingMoodle&amp;#39;, 
                    dir = dir_output)

fs::dir_ls(dir_output)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## /tmp/RtmpANdrK1/moodle-test/TestingMoodle.xml&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can later import this .xml file in your Moodle class.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exporting-to-blackboard&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exporting to Blackboard&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;require(afedR)
my_eoc_dir &amp;lt;- afedR::get_EOC_dir()

available_chapters &amp;lt;- fs::dir_ls(my_eoc_dir)
exercise_files &amp;lt;- fs::dir_ls(available_chapters[1])
dir_output &amp;lt;- file.path(tempdir(), &amp;#39;blackboard-test&amp;#39;)

exams::exams2blackboard(file = exercise_files, 
                        name = &amp;#39;TestingBlackBoard&amp;#39;, 
                        dir = dir_output)

fs::dir_ls(dir_output)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## /tmp/RtmpANdrK1/blackboard-test/TestingBlackBoard.zip&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This .zip file contains all exercises of chapter 01 and can be imported in your blackboard account.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Revision of book &#34;Analyzing Financial and Economic Data with R&#34;</title>
      <link>https://www.msperlin.com/post/2021-02-28-afedr-revision-2021/</link>
      <pubDate>Sun, 28 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2021-02-28-afedr-revision-2021/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I recently launched the third edition of my &lt;a href=&#34;https://www.msperlin.com/adfeR/&#34;&gt;portuguese R book (adfeR-pt-br)&lt;/a&gt;, with many due changes from the &lt;a href=&#34;https://www.msperlin.com/afedR/&#34;&gt;international version (afedR-en)&lt;/a&gt;. To make it clear, the second edition of afedR (en) was ahead in content and the third edition of adfeR (pt-br) closed that gap.&lt;/p&gt;
&lt;p&gt;But, as it usually is with a time evolving platform such as R, the code in afedR-en changed with the deprecation and arrival of new functions and packages. In order to keep the content up to date, I published a &lt;strong&gt;revision of the book&lt;/strong&gt; in &lt;a href=&#34;https://www.amazon.com/dp/B084LSNXMN&#34;&gt;Amazon&lt;/a&gt; and its &lt;a href=&#34;https://www.msperlin.com/afedR/&#34;&gt;web version&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This revision is not only for fixing broken code but also improves other important aspects of the book including ebook/html templates and end-of-chapter exercises. Here are the main changes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Improved and consistent css template for html and ebook.&lt;/li&gt;
&lt;li&gt;Over 100 end of chapter exercises. The exercises within the book are in the &lt;code&gt;exams&lt;/code&gt; format and can be exported to &lt;em&gt;e-learning&lt;/em&gt; platforms. Check out this &lt;a href=&#34;https://www.msperlin.com/post/2021-02-28-dynamic-exercises-afedr/&#34;&gt;blog post&lt;/a&gt; for details.&lt;/li&gt;
&lt;li&gt;To help the reader with topics that don’t quite fit with the main text, new text boxes with important and cautionary messages were implemented in all formats.&lt;/li&gt;
&lt;li&gt;New hardcover format is available at Amazon.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The R books are a lifelong project and I plan to keep improving the work as much as possible over the next years. I’m happy to see that, just like good wine, the content of the book only gets better with the passage of time.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>LANÇAMENTO - Análise de Dados Financeiros e Econômicos com o R (Terceira Edição)</title>
      <link>https://www.msperlin.com/post/2021-02-20-adfer-ed3-announcement/</link>
      <pubDate>Sat, 20 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2021-02-20-adfer-ed3-announcement/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;É com muito prazer que comunico o lançamento oficial da &lt;strong&gt;terceira edição&lt;/strong&gt; do livro &lt;strong&gt;Análise de Dados Financeiros e Econômicos com o R&lt;/strong&gt;. Encontrarás a obra na Amazon.com.br como um &lt;a href=&#34;https://www.amazon.com.br/dp/B08WNC27ZY&#34;&gt;ebook&lt;/a&gt; ou &lt;a href=&#34;https://www.amazon.com/dp/B08WP8CCDB&#34;&gt;livro impresso&lt;/a&gt;. A versão online do livro com os primeiros sete capítulos está disponível neste &lt;a href=&#34;https://www.msperlin.com/adfeR/&#34;&gt;link&lt;/a&gt;. Maiores detalhes, incluindo material suplementar, encontram-se na &lt;a href=&#34;https://www.msperlin.com/publication/2021_book-adfer-pt/&#34;&gt;página do livro&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A primeira edição foi lançada em 2016 e, desde então, venho atualizando o conteúdo com novos pacotes e novos capítulos. A terceira edição contempla as seguintes mudanças:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Todo o conteúdo do livro agora é disponibilizado via pacote &lt;code&gt;adfeR&lt;/code&gt; – &lt;a href=&#34;https://github.com/msperlin/adfeR&#34;&gt;link github&lt;/a&gt; – facilitando muito a reprodução de todos os exemplos de código.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Uso de &lt;strong&gt;caixas de textos customizadas&lt;/strong&gt; para indicar pontos importantes e precauções que os leitores devem ter em cada seção do livro.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Mais de &lt;strong&gt;100 exercícios de final de capítulo&lt;/strong&gt; foram criados e agora possuem gabarito em texto e código, disponível na versão &lt;a href=&#34;https://www.msperlin.com/adfeR/&#34;&gt;web do livro&lt;/a&gt;. Todos os exercícios estão disponíveis no formato &lt;code&gt;exams&lt;/code&gt; e podem ser compilados para um pdf ou então exportados para plataformas de &lt;em&gt;e-learning&lt;/em&gt;, tal como o &lt;em&gt;Moodle&lt;/em&gt; ou &lt;em&gt;Blackboard&lt;/em&gt; (veja seção &lt;em&gt;Conteúdo para Instrutores&lt;/em&gt; no Prefácio do livro). Um exemplo de compilação para pdf e Moodle está disponível neste &lt;a href=&#34;https://www.msperlin.com/post/2021-02-18-dynamic-exercises-adfer/&#34;&gt;post do blog&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Quatro novos pacotes&lt;/strong&gt; especializados na obtenção de dados financeiros e econômicos estão inclusos na nova edição. São estes: &lt;code&gt;GetDFPData2&lt;/code&gt;, &lt;code&gt;GetFREData&lt;/code&gt;, &lt;code&gt;GetQuandlData&lt;/code&gt; e &lt;code&gt;GetBCBData&lt;/code&gt;. Todos pacotes são estáveis, desenvolvidos por mim e serão mantidos ao longo do tempo. Assim, não corremos mais o risco de quebra de código devido a desatualização de um pacote por um autor.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Um novo capítulo sobre &lt;strong&gt;Otimização de Código em R&lt;/strong&gt;, discutindo melhorias na estrutura de código e também minimização do tempo de execução via estratégias de cacheamento local e processamento paralelo.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Uso de &lt;strong&gt;template customizado&lt;/strong&gt; para o ebook e html via CSS (&lt;em&gt;Cascading Style Sheets&lt;/em&gt;). Agora, o livro possui, sem dúvida, uma cara própria e consistente entre os diferentes formatos.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Se gostou do conteúdo, considere comprar o livro e &lt;strong&gt;deixar um feedback na &lt;a href=&#34;https://www.amazon.com.br/dp/B08WNC27ZY&#34;&gt;página da amazon&lt;/a&gt;&lt;/strong&gt;. Sua opinião é muito importante para promover o livro e ajudar outros a aprender mais sobre o R e RStudio. Como autor independente, certamente apreciarei o gesto e tomarei como fator motivante para futuras edições do livro.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Compilando Exercícios do Livro para pdf | html | Moodle | Blackboard</title>
      <link>https://www.msperlin.com/post/2021-02-18-dynamic-exercises-adfer/</link>
      <pubDate>Thu, 18 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2021-02-18-dynamic-exercises-adfer/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;A terceira edição do livro &lt;a href=&#34;https://www.msperlin.com/publication/2021_book-adfer-pt/&#34;&gt;Análise de Dados Financeiros e Econômicos&lt;/a&gt; contém mais de 100 exercícios de final de capítulo, com todas soluções disponíveis na &lt;a href=&#34;https://www.msperlin.com/adfeR/&#34;&gt;página do livro&lt;/a&gt;. Alternativamente, professores e instrutores podem compilar arquivos pdf dos exercícios para seus alunos com o pacote &lt;code&gt;adfeR&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;O primeiro passo é instalar o pacote via &lt;code&gt;devtools&lt;/code&gt; e também o &lt;code&gt;exams&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;#39;msperlin/adfeR&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Outro requisito é a instalação do &lt;code&gt;tinytex&lt;/code&gt; e Latex/texlive para a compilação em pdf:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tinytex::install_tinytex()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;como-funciona&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Como funciona?&lt;/h2&gt;
&lt;p&gt;Todos exercícios do livro estão no formato do pacote &lt;code&gt;exams&lt;/code&gt;. Cada exercício é um arquivo .Rmd contendo código, narrativa do exercício e a solução. Os arquivos em si podem ser encontrados no diretório de instalação do próprio pacote:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;eoc_dir &amp;lt;- adfeR::get_EOC_dir()

eoc_chapters &amp;lt;- fs::dir_ls(eoc_dir)
basename(eoc_chapters)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Cap01-Introducao&amp;quot;                   &amp;quot;Cap02-Operacoes-Basicas&amp;quot;           
##  [3] &amp;quot;Cap03-Scripts-Pesquisa&amp;quot;             &amp;quot;Cap04-Import-Local&amp;quot;                
##  [5] &amp;quot;Cap05-Import-Internet&amp;quot;              &amp;quot;Cap06-Objetos-Armazenamento&amp;quot;       
##  [7] &amp;quot;Cap07-Objetos-Basicos&amp;quot;              &amp;quot;Cap08-Programacao&amp;quot;                 
##  [9] &amp;quot;Cap09-Limpeza-e-estruturacao-dados&amp;quot; &amp;quot;Cap10-Figuras&amp;quot;                     
## [11] &amp;quot;Cap11-Modelagem&amp;quot;                    &amp;quot;Cap12-Reportando&amp;quot;                  
## [13] &amp;quot;Cap13-Otimizacao&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Cada um dos diretórios acima possui diversos exercícios. Veja o caso do capítulo 01:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;basename(fs::dir_ls(eoc_chapters[1]))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;adfeR_Cap-01_01_SPLUS.Rmd&amp;quot;            
##  [2] &amp;quot;adfeR_Cap-01_02_Autores-R.Rmd&amp;quot;        
##  [3] &amp;quot;adfeR_Cap-01_03_diferencial-R.Rmd&amp;quot;    
##  [4] &amp;quot;adfeR_Cap-01_04_nome-R.Rmd&amp;quot;           
##  [5] &amp;quot;adfeR_Cap-01_05_sobre-R.Rmd&amp;quot;          
##  [6] &amp;quot;adfeR_Cap-01_06_Tecnologias-R.Rmd&amp;quot;    
##  [7] &amp;quot;adfeR_Cap-01_07_rtools.Rmd&amp;quot;           
##  [8] &amp;quot;adfeR_Cap-01_08_Grupos.Rmd&amp;quot;           
##  [9] &amp;quot;adfeR_Cap-01_09_RBloggers.Rmd&amp;quot;        
## [10] &amp;quot;adfeR_Cap-01_10_Infraestrutura-TI.Rmd&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;exportando-para-pdf&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exportando para pdf&lt;/h2&gt;
&lt;p&gt;Para compilar para pdf os exercícios basta selecionar:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;nome dos estudantes&lt;/li&gt;
&lt;li&gt;id dos estudantes&lt;/li&gt;
&lt;li&gt;capítulos para incluir&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;e usar o código abaixo:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(adfeR)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: dplyr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;dplyr&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:stats&amp;#39;:
## 
##     filter, lag&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:base&amp;#39;:
## 
##     intersect, setdiff, setequal, union&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;names_students &amp;lt;- c(&amp;#39;Marcelo&amp;#39;, &amp;#39;Ricardo&amp;#39;, &amp;#39;Tarcizio&amp;#39;)
ids_students &amp;lt;- 1:length(names_students) # probably id card?
chapters &amp;lt;- 1:3 # chapters from 1 to 13
dir_output &amp;lt;- file.path(tempdir(), &amp;#39;ExamsFiles&amp;#39;)

l_exams &amp;lt;- build_exercises(students_names = names_students, 
                           students_ids = ids_students, 
                           chapters_to_include = chapters,
                           dir_out = dir_output)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Building exercise for Marcelo&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Adding content to tex&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Building pdf&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required namespace: tinytex&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Copying final pdf&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Building exercise for Ricardo&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Adding content to tex&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Building pdf&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Copying final pdf&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Building exercise for Tarcizio&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Adding content to tex&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Building pdf&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Copying final pdf&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## All exam files are available at folder &amp;quot;/tmp/RtmpboHyLI/ExamsFiles&amp;quot;.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Todos os arquivos pdfs estarão disponíveis na pasta &lt;code&gt;dir_output&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fs::dir_ls(dir_output)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## /tmp/RtmpboHyLI/ExamsFiles/Exercicios Teste_Ver 01_Marcelo.pdf
## /tmp/RtmpboHyLI/ExamsFiles/Exercicios Teste_Ver 02_Ricardo.pdf
## /tmp/RtmpboHyLI/ExamsFiles/Exercicios Teste_Ver 03_Tarcizio.pdf&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;O resultado final será conforme figura abaixo:&lt;/p&gt;
&lt;blockquote class=&#34;imgur-embed-pub&#34; lang=&#34;en&#34; data-id=&#34;a/62d4J1G&#34; data-context=&#34;false&#34;&gt;
&lt;a href=&#34;//imgur.com/a/62d4J1G&#34;&gt;&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;//s.imgur.com/min/embed.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div id=&#34;exportando-para-o-moodle&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exportando para o Moodle&lt;/h2&gt;
&lt;p&gt;Para quem usa o Moodle ou outra plataforma de &lt;em&gt;e-learning&lt;/em&gt; (Blackboard, Canvas, etc), a exportação para estes formatos é bem simples, basta indicar os arquivos de exercícios e usar as funções do pacote &lt;code&gt;exams&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;require(adfeR)
my_eoc_dir &amp;lt;- adfeR::get_EOC_dir()

available_chapters &amp;lt;- fs::dir_ls(my_eoc_dir)
exercise_files &amp;lt;- fs::dir_ls(available_chapters[1])
dir_output &amp;lt;- file.path(tempdir(), &amp;#39;moodle-test&amp;#39;)

exams::exams2moodle(file = exercise_files, 
                    name = &amp;#39;TestingMoodle&amp;#39;, 
                    dir = dir_output)

fs::dir_ls(dir_output)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## /tmp/RtmpboHyLI/moodle-test/TestingMoodle.xml&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Este arquivo .xml conterá todos os exercícios selecionados e pode ser facilmente importado no Moodle para ser aplicado aos alunos.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Looking back at 2020 and plans for 2021</title>
      <link>https://www.msperlin.com/post/2020-12-22-looking-back-2020/</link>
      <pubDate>Tue, 22 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2020-12-22-looking-back-2020/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Wow, what a &lt;strong&gt;long&lt;/strong&gt; year! The pandemic affected everyone, changing the way we live and relate to one another. This was a year full of lessons and we must be thankful and be able to appreciate life even more. Events such as these show how little our “problems” are when put into perspective.&lt;/p&gt;
&lt;p&gt;I’m lucky that, despite the lockdown, I was able to work from home this year. Lets have a look at the highlights.&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;highlights-of-2020&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Highlights of 2020&lt;/h1&gt;
&lt;div id=&#34;academic-papers&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Academic Papers&lt;/h2&gt;
&lt;p&gt;This year I published and co-authored two academic papers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://rac.anpad.org.br/index.php/rac/article/view/1420&#34;&gt;A Garch Tutorial in R - RAC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://linkinghub.elsevier.com/retrieve/pii/S1062940820301406&#34;&gt;Does algorithmic trading harm liquidity? Evidence from Brazil - NAJEF&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I also worked towards my paper pipeline in corporate finance, with the following papers, which are currently under review:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Financial Performance and Academic Titles of Advisers and Directors of Brazilian Companies&lt;/li&gt;
&lt;li&gt;Boards and Gender for Brazilian Listed Companies&lt;/li&gt;
&lt;li&gt;Description of Boards in Brazil&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;books&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Books&lt;/h2&gt;
&lt;p&gt;The second edition of my R book - &lt;a href=&#34;https://www.msperlin.com/publication/2020_book-afedr-en/&#34;&gt;Analyzing Financial and Economic Data with R&lt;/a&gt; was published in January 2020. I spend most of 2019 working towards this edition and I’m very pleased with the result. The book improved a lot, with a more polished content.&lt;/p&gt;
&lt;p&gt;I’m also happy to report that my two other books, &lt;a href=&#34;https://www.amazon.com.br/dp/B07DN4M357&#34;&gt;padfR&lt;/a&gt; and &lt;a href=&#34;https://www.amazon.com.br/dp/B07RR9K9PV&#34;&gt;pirf&lt;/a&gt;, are receiving great reviews in Amazon.com.br. This is great news, motivating the future editions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;R Packages&lt;/h2&gt;
&lt;p&gt;This year I “broke” package &lt;code&gt;GetDFPData&lt;/code&gt; into two: &lt;code&gt;GetDFPData2&lt;/code&gt; and &lt;code&gt;GetFREData&lt;/code&gt;. Both are still in &lt;a href=&#34;https://github.com/msperlin&#34;&gt;Github&lt;/a&gt; but I’ll soon release it to CRAN. You can read more about this decision &lt;a href=&#34;https://www.msperlin.com/post/2020-07-18-new_packages-getfredata-getdfpdata2/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Additionally, I also wrote the book package &lt;code&gt;afedR&lt;/code&gt;, which facilitates the reproducibility of all book examples. See more details about it &lt;a href=&#34;https://www.msperlin.com/post/2020-02-25-afedr-ed2-slides-available/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;checking-2019s-plans&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Checking 2019’s plans&lt;/h1&gt;
&lt;p&gt;At the end of 2019, my plans for 2020 &lt;a href=&#34;https://www.msperlin.com/post/2019-12-15-looking-back-2019/&#34;&gt;were&lt;/a&gt;:&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;Publish afedR (analyzing financial and economic data with R)&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;https://www.msperlin.com/post/2020-01-15-afedr-ed2-announcement/&#34;&gt;Done! :)&lt;/a&gt;
&lt;/dd&gt;
&lt;dt&gt;Finish board papers&lt;/dt&gt;
&lt;dd&gt;Almost Done. All papers are now in review and, hopefully, are going to be published soon.
&lt;/dd&gt;
&lt;dt&gt;Start “personal finance project”&lt;/dt&gt;
&lt;dd&gt;Not done. This is an idea that I’m struggling with. I’m not really sure how to implement it and still have to figure out the details.
&lt;/dd&gt;
&lt;/dl&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;plans-for-2021&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Plans for 2021&lt;/h1&gt;
&lt;dl&gt;
&lt;dt&gt;Publish new R/ggplot2 book (&lt;em&gt;Visualização de Dados com R&lt;/em&gt;)&lt;/dt&gt;
&lt;dd&gt;This book will be mostly about using &lt;code&gt;ggplot2&lt;/code&gt; in data visualization. It will be written in portuguese and, if it comes out right and do well, I’ll translate into english. I already got 2 chapters written, but still missing a lot of work and content.
&lt;/dd&gt;
&lt;dt&gt;Publish third edition of &lt;em&gt;Análise de Dados Financeiros e Econômicos com o R&lt;/em&gt;&lt;/dt&gt;
&lt;dd&gt;The portuguese version of my R book is already in its third edition and I’m very excited for this new edition. It will incorporate many changes from the english edition and more!
&lt;/dd&gt;
&lt;dt&gt;Publish board papers&lt;/dt&gt;
&lt;dd&gt;Soon. The three papers are in revision.
&lt;/dd&gt;
&lt;dt&gt;Publish paper about academic inbreeding&lt;/dt&gt;
&lt;dd&gt;I’m writing a new paper about the effects of academic inbreeding in Brazil using Lattes data. The paper is its final internal review and will soon be sent to for its formal review. The results are very interesting and I hope to write more about it soon.
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>New Packages: GetDFPdata = GetDFPData2 &#43; GetFREData</title>
      <link>https://www.msperlin.com/post/2020-07-18-new_packages-getfredata-getdfpdata2/</link>
      <pubDate>Sat, 18 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2020-07-18-new_packages-getfredata-getdfpdata2/</guid>
      <description>


&lt;p&gt;Back in 2017 I wrote the first version of package GetDFPData, along with a &lt;a href=&#34;http://bibliotecadigital.fgv.br/ojs/index.php/rbfin/article/view/78654&#34;&gt;paper&lt;/a&gt; describing the code and providing an empirical application.&lt;/p&gt;
&lt;p&gt;However, maintaining the package over the years has been frustrating. The code is becoming increasingly complex, much due to the fact that it handles FRE and DFP data in a single package. Execution speed for large scale importation – many years and many companies – is not reasonable. In top of that, B3’s website is unstable as a source of data and it seems it will stay like that for a long time.&lt;/p&gt;
&lt;p&gt;Additionally, back in april 2020 (see this &lt;a href=&#34;https://www.msperlin.com/post/2020-04-20-new-package-getcvmdata/&#34;&gt;blog post&lt;/a&gt;), I started to work with CVM data from its &lt;a href=&#34;http://dados.cvm.gov.br/dados/CIA_ABERTA/&#34;&gt;ftp site&lt;/a&gt;. The experience has been great. The data is solid, matching all B3’s numbers, with easy and fast access. For example, I can download 10 years of financial data for all available companies in less than 10 minutes.&lt;/p&gt;
&lt;p&gt;After some considerable thought, I’m convinced that is much easier to maintain two separate packages, instead of combining both in a single module such as in &lt;code&gt;GetDFPData&lt;/code&gt;. With that, I’m releasing two new packages: &lt;code&gt;GetDFPData2&lt;/code&gt;, and &lt;code&gt;GetFREData&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The first, &lt;code&gt;GetDFPData2&lt;/code&gt; (previously called &lt;a href=&#34;https://www.msperlin.com/post/2020-04-20-new-package-getcvmdata/&#34;&gt;GetCVMData&lt;/a&gt;), is a backwards incompatible version of &lt;code&gt;GetDFPData&lt;/code&gt;, using the CVM ftp site as it source and focusing in one purpose: downloading annual and quarterly financial reports. The second, &lt;code&gt;GetFREData&lt;/code&gt; only imports corporate data from the FRE system.&lt;/p&gt;
&lt;div id=&#34;installation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# not in CRAN, install from github
devtools::install_github(&amp;#39;msperlin/GetDFPData2&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# not in CRAN, install from github
devtools::install_github(&amp;#39;msperlin/GetFREData&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;examples-of-usage&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Examples of Usage&lt;/h2&gt;
&lt;div id=&#34;getdfpdata2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;GetDFPData2&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(GetDFPData2)
library(tidyverse)

# information about companies
df_info &amp;lt;- get_info_companies(tempdir())
df_info &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2,530 × 47
##    CNPJ               DENOM_SOCIAL DENOM_COMERC DT_REG     DT_CONST   DT_CANCEL 
##    &amp;lt;chr&amp;gt;              &amp;lt;chr&amp;gt;        &amp;lt;chr&amp;gt;        &amp;lt;date&amp;gt;     &amp;lt;date&amp;gt;     &amp;lt;date&amp;gt;    
##  1 08.773.135/0001-00 2W ENERGIA … &amp;lt;NA&amp;gt;         2020-10-29 2007-03-23 NA        
##  2 11.396.633/0001-87 3A COMPANHI… TRIPLO A  C… 2010-03-08 2009-11-03 2015-12-18
##  3 12.091.809/0001-55 3R PETROLEU… &amp;lt;NA&amp;gt;         2020-11-09 2010-06-08 NA        
##  4 01.547.749/0001-16 521 PARTICI… 521 PARTICI… 1997-07-11 1996-07-30 NA        
##  5 01.851.771/0001-55 524 PARTICI… 524 PARTICI… 1997-05-30 1997-04-02 NA        
##  6 01.919.008/0001-19 525 PARTICI… 525 PARTICI… 1997-07-16 1997-04-02 2006-05-30
##  7 92.659.614/0001-06 A J RENNER … A J RENNER   1969-06-24 NA         1998-06-17
##  8 02.288.752/0001-25 A.P. PARTIC… A.P. PARTIC… 1998-01-21 1997-12-14 2004-12-23
##  9 21.649.280/0001-33 ABC DADOS E… ABC COMPUTA… 1988-06-03 NA         1993-03-05
## 10 02.258.274/0001-00 ABC SUPERME… ABC SUPERME… 1998-02-27 1997-09-30 2001-12-17
## # … with 2,520 more rows, and 41 more variables: MOTIVO_CANCEL &amp;lt;chr&amp;gt;,
## #   SIT_REG &amp;lt;chr&amp;gt;, DT_INI_SIT &amp;lt;date&amp;gt;, CD_CVM &amp;lt;dbl&amp;gt;, SETOR_ATIV &amp;lt;chr&amp;gt;,
## #   TP_MERC &amp;lt;chr&amp;gt;, CATEG_REG &amp;lt;chr&amp;gt;, DT_INI_CATEG &amp;lt;date&amp;gt;, SIT_EMISSOR &amp;lt;chr&amp;gt;,
## #   DT_INI_SIT_EMISSOR &amp;lt;date&amp;gt;, CONTROLE_ACIONARIO &amp;lt;chr&amp;gt;, TP_ENDER &amp;lt;chr&amp;gt;,
## #   LOGRADOURO &amp;lt;chr&amp;gt;, COMPL &amp;lt;chr&amp;gt;, BAIRRO &amp;lt;chr&amp;gt;, MUN &amp;lt;chr&amp;gt;, UF &amp;lt;chr&amp;gt;,
## #   PAIS &amp;lt;chr&amp;gt;, CEP &amp;lt;dbl&amp;gt;, DDD_TEL &amp;lt;chr&amp;gt;, TEL &amp;lt;dbl&amp;gt;, DDD_FAX &amp;lt;chr&amp;gt;, FAX &amp;lt;dbl&amp;gt;,
## #   EMAIL &amp;lt;chr&amp;gt;, TP_RESP &amp;lt;chr&amp;gt;, RESP &amp;lt;chr&amp;gt;, DT_INI_RESP &amp;lt;date&amp;gt;, …&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;search_company(&amp;#39;grendene&amp;#39;)

# downloading DFP data
l_dfp &amp;lt;- get_dfp_data(companies_cvm_codes = 19615, 
                      use_memoise = FALSE,
                      clean_data = TRUE,
                      type_docs = c(&amp;#39;DRE&amp;#39;), 
                      type_format = &amp;#39;con&amp;#39;,
                      first_year = 2010, 
                      last_year = 2020)

glimpse(l_dfp)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 1
##  $ DF Consolidado - Demonstração do Resultado: tibble [340 × 16] (S3: tbl_df/tbl/data.frame)
##   ..$ CNPJ_CIA    : chr [1:340] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; ...
##   ..$ CD_CVM      : num [1:340] 19615 19615 19615 19615 19615 ...
##   ..$ DT_REFER    : Date[1:340], format: &amp;quot;2010-12-31&amp;quot; &amp;quot;2010-12-31&amp;quot; ...
##   ..$ DT_INI_EXERC: Date[1:340], format: &amp;quot;2010-01-01&amp;quot; &amp;quot;2010-01-01&amp;quot; ...
##   ..$ DT_FIM_EXERC: Date[1:340], format: &amp;quot;2010-12-31&amp;quot; &amp;quot;2010-12-31&amp;quot; ...
##   ..$ DENOM_CIA   : chr [1:340] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; ...
##   ..$ VERSAO      : num [1:340] 2 2 2 2 2 2 2 2 2 2 ...
##   ..$ GRUPO_DFP   : chr [1:340] &amp;quot;DF Consolidado - Demonstração do Resultado&amp;quot; &amp;quot;DF Consolidado - Demonstração do Resultado&amp;quot; &amp;quot;DF Consolidado - Demonstração do Resultado&amp;quot; &amp;quot;DF Consolidado - Demonstração do Resultado&amp;quot; ...
##   ..$ MOEDA       : chr [1:340] &amp;quot;REAL&amp;quot; &amp;quot;REAL&amp;quot; &amp;quot;REAL&amp;quot; &amp;quot;REAL&amp;quot; ...
##   ..$ ESCALA_MOEDA: chr [1:340] &amp;quot;MIL&amp;quot; &amp;quot;MIL&amp;quot; &amp;quot;MIL&amp;quot; &amp;quot;MIL&amp;quot; ...
##   ..$ ORDEM_EXERC : chr [1:340] &amp;quot;ÚLTIMO&amp;quot; &amp;quot;ÚLTIMO&amp;quot; &amp;quot;ÚLTIMO&amp;quot; &amp;quot;ÚLTIMO&amp;quot; ...
##   ..$ CD_CONTA    : chr [1:340] &amp;quot;3.01&amp;quot; &amp;quot;3.02&amp;quot; &amp;quot;3.03&amp;quot; &amp;quot;3.04&amp;quot; ...
##   ..$ DS_CONTA    : chr [1:340] &amp;quot;Receita de Venda de Bens e/ou Serviços&amp;quot; &amp;quot;Custo dos Bens e/ou Serviços Vendidos&amp;quot; &amp;quot;Resultado Bruto&amp;quot; &amp;quot;Despesas/Receitas Operacionais&amp;quot; ...
##   ..$ VL_CONTA    : num [1:340] 1604507 -953261 651246 -442833 -377010 ...
##   ..$ COLUNA_DF   : logi [1:340] NA NA NA NA NA NA ...
##   ..$ source_file : chr [1:340] &amp;quot;dfp_cia_aberta_DRE_con_2010.csv&amp;quot; &amp;quot;dfp_cia_aberta_DRE_con_2010.csv&amp;quot; &amp;quot;dfp_cia_aberta_DRE_con_2010.csv&amp;quot; &amp;quot;dfp_cia_aberta_DRE_con_2010.csv&amp;quot; ...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dre_annual &amp;lt;- l_dfp$`DF Consolidado - Demonstração do Resultado`

p &amp;lt;- ggplot(dre_annual %&amp;gt;%
              filter(DS_CONTA == &amp;#39;Lucro/Prejuízo Consolidado do Período&amp;#39;), 
            aes(x = DT_REFER, y = VL_CONTA)) + 
  geom_col() +
  facet_wrap(~DENOM_CIA, scales = &amp;#39;free&amp;#39;) + 
  theme_bw()

p&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2020-07-18-new_packages-GetFREData-GetDFPData2_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;getfredata&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;GetFREData&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(GetFREData)
library(tidyverse)

l_fre &amp;lt;- get_fre_data(companies_cvm_codes = 19615,
                      fre_to_read = &amp;#39;last&amp;#39;,
                      first_year = 2018,
                      last_year = 2020)

glimpse(l_fre)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 21
##  $ df_stockholders            :&amp;#39;data.frame&amp;#39;: 30 obs. of  18 variables:
##   ..$ CNPJ_CIA               : chr [1:30] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; ...
##   ..$ DENOM_CIA              : chr [1:30] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; ...
##   ..$ DT_REFER               : Date[1:30], format: &amp;quot;2018-01-01&amp;quot; &amp;quot;2018-01-01&amp;quot; ...
##   ..$ CD_CVM                 : num [1:30] 19615 19615 19615 19615 19615 ...
##   ..$ ID_DOC                 : num [1:30] 83396 83396 83396 83396 83396 ...
##   ..$ VERSAO                 : num [1:30] 16 16 16 16 16 16 16 16 16 16 ...
##   ..$ type.register          : chr [1:30] &amp;quot;Acionista&amp;quot; &amp;quot;Acionista&amp;quot; &amp;quot;Acionista&amp;quot; &amp;quot;Acionista&amp;quot; ...
##   ..$ id.person              : chr [1:30] &amp;quot;37071813833   &amp;quot; &amp;quot;09867597087   &amp;quot; &amp;quot;09864784072   &amp;quot; &amp;quot;68595743053   &amp;quot; ...
##   ..$ id.nationality         : chr [1:30] &amp;quot;Brasileira&amp;quot; &amp;quot;Brasileiro&amp;quot; &amp;quot;Brasileiro&amp;quot; &amp;quot;Brasileiro&amp;quot; ...
##   ..$ id.state               : chr [1:30] &amp;quot;São Paulo&amp;quot; &amp;quot;Rio Grande do Sul&amp;quot; &amp;quot;Rio Grande do Sul&amp;quot; &amp;quot;Rio Grande do Sul&amp;quot; ...
##   ..$ id.country             : logi [1:30] NA NA NA NA NA NA ...
##   ..$ name.stockholder       : chr [1:30] &amp;quot;Gabriella de Camargo Bartelle&amp;quot; &amp;quot;Alexandre Grendene Bartelle&amp;quot; &amp;quot;Pedro Grendene Bartelle&amp;quot; &amp;quot;Pedro Bartelle&amp;quot; ...
##   ..$ type.stockholder       : chr [1:30] &amp;quot;Fisica&amp;quot; &amp;quot;Fisica&amp;quot; &amp;quot;Fisica&amp;quot; &amp;quot;Fisica&amp;quot; ...
##   ..$ qtd.ord.shares         : chr [1:30] &amp;quot;28912677&amp;quot; &amp;quot;371651807&amp;quot; &amp;quot;125312376&amp;quot; &amp;quot;36465597&amp;quot; ...
##   ..$ perc.ord.shares        : chr [1:30] &amp;quot;3.200000&amp;quot; &amp;quot;41.200000&amp;quot; &amp;quot;13.890000&amp;quot; &amp;quot;4.040000&amp;quot; ...
##   ..$ qtd.pref.shares        : chr [1:30] &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; ...
##   ..$ perc.pref.shares       : chr [1:30] &amp;quot;0.000000&amp;quot; &amp;quot;0.000000&amp;quot; &amp;quot;0.000000&amp;quot; &amp;quot;0.000000&amp;quot; ...
##   ..$ controlling.stockholder: logi [1:30] TRUE TRUE TRUE TRUE TRUE TRUE ...
##  $ df_capital                 :&amp;#39;data.frame&amp;#39;: 6 obs. of  9 variables:
##   ..$ CNPJ_CIA   : chr [1:6] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; ...
##   ..$ DENOM_CIA  : chr [1:6] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; ...
##   ..$ DT_REFER   : Date[1:6], format: &amp;quot;2018-01-01&amp;quot; &amp;quot;2018-01-01&amp;quot; ...
##   ..$ CD_CVM     : num [1:6] 19615 19615 19615 19615 19615 ...
##   ..$ ID_DOC     : num [1:6] 83396 83396 94693 94693 103471 ...
##   ..$ VERSAO     : num [1:6] 16 16 18 18 11 11
##   ..$ stock.type : chr [1:6] &amp;quot;ON&amp;quot; &amp;quot;PN&amp;quot; &amp;quot;ON&amp;quot; &amp;quot;PN&amp;quot; ...
##   ..$ stock.class: chr [1:6] &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; ...
##   ..$ qtd.issued : num [1:6] 9.02e+08 0.00 9.02e+08 0.00 9.02e+08 ...
##  $ df_stock_values            :&amp;#39;data.frame&amp;#39;: 6 obs. of  13 variables:
##   ..$ CNPJ_CIA              : chr [1:6] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; ...
##   ..$ DENOM_CIA             : chr [1:6] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; ...
##   ..$ DT_REFER              : Date[1:6], format: &amp;quot;2018-01-01&amp;quot; &amp;quot;2018-01-01&amp;quot; ...
##   ..$ CD_CVM                : num [1:6] 19615 19615 19615 19615 19615 ...
##   ..$ ID_DOC                : num [1:6] 83396 83396 94693 94693 103471 ...
##   ..$ VERSAO                : num [1:6] 16 16 18 18 11 11
##   ..$ stock.class           : chr [1:6] &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; ...
##   ..$ stock.type            : chr [1:6] &amp;quot;ON&amp;quot; &amp;quot;PN&amp;quot; &amp;quot;ON&amp;quot; &amp;quot;PN&amp;quot; ...
##   ..$ max.price             : num [1:6] 28.8 0 8.24 0 12.65 ...
##   ..$ min.price             : num [1:6] 25.32 0 6.59 0 7.94 ...
##   ..$ avg.price             : num [1:6] 26.7 0 7.6 0 10.5 ...
##   ..$ flag.missing.avg.price: logi [1:6] FALSE NA FALSE NA FALSE NA
##   ..$ qtd.issued            : num [1:6] 9.02e+08 0.00 9.02e+08 0.00 9.02e+08 ...
##  $ df_mkt_value               :&amp;#39;data.frame&amp;#39;: 3 obs. of  9 variables:
##   ..$ CNPJ_CIA     : chr [1:3] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot;
##   ..$ DENOM_CIA    : chr [1:3] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot;
##   ..$ DT_REFER     : Date[1:3], format: &amp;quot;2018-01-01&amp;quot; &amp;quot;2019-01-01&amp;quot; ...
##   ..$ CD_CVM       : num [1:3] 19615 19615 19615
##   ..$ ID_DOC       : num [1:3] 83396 94693 103471
##   ..$ VERSAO       : num [1:3] 16 18 11
##   ..$ mkt.avg.value: num [1:3] 2.41e+10 6.86e+09 9.44e+09
##   ..$ mkt.min.value: num [1:3] 2.28e+10 5.95e+09 7.16e+09
##   ..$ mkt.max.value: num [1:3] 2.60e+10 7.43e+09 1.14e+10
##  $ df_increase_capital        :&amp;#39;data.frame&amp;#39;: 0 obs. of  0 variables
##  $ df_capital_reduction       :&amp;#39;data.frame&amp;#39;: 0 obs. of  0 variables
##  $ df_compensation            :&amp;#39;data.frame&amp;#39;: 3 obs. of  22 variables:
##   ..$ CNPJ_CIA                          : chr [1:3] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot;
##   ..$ DENOM_CIA                         : chr [1:3] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot;
##   ..$ DT_REFER                          : Date[1:3], format: &amp;quot;2018-01-01&amp;quot; &amp;quot;2019-01-01&amp;quot; ...
##   ..$ CD_CVM                            : num [1:3] 19615 19615 19615
##   ..$ ID_DOC                            : num [1:3] 83396 94693 103471
##   ..$ VERSAO                            : num [1:3] 16 18 11
##   ..$ level.remuneration                : chr [1:3] &amp;quot;Management Council&amp;quot; &amp;quot;Management Council&amp;quot; &amp;quot;Management Council&amp;quot;
##   ..$ qtd.members                       : num [1:3] 6 6 6
##   ..$ qtd.remunerated.members           : num [1:3] 6 6 6
##   ..$ total.value.remuneration          : num [1:3] 1116000 1146000 1188000
##   ..$ fixed.salary                      : num [1:3] 1116000 1146000 1188000
##   ..$ fixed.benefits                    : num [1:3] 0 0 0
##   ..$ fixed.participations              : num [1:3] 0 0 0
##   ..$ fixed.others                      : num [1:3] 0 0 0
##   ..$ variable.bonus                    : num [1:3] 0 0 0
##   ..$ variable.results.participation    : num [1:3] 0 0 0
##   ..$ variable.meetings.participation   : num [1:3] 0 0 0
##   ..$ variable.commissions.participation: num [1:3] 0 0 0
##   ..$ variable.others                   : num [1:3] 0 0 0
##   ..$ post.job.compensation             : num [1:3] 0 0 0
##   ..$ ceasing.job.compensation          : num [1:3] 0 0 0
##   ..$ stocks.options.benefits           : num [1:3] 0 0 0
##  $ df_compensation_summary    :&amp;#39;data.frame&amp;#39;: 9 obs. of  13 variables:
##   ..$ CNPJ_CIA               : chr [1:9] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; ...
##   ..$ DENOM_CIA              : chr [1:9] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; ...
##   ..$ DT_REFER               : Date[1:9], format: &amp;quot;2018-01-01&amp;quot; &amp;quot;2018-01-01&amp;quot; ...
##   ..$ CD_CVM                 : num [1:9] 19615 19615 19615 19615 19615 ...
##   ..$ ID_DOC                 : num [1:9] 83396 83396 83396 94693 94693 ...
##   ..$ VERSAO                 : num [1:9] 16 16 16 18 18 18 11 11 11
##   ..$ level.remuneration     : chr [1:9] &amp;quot;Management Council&amp;quot; &amp;quot;Statutory Directors&amp;quot; &amp;quot;Fiscal Council&amp;quot; &amp;quot;Management Council&amp;quot; ...
##   ..$ qtd.members            : num [1:9] 6 3 3 6 3 3 6 3 3
##   ..$ qtd.remunerated.members: num [1:9] 6 3 3 6 3 3 6 3 3
##   ..$ max.remuneration       : num [1:9] 186000 2748408 142500 191000 2876477 ...
##   ..$ mean.remuneration      : num [1:9] 186000 2050482 142500 191000 2134281 ...
##   ..$ min.remuneration       : num [1:9] 186000 1423997 142500 191000 1468768 ...
##   ..$ observations           : logi [1:9] NA NA NA NA NA NA ...
##  $ df_transactions_related    :&amp;#39;data.frame&amp;#39;: 127 obs. of  17 variables:
##   ..$ CNPJ_CIA                      : chr [1:127] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; ...
##   ..$ DENOM_CIA                     : chr [1:127] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; ...
##   ..$ DT_REFER                      : Date[1:127], format: &amp;quot;2018-01-01&amp;quot; &amp;quot;2018-01-01&amp;quot; ...
##   ..$ CD_CVM                        : num [1:127] 19615 19615 19615 19615 19615 ...
##   ..$ ID_DOC                        : num [1:127] 83396 83396 83396 83396 83396 ...
##   ..$ VERSAO                        : num [1:127] 16 16 16 16 16 16 16 16 16 16 ...
##   ..$ id.transaction                : chr [1:127] &amp;quot;2403&amp;quot; &amp;quot;2404&amp;quot; &amp;quot;2405&amp;quot; &amp;quot;2406&amp;quot; ...
##   ..$ name.related.part             : chr [1:127] &amp;quot;Mailson da Nóbrega Consultoria S/C Ltda&amp;quot; &amp;quot;Vulcabras|Azaleia Argentina S.A.&amp;quot; &amp;quot;Mailson da Nóbrega Consultoria S/C Ltda&amp;quot; &amp;quot;Grendene USA, Inc&amp;quot; ...
##   ..$ date.transaction              : Date[1:127], format: &amp;quot;2016-12-31&amp;quot; &amp;quot;2015-12-31&amp;quot; ...
##   ..$ description.related.part      : chr [1:127] &amp;quot;Empresa pertencente a membro do Conselho de Administração&amp;quot; &amp;quot;Empresa controlada por acionista da Grendene S.A.&amp;quot; &amp;quot;Empresa pertencente a membro do Conselho de Administração&amp;quot; &amp;quot;Empresa controlada&amp;quot; ...
##   ..$ description.transaction       : chr [1:127] &amp;quot;Assessoria na área econômica financeira&amp;quot; &amp;quot;Cliente - venda de insumos&amp;quot; &amp;quot;Assessoria na área econômica financeira&amp;quot; &amp;quot;Cliente - venda de calçados para abastecimento do mercado onde a mesma está sediada&amp;quot; ...
##   ..$ value.transaction             : chr [1:127] &amp;quot;72000.00&amp;quot; &amp;quot;306000.00&amp;quot; &amp;quot;72000.00&amp;quot; &amp;quot;14641000.00&amp;quot; ...
##   ..$ description.guarantees        : chr [1:127] &amp;quot;Não aplicável&amp;quot; &amp;quot;Não aplicável&amp;quot; &amp;quot;Não aplicável&amp;quot; &amp;quot;Não aplicável&amp;quot; ...
##   ..$ description.transaction.period: chr [1:127] &amp;quot;Prazo indeterminado&amp;quot; &amp;quot;Prazo indeterminado&amp;quot; &amp;quot;Prazo indeterminado&amp;quot; &amp;quot;Prazo indeterminado&amp;quot; ...
##   ..$ description.rescision         : chr [1:127] &amp;quot;Encerramento das atividades&amp;quot; &amp;quot;Encerramento das atividades&amp;quot; &amp;quot;Encerramento das atividades&amp;quot; &amp;quot;Encerramento das atividades&amp;quot; ...
##   ..$ interest.rate                 : num [1:127] 0 0 0 0 0 0 0 0 0 0 ...
##   ..$ value.balance                 : chr [1:127] &amp;quot;R$0,00&amp;quot; &amp;quot;R$0,00&amp;quot; &amp;quot;R$0,00&amp;quot; &amp;quot;R$9.311.000,00&amp;quot; ...
##  $ df_other_events            :&amp;#39;data.frame&amp;#39;: 3 obs. of  12 variables:
##   ..$ CNPJ_CIA              : chr [1:3] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot;
##   ..$ DENOM_CIA             : chr [1:3] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot;
##   ..$ DT_REFER              : Date[1:3], format: &amp;quot;2018-01-01&amp;quot; &amp;quot;2019-01-01&amp;quot; ...
##   ..$ CD_CVM                : num [1:3] 19615 19615 19615
##   ..$ ID_DOC                : num [1:3] 83396 94693 103471
##   ..$ VERSAO                : num [1:3] 16 18 11
##   ..$ approval.date         : Date[1:3], format: &amp;quot;2018-04-23&amp;quot; &amp;quot;2018-04-23&amp;quot; ...
##   ..$ type.event            : chr [1:3] &amp;quot;Desdobramento&amp;quot; &amp;quot;Desdobramento&amp;quot; &amp;quot;Desdobramento&amp;quot;
##   ..$ qtd.ord.shares.before : num [1:3] 3.01e+08 3.01e+08 3.01e+08
##   ..$ qtd.ord.shares.after  : num [1:3] 9.02e+08 9.02e+08 9.02e+08
##   ..$ qtd.pref.shares.before: num [1:3] 0 0 0
##   ..$ qtd.pref.shares.after : num [1:3] 0 0 0
##  $ df_stock_repurchases       :&amp;#39;data.frame&amp;#39;: 12 obs. of  16 variables:
##   ..$ CNPJ_CIA                     : chr [1:12] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; ...
##   ..$ DENOM_CIA                    : chr [1:12] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; ...
##   ..$ DT_REFER                     : Date[1:12], format: &amp;quot;2018-01-01&amp;quot; &amp;quot;2018-01-01&amp;quot; ...
##   ..$ CD_CVM                       : num [1:12] 19615 19615 19615 19615 19615 ...
##   ..$ ID_DOC                       : num [1:12] 83396 83396 83396 83396 94693 ...
##   ..$ VERSAO                       : num [1:12] 16 16 16 16 18 18 18 18 11 11 ...
##   ..$ date.decision                : Date[1:12], format: &amp;quot;2017-07-27&amp;quot; &amp;quot;2016-02-25&amp;quot; ...
##   ..$ date.start.repurchase        : Date[1:12], format: &amp;quot;2017-08-25&amp;quot; &amp;quot;2016-02-26&amp;quot; ...
##   ..$ date.end.repurchase          : Date[1:12], format: &amp;quot;2019-02-21&amp;quot; &amp;quot;2017-08-24&amp;quot; ...
##   ..$ available.capital.repurchase : num [1:12] 14563536 16117227 17000000 19072706 29188481 ...
##   ..$ type.stock                   : chr [1:12] &amp;quot;Ordinária&amp;quot; &amp;quot;Ordinária&amp;quot; &amp;quot;Ordinária&amp;quot; &amp;quot;Ordinária&amp;quot; ...
##   ..$ qtd.stocks.repurchased       : num [1:12] 1312343 547841 0 487096 130000 ...
##   ..$ qtd.stocks.predicted         : num [1:12] 2.0e+06 1.5e+06 1.5e+06 1.5e+06 6.0e+06 2.0e+06 1.5e+06 1.5e+06 2.5e+07 6.0e+06 ...
##   ..$ average.price                : num [1:12] 26.78 17.96 0 14.38 7.36 ...
##   ..$ percent.stock.float.purchased: num [1:12] 65.6 36.5 0 32.47 2.17 ...
##   ..$ percent.stock.float.predicted: chr [1:12] &amp;quot;2.380000&amp;quot; &amp;quot;1.820000&amp;quot; &amp;quot;1.910000&amp;quot; &amp;quot;1.950000&amp;quot; ...
##  $ df_debt_composition        :&amp;#39;data.frame&amp;#39;: 6 obs. of  13 variables:
##   ..$ CNPJ_CIA               : chr [1:6] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; ...
##   ..$ DENOM_CIA              : chr [1:6] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; ...
##   ..$ DT_REFER               : Date[1:6], format: &amp;quot;2018-01-01&amp;quot; &amp;quot;2018-01-01&amp;quot; ...
##   ..$ CD_CVM                 : num [1:6] 19615 19615 19615 19615 19615 ...
##   ..$ ID_DOC                 : num [1:6] 83396 83396 94693 94693 103471 ...
##   ..$ VERSAO                 : num [1:6] 16 16 18 18 11 11
##   ..$ type.debt              : chr [1:6] &amp;quot;Empréstimo&amp;quot; &amp;quot;Financiamento&amp;quot; &amp;quot;Empréstimo&amp;quot; &amp;quot;Financiamento&amp;quot; ...
##   ..$ type.debt.guarantee    : chr [1:6] &amp;quot;Garantia Real&amp;quot; &amp;quot;Quirografárias&amp;quot; &amp;quot;Garantia Real&amp;quot; &amp;quot;Quirografárias&amp;quot; ...
##   ..$ debt.value.under.1.year: num [1:6] 1.08e+07 3.11e+08 1.07e+07 3.56e+08 1.04e+07 ...
##   ..$ debt.value.1.to.3.years: num [1:6] 31389447 2412999 20681054 6930075 10340527 ...
##   ..$ debt.value.3.to.5.years: num [1:6] 0 2522127 0 1194397 0 ...
##   ..$ debt.value.more.5.years: num [1:6] 0 0 0 0 0 0
##   ..$ debt.total             : num [1:6] 4.22e+07 3.16e+08 3.14e+07 3.64e+08 2.07e+07 ...
##  $ df_board_composition       :&amp;#39;data.frame&amp;#39;: 47 obs. of  22 variables:
##   ..$ CNPJ_CIA                : chr [1:47] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; ...
##   ..$ DENOM_CIA               : chr [1:47] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; ...
##   ..$ DT_REFER                : Date[1:47], format: &amp;quot;2018-01-01&amp;quot; &amp;quot;2018-01-01&amp;quot; ...
##   ..$ CD_CVM                  : num [1:47] 19615 19615 19615 19615 19615 ...
##   ..$ ID_DOC                  : num [1:47] 83396 83396 83396 83396 83396 ...
##   ..$ VERSAO                  : num [1:47] 16 16 16 16 16 16 16 16 16 16 ...
##   ..$ person.name             : chr [1:47] &amp;quot;Gelson Luis Rostirolla&amp;quot; &amp;quot;Rudimar Dall Onder&amp;quot; &amp;quot;Francisco Olinto Velo Schmitt&amp;quot; &amp;quot;Alexandre Grendene Bartelle&amp;quot; ...
##   ..$ person.cpf              : num [1:47] 1.48e+10 2.55e+10 2.64e+10 9.87e+09 4.30e+09 ...
##   ..$ person.profession       : chr [1:47] &amp;quot;Administrador de Empresas&amp;quot; &amp;quot;Engenheiro Mecânico&amp;quot; &amp;quot;Engenheiro Elétrico&amp;quot; &amp;quot;Industrial&amp;quot; ...
##   ..$ person.cv               : chr [1:47] &amp;quot;Formação: Administração de Empresas (1977) e Ciências Contábeis (1979) pela UNOESC – Universidade do Oeste Cata&amp;quot;| __truncated__ &amp;quot;Formação: Engenharia Mecânica (1981) pela Universidade de Caxias do SUL (UCS). Iniciou suas atividades na Compa&amp;quot;| __truncated__ &amp;quot;Formação: Engenharia Elétrica pela Universidade Federal do Rio Grande do Sul em 1978; Especialização e Mestrado&amp;quot;| __truncated__ &amp;quot;Fundador da Companhia e Presidente do Conselho de Administração desde 18 de agosto de 2004. \n\nFormação: Bacha&amp;quot;| __truncated__ ...
##   ..$ person.dob              : Date[1:47], format: &amp;quot;1953-02-14&amp;quot; &amp;quot;1956-08-14&amp;quot; ...
##   ..$ code.type.board         : chr [1:47] &amp;quot;1&amp;quot; &amp;quot;1&amp;quot; &amp;quot;1&amp;quot; &amp;quot;2&amp;quot; ...
##   ..$ desc.type.board         : chr [1:47] &amp;quot;Director&amp;quot; &amp;quot;Director&amp;quot; &amp;quot;Director&amp;quot; &amp;quot;Management Council&amp;quot; ...
##   ..$ desc.type.board2        : logi [1:47] NA NA NA NA NA NA ...
##   ..$ code.type.job           : chr [1:47] &amp;quot;11&amp;quot; &amp;quot;10&amp;quot; &amp;quot;12&amp;quot; &amp;quot;20&amp;quot; ...
##   ..$ desc.job                : chr [1:47] &amp;quot;Não ocupa outras funções no emissor.&amp;quot; &amp;quot;Não ocupa outras funções no emissor.&amp;quot; &amp;quot;Diretor Administrativo Financeiro&amp;quot; &amp;quot;Presidente do comitê de gestão do programa de stock option.&amp;quot; ...
##   ..$ date.election           : Date[1:47], format: &amp;quot;2019-02-14&amp;quot; &amp;quot;2019-02-14&amp;quot; ...
##   ..$ date.effective          : Date[1:47], format: &amp;quot;2019-02-14&amp;quot; &amp;quot;2019-02-14&amp;quot; ...
##   ..$ mandate.duration        : chr [1:47] &amp;quot;3 anos&amp;quot; &amp;quot;3 anos&amp;quot; &amp;quot;3 anos&amp;quot; &amp;quot;2 anos&amp;quot; ...
##   ..$ ellected.by.controller  : logi [1:47] TRUE TRUE TRUE TRUE TRUE TRUE ...
##   ..$ qtd.consecutive.mandates: num [1:47] 6 6 5 8 8 8 8 8 7 9 ...
##   ..$ percentage.participation: num [1:47] 0 0 0 100 100 100 100 100 100 0 ...
##  $ df_committee_composition   :&amp;#39;data.frame&amp;#39;: 30 obs. of  22 variables:
##   ..$ CNPJ_CIA                : chr [1:30] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; ...
##   ..$ DENOM_CIA               : chr [1:30] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; ...
##   ..$ DT_REFER                : Date[1:30], format: &amp;quot;2018-01-01&amp;quot; &amp;quot;2018-01-01&amp;quot; ...
##   ..$ CD_CVM                  : num [1:30] 19615 19615 19615 19615 19615 ...
##   ..$ ID_DOC                  : num [1:30] 83396 83396 83396 94693 94693 ...
##   ..$ VERSAO                  : num [1:30] 16 16 16 18 18 18 18 18 18 18 ...
##   ..$ person.name             : chr [1:30] &amp;quot;Alexandre Grendene Bartelle&amp;quot; &amp;quot;Pedro Grendene Bartelle&amp;quot; &amp;quot;Renato Ochman&amp;quot; &amp;quot;Pedro Grendene Bartelle&amp;quot; ...
##   ..$ person.cpf              : num [1:30] 9.87e+09 9.86e+09 3.76e+10 9.86e+09 9.86e+09 ...
##   ..$ person.profession       : chr [1:30] &amp;quot;Industrial&amp;quot; &amp;quot;Industrial&amp;quot; &amp;quot;Advogado&amp;quot; &amp;quot;Industrial&amp;quot; ...
##   ..$ person.cv               : chr [1:30] &amp;quot;Fundador da Companhia e Presidente do Conselho de Administração desde 18 de agosto de 2004. \n\nFormação: Bacha&amp;quot;| __truncated__ &amp;quot;Fundador da Companhia. Vice-Presidente do Conselho de Administração desde 18 de agosto de 2004. \n\nFormação: B&amp;quot;| __truncated__ &amp;quot;Membro do Conselho de Administração desde 18 de agosto de 2004. \n\nFormação: Advogado, Bacharel em Direito pel&amp;quot;| __truncated__ NA ...
##   ..$ person.dob              : Date[1:30], format: &amp;quot;1950-01-23&amp;quot; &amp;quot;1950-01-23&amp;quot; ...
##   ..$ code.type.committee     : chr [1:30] &amp;quot;9&amp;quot; &amp;quot;9&amp;quot; &amp;quot;9&amp;quot; &amp;quot;9&amp;quot; ...
##   ..$ desc.type.committee     : chr [1:30] &amp;quot;Other Committee&amp;quot; &amp;quot;Other Committee&amp;quot; &amp;quot;Other Committee&amp;quot; &amp;quot;Other Committee&amp;quot; ...
##   ..$ code.type.job           : chr [1:30] &amp;quot;1&amp;quot; &amp;quot;3&amp;quot; &amp;quot;3&amp;quot; &amp;quot;3&amp;quot; ...
##   ..$ desc.committee          : chr [1:30] &amp;quot;Gestão do Programa de Stock Option&amp;quot; &amp;quot;Gestão do Programa de Stock Option&amp;quot; &amp;quot;Gestão do Programa de Stock Option&amp;quot; &amp;quot;Gestão do Programa de Stock Option&amp;quot; ...
##   ..$ desc.job                : chr [1:30] &amp;quot;Presidente do Conselho de Administração&amp;quot; &amp;quot;Vice presidente do Conselho de Administração&amp;quot; &amp;quot;Membro do Conselho de Administração&amp;quot; &amp;quot;Vice presidente do Conselho de Administração e membro do Comitê de Investimentos&amp;quot; ...
##   ..$ date.election           : Date[1:30], format: &amp;quot;2015-02-12&amp;quot; &amp;quot;2015-02-12&amp;quot; ...
##   ..$ date.effective          : Date[1:30], format: &amp;quot;2015-02-12&amp;quot; &amp;quot;2015-02-12&amp;quot; ...
##   ..$ mandate.duration        : chr [1:30] &amp;quot;indeterminado&amp;quot; &amp;quot;Indeterminado&amp;quot; &amp;quot;Indeterminado&amp;quot; &amp;quot;Indeterminado&amp;quot; ...
##   ..$ qtd.consecutive.mandates: num [1:30] 1 1 1 1 1 1 1 1 1 1 ...
##   ..$ percentage.participation: num [1:30] 100 100 100 100 100 100 100 100 100 100 ...
##   ..$ other.committes         : chr [1:30] &amp;quot;Gestão do Programa de Stock Option&amp;quot; &amp;quot;Gestão do Programa de Stock Option&amp;quot; &amp;quot;Gestão do Programa de Stock Option&amp;quot; &amp;quot;Gestão do Programa de Stock Option&amp;quot; ...
##  $ df_family_relations        :&amp;#39;data.frame&amp;#39;: 20 obs. of  14 variables:
##   ..$ CNPJ_CIA           : chr [1:20] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; ...
##   ..$ DENOM_CIA          : chr [1:20] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; ...
##   ..$ DT_REFER           : Date[1:20], format: &amp;quot;2018-01-01&amp;quot; &amp;quot;2018-01-01&amp;quot; ...
##   ..$ CD_CVM             : num [1:20] 19615 19615 19615 19615 19615 ...
##   ..$ ID_DOC             : num [1:20] 83396 83396 83396 83396 83396 ...
##   ..$ VERSAO             : num [1:20] 16 16 16 16 16 16 16 16 18 18 ...
##   ..$ person.name        : chr [1:20] &amp;quot;Pedro Grendene Bartelle&amp;quot; &amp;quot;Pedro Grendene Bartelle&amp;quot; &amp;quot;Alexandre Grendene Bartelle&amp;quot; &amp;quot;Alexandre Grendene Bartelle&amp;quot; ...
##   ..$ person.cpf         : num [1:20] 9.86e+09 9.86e+09 9.87e+09 9.87e+09 9.86e+09 ...
##   ..$ person.job         : chr [1:20] &amp;quot;Vice Presidente do Conselho de Administração&amp;quot; &amp;quot;Diretor Vice Presidente&amp;quot; &amp;quot;Presidente do Conselho de Administração&amp;quot; &amp;quot;Diretor Presidente&amp;quot; ...
##   ..$ related.person.name: chr [1:20] &amp;quot;Alexandre Grendene Bartelle&amp;quot; &amp;quot;Alexandre Grendene Bartelle&amp;quot; &amp;quot;Pedro Grendene Bartelle&amp;quot; &amp;quot;Pedro Grendene Bartelle&amp;quot; ...
##   ..$ related.person.cpf : num [1:20] 9.87e+09 9.87e+09 9.86e+09 9.86e+09 6.86e+10 ...
##   ..$ related.person.job : chr [1:20] &amp;quot;Presidente do Conselho de Administração&amp;quot; &amp;quot;Diretor Presidente&amp;quot; &amp;quot;Vice Presidente do Conselho de Administração&amp;quot; &amp;quot;Diretor Vice Presidente&amp;quot; ...
##   ..$ code.relationship  : chr [1:20] &amp;quot;2&amp;quot; &amp;quot;2&amp;quot; &amp;quot;2&amp;quot; &amp;quot;2&amp;quot; ...
##   ..$ desc.relationship  : chr [1:20] &amp;quot;Irmão ou Irmã (1º grau por consangüinidade)&amp;quot; &amp;quot;Irmão ou Irmã (1º grau por consangüinidade)&amp;quot; &amp;quot;Irmão ou Irmã (1º grau por consangüinidade)&amp;quot; &amp;quot;Irmão ou Irmã (1º grau por consangüinidade)&amp;quot; ...
##  $ df_family_related_companies:&amp;#39;data.frame&amp;#39;: 54 obs. of  15 variables:
##   ..$ CNPJ_CIA            : chr [1:54] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; ...
##   ..$ DENOM_CIA           : chr [1:54] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; ...
##   ..$ DT_REFER            : Date[1:54], format: &amp;quot;2018-01-01&amp;quot; &amp;quot;2018-01-01&amp;quot; ...
##   ..$ CD_CVM              : num [1:54] 19615 19615 19615 19615 19615 ...
##   ..$ ID_DOC              : num [1:54] 83396 83396 83396 83396 83396 ...
##   ..$ VERSAO              : num [1:54] 16 16 16 16 16 16 16 16 16 16 ...
##   ..$ person.name         : chr [1:54] &amp;quot;Pedro Grendene Bartelle&amp;quot; &amp;quot;Pedro Grendene Bartelle&amp;quot; &amp;quot;Pedro Grendene Bartelle&amp;quot; &amp;quot;Maílson Ferreira da Nóbrega&amp;quot; ...
##   ..$ person.cpf          : num [1:54] 9.86e+09 9.86e+09 9.86e+09 4.30e+09 3.76e+10 ...
##   ..$ person.job          : chr [1:54] &amp;quot;Vice-Presidente do Conselho de Administração&amp;quot; &amp;quot;Vice-Presidente do Conselho de Administração&amp;quot; &amp;quot;Vice-Presidente do Conselho de Administração&amp;quot; &amp;quot;Conselheiro de Administração&amp;quot; ...
##   ..$ type.related.person : chr [1:54] &amp;quot;Cliente&amp;quot; &amp;quot;Fornecedor&amp;quot; &amp;quot;Cliente&amp;quot; &amp;quot;Fornecedor&amp;quot; ...
##   ..$ type.relationship   : chr [1:54] &amp;quot;Controle&amp;quot; &amp;quot;Controle&amp;quot; &amp;quot;Controle&amp;quot; &amp;quot;Controle&amp;quot; ...
##   ..$ observations        : chr [1:54] &amp;quot;Venda de insumos e matrizes utilizados na produção de calçados - prazo médio de recebimento 32 dias.&amp;quot; &amp;quot;Compra de serviços referente comissões - Prazo médio de pagamentos 11 dias&amp;quot; &amp;quot;Venda de matrizes utilizadas na produção de calçados - Prazo médio de recebimento 33 dias.&amp;quot; &amp;quot;Assessoria&amp;quot; ...
##   ..$ related.company.name: chr [1:54] &amp;quot;Vulcabras|Azaleia - CE, Calçados e Artigos Esportivos S.A.&amp;quot; &amp;quot;Vulcabras|Azaleia - CE, Calçados e Artigos Esportivos S.A.&amp;quot; &amp;quot;Vulcabras|Azaleia - BA, Calçados e Artigos Esportivos S.A.&amp;quot; &amp;quot;Mailson da Nóbrega Consultoria S/C Ltda&amp;quot; ...
##   ..$ related.company.cnpj: num [1:54] 9.54e+11 9.54e+11 7.34e+11 1.58e+12 6.24e+13 ...
##   ..$ related.company.job : chr [1:54] &amp;quot;Acionista controlador&amp;quot; &amp;quot;Acionista controlados&amp;quot; &amp;quot;Acionista controlador&amp;quot; &amp;quot;Sócio proprietário&amp;quot; ...
##  $ df_auditing                :&amp;#39;data.frame&amp;#39;: 5 obs. of  14 variables:
##   ..$ CNPJ_CIA                  : chr [1:5] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; ...
##   ..$ DENOM_CIA                 : chr [1:5] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; ...
##   ..$ DT_REFER                  : Date[1:5], format: &amp;quot;2018-01-01&amp;quot; &amp;quot;2018-01-01&amp;quot; ...
##   ..$ CD_CVM                    : num [1:5] 19615 19615 19615 19615 19615
##   ..$ ID_DOC                    : num [1:5] 83396 83396 94693 94693 103471
##   ..$ VERSAO                    : num [1:5] 16 16 18 18 11
##   ..$ auditor.name              : chr [1:5] &amp;quot;PRICEWATERHOUSECOOPERS AUDITORES INDEPENDENTES (PWC)&amp;quot; &amp;quot;Ernst &amp;amp; Young Auditores Independentes S/S&amp;quot; &amp;quot;PRICEWATERHOUSECOOPERS AUDITORES INDEPENDENTES (PWC)&amp;quot; &amp;quot;Ernst &amp;amp; Young Auditores Independentes S/S&amp;quot; ...
##   ..$ auditor.cnpj              : chr [1:5] &amp;quot;61562112000635&amp;quot; &amp;quot;61366936000206&amp;quot; &amp;quot;61562112000635&amp;quot; &amp;quot;61366936001105&amp;quot; ...
##   ..$ contract.first.date       : Date[1:5], format: &amp;quot;2012-01-01&amp;quot; &amp;quot;2017-01-01&amp;quot; ...
##   ..$ contract.last.date        : Date[1:5], format: &amp;quot;2016-12-31&amp;quot; NA ...
##   ..$ description.contract      : chr [1:5] &amp;quot;Revisão dos ITR&amp;#39;s (Controladora e Consolidado) e auditoria anual de balanço da Controladora e Consolidado.&amp;quot; &amp;quot;Revisão dos ITR&amp;#39;s (controladora e Consolidado) e auditoria anual de balanço da Controladora e Consolidado.&amp;quot; &amp;quot;Revisão dos ITR&amp;#39;s (Controladora e Consolidado) e auditoria anual de balanço da Controladora e Consolidado.&amp;quot; &amp;quot;Revisão dos ITR&amp;#39;s (controladora e Consolidado) e auditoria anual de balanço da Controladora e Consolidado.&amp;quot; ...
##   ..$ compensation              : chr [1:5] &amp;quot;No exercício social encerrado em 31/12/2016 o montante total da remuneração dos auditores independentes foi R$4&amp;quot;| __truncated__ &amp;quot;Para o exercício encerrado em 31/12/2017 - R$409,2 mil, referente a serviços de auditoria prestados e R$131,1 m&amp;quot;| __truncated__ &amp;quot;No exercício social encerrado em 31/12/2016 o montante total da remuneração dos auditores independentes foi R$4&amp;quot;| __truncated__ &amp;quot;Para o exercício encerrado em 31/12/2017 - R$409,2 mil, referente a serviços de auditoria prestados e R$131,1 m&amp;quot;| __truncated__ ...
##   ..$ justification.substitution: chr [1:5] &amp;quot;Substituição em cumprimento à Instrução da Comissão de Valores Mobiliários nº 308/99 (art.31), que determina a &amp;quot;| __truncated__ NA &amp;quot;Substituição em cumprimento à Instrução da Comissão de Valores Mobiliários nº 308/99 (art.31), que determina a &amp;quot;| __truncated__ NA ...
##   ..$ reason.discordance        : chr [1:5] &amp;quot;Não houve discordância&amp;quot; NA &amp;quot;Não houve discordância&amp;quot; NA ...
##  $ df_responsible_docs        :&amp;#39;data.frame&amp;#39;: 6 obs. of  9 variables:
##   ..$ CNPJ_CIA   : chr [1:6] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; ...
##   ..$ DENOM_CIA  : chr [1:6] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; ...
##   ..$ DT_REFER   : Date[1:6], format: &amp;quot;2018-01-01&amp;quot; &amp;quot;2018-01-01&amp;quot; ...
##   ..$ CD_CVM     : num [1:6] 19615 19615 19615 19615 19615 ...
##   ..$ ID_DOC     : num [1:6] 83396 83396 94693 94693 103471 ...
##   ..$ VERSAO     : num [1:6] 16 16 18 18 11 11
##   ..$ person.cod : chr [1:6] &amp;quot;66&amp;quot; &amp;quot;67&amp;quot; &amp;quot;38&amp;quot; &amp;quot;39&amp;quot; ...
##   ..$ person.name: chr [1:6] &amp;quot;Rudimar Dall Onder&amp;quot; &amp;quot;Francisco Olinto Velo Schmitt&amp;quot; &amp;quot;Rudimar Dall Onder&amp;quot; &amp;quot;Alceu Demartini de Albuquerque&amp;quot; ...
##   ..$ person.job : chr [1:6] &amp;quot;Diretor Presidente&amp;quot; &amp;quot;Diretor de Relações com Investidores&amp;quot; &amp;quot;Diretor Presidente&amp;quot; &amp;quot;Diretor de Relações com Investidores&amp;quot; ...
##  $ df_stocks_details          :&amp;#39;data.frame&amp;#39;: 3 obs. of  16 variables:
##   ..$ CNPJ_CIA           : chr [1:3] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot;
##   ..$ DENOM_CIA          : chr [1:3] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot;
##   ..$ DT_REFER           : Date[1:3], format: &amp;quot;2018-01-01&amp;quot; &amp;quot;2019-01-01&amp;quot; ...
##   ..$ CD_CVM             : num [1:3] 19615 19615 19615
##   ..$ ID_DOC             : num [1:3] 83396 94693 103471
##   ..$ VERSAO             : num [1:3] 16 18 11
##   ..$ type.stock.id      : chr [1:3] &amp;quot;1&amp;quot; &amp;quot;1&amp;quot; &amp;quot;1&amp;quot;
##   ..$ type.stock.text    : chr [1:3] &amp;quot;Ordinária&amp;quot; &amp;quot;Ordinária&amp;quot; &amp;quot;Ordinária&amp;quot;
##   ..$ tag.along          : num [1:3] 100 100 100
##   ..$ preferential.code  : chr [1:3] &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot;
##   ..$ preferential.text  : logi [1:3] NA NA NA
##   ..$ dividend.text      : chr [1:3] &amp;quot;Conforme o Estatuto Social da Companhia, art.32, os acionistas fazem jus a dividendo obrigatório anual equivale&amp;quot;| __truncated__ &amp;quot;Conforme o Estatuto Social da Companhia, art.32, os acionistas fazem jus a dividendo obrigatório anual equivale&amp;quot;| __truncated__ &amp;quot;Conforme o Estatuto Social da Companhia, art.32, os acionistas fazem jus a dividendo obrigatório anual equivale&amp;quot;| __truncated__
##   ..$ flag.voting.rights : chr [1:3] &amp;quot;1&amp;quot; &amp;quot;1&amp;quot; &amp;quot;1&amp;quot;
##   ..$ flag.voting.text   : chr [1:3] &amp;quot;Pleno&amp;quot; &amp;quot;Pleno&amp;quot; &amp;quot;Pleno&amp;quot;
##   ..$ flag.conversibility: chr [1:3] &amp;quot;Não&amp;quot; &amp;quot;Não&amp;quot; &amp;quot;Não&amp;quot;
##   ..$ other.info.text    : chr [1:3] &amp;quot;Não existem características relevantes adicionais.&amp;quot; &amp;quot;Não existem características relevantes adicionais.&amp;quot; &amp;quot;Não existem características relevantes adicionais.&amp;quot;
##  $ df_dividends_details       :&amp;#39;data.frame&amp;#39;: 3 obs. of  11 variables:
##   ..$ CNPJ_CIA            : chr [1:3] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot;
##   ..$ DENOM_CIA           : chr [1:3] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot;
##   ..$ DT_REFER            : Date[1:3], format: &amp;quot;2018-01-01&amp;quot; &amp;quot;2019-01-01&amp;quot; ...
##   ..$ CD_CVM              : num [1:3] 19615 19615 19615
##   ..$ ID_DOC              : num [1:3] 83396 94693 103471
##   ..$ VERSAO              : num [1:3] 16 18 11
##   ..$ net.profit          : num [1:3] 6.61e+08 5.86e+08 4.95e+08
##   ..$ distributed.dividend: num [1:3] 3.78e+08 3.15e+08 2.76e+08
##   ..$ retained.profit     : num [1:3] 2.74e+08 2.70e+08 2.19e+08
##   ..$ payout              : num [1:3] 57.2 53.8 55.7
##   ..$ div.yeild.on.equity : num [1:3] 22.6 18.2 14.3
##  $ df_intangible_details      :&amp;#39;data.frame&amp;#39;: 38 obs. of  10 variables:
##   ..$ CNPJ_CIA   : chr [1:38] &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; &amp;quot;89.850.341/0001-60&amp;quot; ...
##   ..$ DENOM_CIA  : chr [1:38] &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; &amp;quot;GRENDENE S.A.&amp;quot; ...
##   ..$ DT_REFER   : Date[1:38], format: &amp;quot;2018-01-01&amp;quot; &amp;quot;2018-01-01&amp;quot; ...
##   ..$ CD_CVM     : num [1:38] 19615 19615 19615 19615 19615 ...
##   ..$ ID_DOC     : num [1:38] 83396 83396 83396 83396 83396 ...
##   ..$ VERSAO     : num [1:38] 16 16 16 16 16 16 16 16 16 16 ...
##   ..$ id         : num [1:38] 1111 1112 1113 1114 1115 ...
##   ..$ id.type    : num [1:38] 2 2 2 2 2 2 2 2 2 2 ...
##   ..$ patent.desc: chr [1:38] &amp;quot;Zaxy&amp;quot; &amp;quot;Mel&amp;quot; &amp;quot;Cartago&amp;quot; &amp;quot;Rider&amp;quot; ...
##   ..$ duration   : Date[1:38], format: NA NA ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A GARCH Tutorial in R (revised)</title>
      <link>https://www.msperlin.com/post/2020-07-07-garch-tutorial-in-r-revised/</link>
      <pubDate>Tue, 07 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2020-07-07-garch-tutorial-in-r-revised/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;&lt;strong&gt;2020-07-22 Update: The final version of the paper is now published at &lt;a href=&#34;https://rac.anpad.org.br/index.php/rac/article/view/1420?fbclid=IwAR0D0N5RBmeX92sXY22r8RWPDjlVjM00p-DjuufSrYf9WgOf9JhOcGoUS1Q&#34;&gt;RAC&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Back in May 2020, I started to work on a &lt;a href=&#34;https://www.msperlin.com/post/2020-03-29-garch-tutorial-in-r/&#34;&gt;new paper&lt;/a&gt; regarding the use of Garch models in R. Today we finished the peer review process and finally got a final version of the &lt;a href=&#34;https://docs.google.com/document/d/1eHuKsp3-GokyjOwr0PZ_dNnVTzmSS4PCPMzI9LfUclI/edit?usp=sharing&#34;&gt;article&lt;/a&gt; and &lt;a href=&#34;https://github.com/msperlin/GARCH-RAC&#34;&gt;code&lt;/a&gt;. I’m glad to report that the content improved significantly.&lt;/p&gt;
&lt;p&gt;In a nutshell, the paper motivates GARCH models and presents an empirical application using R: given the recent COVID-19 crisis, we investigate the likelihood of Ibovespa index reach its peak value once again in the upcoming years.&lt;/p&gt;
&lt;p&gt;All code and data used in the study is available in &lt;a href=&#34;https://github.com/msperlin/GARCH-RAC&#34;&gt;GitHub&lt;/a&gt;, so fell free to download the zip file and play around. Likewise, you can run the same code at &lt;a href=&#34;https://rstudio.cloud/project/1371589&#34;&gt;RStudio Cloud&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Call for papers on data reuse</title>
      <link>https://www.msperlin.com/post/2020-05-27-call-for-papers-rac/</link>
      <pubDate>Wed, 27 May 2020 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2020-05-27-call-for-papers-rac/</guid>
      <description>


&lt;p&gt;Myself and Henrique Martins (PUC Rio) organized a call for papers on data reuse, for publication in &lt;a href=&#34;https://rac.anpad.org.br/index.php/rac&#34;&gt;RAC – Revista de Administração Contemporanea&lt;/a&gt;. The deadline for submission is 10th october 2020, with expected publication date in july 2021.&lt;/p&gt;
&lt;p&gt;We will select quality papers that use data already published and shared in other scientific outlet to test new theories or present a tutorial article, helping students see how an econometric result was achieved in practice.&lt;/p&gt;
&lt;p&gt;You can find more details about this call for papers in this &lt;a href=&#34;https://www.msperlin.com/files/CALL%20FOR%20PAPERS_RAC_2021_Data%20Reuse.pdf&#34;&gt;pdf file&lt;/a&gt;. I encourage everyone to submit their work. If you got any question, please let me know.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Financial Datasets Available in the Website</title>
      <link>https://www.msperlin.com/post/2020-04-20-free-compiled-data-in-site/</link>
      <pubDate>Mon, 20 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2020-04-20-free-compiled-data-in-site/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I’ve been researching financial data for over 10 years and gathered a great deal of compiled tables. Most of these comes from my R packages and have been used for creating class material, doing &lt;a href=&#34;https://www.msperlin.com/publication/&#34;&gt;research&lt;/a&gt; and even &lt;a href=&#34;https://www.msperlin.com/publication/2019_book-pirf/&#34;&gt;writing a book&lt;/a&gt;. These files were mostly found in many copies across different projects.&lt;/p&gt;
&lt;p&gt;Last week I started to organize and centralize all my data files and noticed how valuable these tables could be for other researchers and teachers.&lt;/p&gt;
&lt;p&gt;As of today, I’ll be hosting all public compiled data in my &lt;a href=&#34;https://dataverse.harvard.edu/dataverse/msperlin&#34;&gt;dataverse website&lt;/a&gt;. Most of them are the product of using my R packages in a large scale data grabbing process. For example, I used package &lt;code&gt;BatchGetSymbols&lt;/code&gt; to download daily prices of all stocks belonging to the SP500 since 2015 and saved it in a .csv file.&lt;/p&gt;
&lt;p&gt;Hope you find these files as useful as they were to me. If you use it for writing a report, make sure to cite the package as the source of data (see the &lt;em&gt;Readme.txt&lt;/em&gt; file in each folder for details).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New R package: GetCVMData</title>
      <link>https://www.msperlin.com/post/2020-04-20-new-package-getcvmdata/</link>
      <pubDate>Mon, 20 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2020-04-20-new-package-getcvmdata/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div class=&#34;alert alert-warning&#34;&gt;
&lt;p&gt;
2020-07-18: Package GetCVMData is now named GetDFPData2. See &lt;a href=&#34;https://www.msperlin.com/post/2020-07-18-new_packages-getfredata-getdfpdata2/&#34;&gt;this post&lt;/a&gt; for details. The old code in &lt;code&gt;GetCVMData&lt;/code&gt; is still in Github but will no longer be developed.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Package &lt;code&gt;GetCVMData&lt;/code&gt; is an alternative to &lt;code&gt;GetDFPData&lt;/code&gt;. Both have the same objective: fetch corporate data of Brazilian companies trading at B3, but diverge in their source. While &lt;code&gt;GetDFPData&lt;/code&gt; imports data directly from the DFP and FRE systems, &lt;code&gt;GetCVMData&lt;/code&gt; uses the &lt;a href=&#34;http://dados.cvm.gov.br/dados/CIA_ABERTA/&#34;&gt;CVM ftp site&lt;/a&gt; for grabbing compiled .csv files.&lt;/p&gt;
&lt;p&gt;When doing large scale importations, &lt;code&gt;GetDFPData&lt;/code&gt; fells sluggish due to the parsing of large xml files. As an example, building the dataset available in my &lt;a href=&#34;https://www.msperlin.com/data/data/&#34;&gt;data page&lt;/a&gt; takes around six hours of execution using 10 cores of my home computer.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;GetCVMData&lt;/code&gt; is lean and fast. Since the data is already parsed in csv files, all the code does is organize the files, download and read. For comparison, all DFP documents, annual financial reports, available in CVM can be imported in less than 1 minute. Additionally, &lt;code&gt;GetCVMData&lt;/code&gt; can also parse ITR (quarterly) data, which was not available in &lt;code&gt;GetDFPData&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;However, be aware that the output data is not the same. I kept all original column names from CVM and some information, such as tickers, are not available in &lt;code&gt;GetCVMData&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Here’s an example of usage:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if (!require(devtools)) install.packages(&amp;#39;devtools&amp;#39;)  
if (!require(GetCVMData)) devtools::install_github(&amp;#39;msperlin/GetCVMData&amp;#39;) # not in CRAN yet

library(GetCVMData)
library(tidyverse)

# fetch information about companies
df_info &amp;lt;- get_info_companies()


# search for companies
df_search &amp;lt;- search_company(&amp;#39;odontoprev&amp;#39;)

# DFP annual data
id_cvm &amp;lt;- df_search$CD_CVM[1] # use NULL for all companies
df_dfp &amp;lt;- get_dfp_data(companies_cvm_codes = id_cvm, 
                       first_year = 2015,
                       last_year = 2019,
                       type_docs = c(&amp;#39;DRE&amp;#39;, &amp;#39;BPA&amp;#39;, &amp;#39;BPP&amp;#39;), # income, assets, liabilities
                       type_format = &amp;#39;con&amp;#39; # consolidated statements
                       )

glimpse(df_dfp)

# ITR quarterly data
df_itr &amp;lt;- get_itr_data(companies_cvm_codes = id_cvm, 
                       first_year = 2010,
                       last_year = 2020, 
                       type_docs = c(&amp;#39;DRE&amp;#39;, &amp;#39;BPA&amp;#39;, &amp;#39;BPP&amp;#39;), # income, assets, liabilities
                       type_format = &amp;#39;con&amp;#39; # consolidated statements
                       )

glimpse(df_itr)

# FRE data (not yet implemented..)
#df_fre &amp;lt;- get_fre_data()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Lets plot the quarterly profit of &lt;code&gt;df_itr$DENOM_CIA[1]&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

quarterly_profits &amp;lt;- df_itr  %&amp;gt;%
  filter(GRUPO_DFP == &amp;#39;DF Consolidado - Demonstração do Resultado&amp;#39;,
         DS_CONTA == &amp;#39;Lucro/Prejuízo Consolidado do Período&amp;#39;) 
  
# plot it
p &amp;lt;- ggplot(quarterly_profits, aes(x = DT_FIM_EXERC, y = VL_CONTA)) + 
  geom_col() + 
  theme_bw() + 
  labs(title = paste0(&amp;#39;Quarterly profits of &amp;#39;, quarterly_profits$DENOM_CIA[1]),
       caption = &amp;#39;Data from CVM&amp;#39;,
       x = &amp;#39;&amp;#39;,
       y = &amp;#39;Consolidade Profits&amp;#39;)

p&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Update on GetDFPData tables -- 2019&#39;s DFP and FRE data</title>
      <link>https://www.msperlin.com/post/2020-04-17-update-getdfpdata/</link>
      <pubDate>Fri, 17 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2020-04-17-update-getdfpdata/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;After battling B3’s website for days, I finally managed to gather a master table for all corporate data. I’m happy to report that the 2019’s data is now included in GetDFPData, the CRAN package and &lt;a href=&#34;https://www.msperlin.com/shiny/GetDFPData/&#34;&gt;shiny interface&lt;/a&gt;. This includes new financial statements and company’s FRE data.&lt;/p&gt;
&lt;p&gt;I also want to use this update to formally thank everyone that made a donation in the &lt;a href=&#34;https://www.msperlin.com/shiny/GetDFPData/&#34;&gt;shiny website&lt;/a&gt;. Your donation is not only helping paying for the bills of the server but increasing my motivation for working further in this project.&lt;/p&gt;
&lt;p&gt;As for R code with then new dataset, let’s give it a try:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(GetDFPData)
library(tidyverse)

name.companies &amp;lt;- c(&amp;#39;PETRÓLEO BRASILEIRO  S.A.  - PETROBRAS&amp;#39;)

first.date &amp;lt;- &amp;#39;2017-01-01&amp;#39;
last.date &amp;lt;- &amp;#39;2020-01-01&amp;#39;
inflation.index &amp;lt;- &amp;#39;IPCA&amp;#39;

df.reports &amp;lt;- gdfpd.GetDFPData(name.companies = name.companies,
                               first.date = first.date,
                               last.date = last.date)

glimpse(df.reports)&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>A GARCH Tutorial in R</title>
      <link>https://www.msperlin.com/post/2020-03-29-garch-tutorial-in-r/</link>
      <pubDate>Sun, 29 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2020-03-29-garch-tutorial-in-r/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Myself, Mauro Mastella, Daniel Vancin and Henrique Ramos, just finished a tutorial paper about GARCH models in R and I believe it is a good content for those learning financial econometrics. You can find the full paper in this &lt;a href=&#34;https://docs.google.com/document/d/1BcIFoM25haxWIVtQfzMMGPnPG--gTt2f3XhGJlSHQus/edit?usp=sharing&#34;&gt;link&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In a nutshell, the paper introduces motivation behind the GARCH type of models and presents an empirical application: given the recent COVID-19 crisis, we investigate how much time it would take for the Ibovespa index to reach its peak value once again. The results indicate that it would take, on average, about two and half years for the index to recover.&lt;/p&gt;
&lt;p&gt;All code and data used in the study is available in &lt;a href=&#34;https://github.com/msperlin/GARCH-RAC&#34;&gt;GitHub&lt;/a&gt;, so fell free to download the zip file and play around. You can find all figures of the paper in this &lt;a href=&#34;https://imgur.com/gallery/w2U9MSs&#34;&gt;link&lt;/a&gt;. Worth pointing out that you can reproduce all results in your own computer by executing the source code at &lt;a href=&#34;https://github.com/msperlin/GARCH-RAC&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;iframe src=&#34;https://docs.google.com/document/d/e/2PACX-1vTIk9P2QwACBW8qtQXZONqJqCb1R5Ewh8AwljSIdX94xRYlljj_E6t5Xn0hO71YvtckrcIFRsAOR3us/pub?embedded=true&#34; width=&#34;700&#34; height=&#34;500&#34;&gt;
&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>Book slides - Analyzing Financial and Economic Data with R</title>
      <link>https://www.msperlin.com/post/2020-02-25-afedr-ed2-slides-available/</link>
      <pubDate>Tue, 25 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2020-02-25-afedr-ed2-slides-available/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div class=&#34;alert alert-warning&#34;&gt;
&lt;p&gt;
2021-02-28 – Important: this blog post is deprecated. With the &lt;a href=&#34;https://www.msperlin.com/post/2021-02-28-afedr-revision-2021/&#34;&gt;last revision&lt;/a&gt; in march 2021, the Rmd slides are no longer available within the book material.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The slides for my newly released book &lt;a href=&#34;https://www.msperlin.com/post/2020-01-15-afedr-ed2-announcement/&#34;&gt;Analyzing Financial and Economic Data with R&lt;/a&gt; are finally ready! I apologize for keep you guys waiting.&lt;/p&gt;
&lt;p&gt;The slides are available as independent .Rmd files for all book chapters including:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## character(0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All content is released with a generous MIT license, so fell free to use and edit the files as you wish.&lt;/p&gt;
&lt;p&gt;You can download the slides and other book material with the following code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if (!require(devtools)) install.packages(&amp;quot;devtools&amp;quot;)

devtools::install_github(&amp;#39;msperlin/afedR&amp;#39;)

# ignore warning messages (long paths..)
afedR::afedR_get_book_files(path_to_copy = &amp;#39;~&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Alternatively, you can download the files directly from &lt;a href=&#34;https://github.com/msperlin/afedR/tree/master/inst/extdata&#34;&gt;github&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The bundle also includes other teaching material that may help conduct a complete R tutorial:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Solutions to end of chapter exercises&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;All R Code used in the book&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Dynamic exercises (package exams)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Data files&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you liked the material, please consider purchasing the book and &lt;strong&gt;leaving your feedback at &lt;a href=&#34;https://www.amazon.com/dp/B084LSNXMN&#34;&gt;Amazon&lt;/a&gt;&lt;/strong&gt;. Your oppinion is very important for promoting the book and help others learn more about R and RStudio. As an author, I certainly appreciate the gesture and will take it as a motivating factor for future editions of the book.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Book release - Analyzing Financial and Economic Data with R (2º edition)</title>
      <link>https://www.msperlin.com/post/2020-01-15-afedr-ed2-announcement/</link>
      <pubDate>Mon, 10 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2020-01-15-afedr-ed2-announcement/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div class=&#34;alert alert-success&#34;&gt;
&lt;p&gt;
2021-02-28 – The book was revised in march 2021. See this &lt;a href=&#34;https://www.msperlin.com/post/2021-02-28-afedr-revision-2021/&#34;&gt;blog post&lt;/a&gt; for details.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;After a couple of unexpected delays, I am very pleased to announce the publication of the second edition of my book, &lt;strong&gt;Analyzing Financial and Economic Data with R&lt;/strong&gt;. You can find it in Amazon as an &lt;a href=&#34;https://www.amazon.com/dp/B084LSNXMN&#34;&gt;ebook&lt;/a&gt; or &lt;a href=&#34;https://www.amazon.com/dp/171062731X&#34;&gt;paperback&lt;/a&gt;. An online version is available &lt;a href=&#34;https://www.msperlin.com/afedR/&#34;&gt;here&lt;/a&gt;. More details, including supplementary material, are available in the &lt;a href=&#34;https://www.msperlin.com/publication/2020_book-afedr-en/&#34;&gt;book webpage&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The first edition was released back in 2017 and it was a great journey working once again in this material. Many sections and chapters have been improved, along with new content. Here are the main changes:&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;Alignment with the tidyverse&lt;/dt&gt;
&lt;dd&gt;&lt;ul&gt;
&lt;li&gt;Some base function are presented but priority is for &lt;code&gt;readr&lt;/code&gt;, &lt;code&gt;ggplot2&lt;/code&gt;, &lt;code&gt;dplyr&lt;/code&gt;, &lt;code&gt;stringr&lt;/code&gt;, &lt;code&gt;purrr&lt;/code&gt; and so on.&lt;/li&gt;
&lt;li&gt;100+ pages of new content (a 25% overall increase from previous edition).&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;dt&gt;Teaching Material&lt;/dt&gt;
&lt;dd&gt;&lt;ul&gt;
&lt;li&gt;Static end of chapter exercises, with solutions publicly available in the internet;&lt;/li&gt;
&lt;li&gt;Rmarkdown slides for each chapter;&lt;/li&gt;
&lt;li&gt;Dynamic 90+ exercises with the &lt;a href=&#34;http://www.r-exams.org/&#34;&gt;&lt;code&gt;exams&lt;/code&gt; package&lt;/a&gt;. This means you can create and grade randomized unique tests for your students (see this &lt;a href=&#34;https://www.msperlin.com/post/2019-12-02-dynamic-exercises-afedr/&#34;&gt;post&lt;/a&gt; for details);&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;dt&gt;Book package &lt;code&gt;afedR&lt;/code&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;ul&gt;
&lt;li&gt;This package makes it easier to import book datasets, slides, functions and solutions for end-of-chapter exercises. Available in &lt;a href=&#34;https://github.com/msperlin/afedR&#34;&gt;GitHub&lt;/a&gt; only. See this &lt;a href=&#34;https://www.msperlin.com/post/2020-02-25-afedr-ed2-slides-available/&#34;&gt;blog post&lt;/a&gt; for instructions on installation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;dt&gt;Three new chapters&lt;/dt&gt;
&lt;dd&gt;&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Cleaning and Structuring Financial and Economic Data&lt;/em&gt; – How to clean financial and economic data by dealing with long/wide dataframes, outlier detection/removal and desinflating prices and indexes.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Reporting Results&lt;/em&gt; – Using &lt;code&gt;xtable&lt;/code&gt; and &lt;code&gt;texreg&lt;/code&gt; to report tables and models. Includes a special section about the RMarkdown technology.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Optimizing Code&lt;/em&gt; – Profiling code for bottlenecks and using vectorization, &lt;code&gt;rcpp&lt;/code&gt; and &lt;code&gt;memoise&lt;/code&gt; to speed up R computations.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;dt&gt;Two new packages in CRAN&lt;/dt&gt;
&lt;dd&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;simfinR&lt;/code&gt; – grabs corporate datasets from the &lt;a href=&#34;https://simfin.com/&#34;&gt;SimFin project&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GetQuandlData&lt;/code&gt;– uses &lt;a href=&#34;https://www.quandl.com/&#34;&gt;Quandl&lt;/a&gt; json api and caching for easier and faster data importation;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;If you liked the material, please consider purchasing it and &lt;strong&gt;leaving your feedback at &lt;a href=&#34;https://www.amazon.com/dp/B084LSNXMN&#34;&gt;Amazon&lt;/a&gt;&lt;/strong&gt;. Your oppinion is very important for promoting the book and help others learn more about R and RStudio. As an author, I certainly appreciate the gesture and will take it as a motivating factor for future editions of the book.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Looking back at 2019 and plans for 2020</title>
      <link>https://www.msperlin.com/post/2019-12-15-looking-back-2019/</link>
      <pubDate>Thu, 12 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2019-12-15-looking-back-2019/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I’m just about to leave for my vacation and, as usual, I’ll write about the highlights of 2019 and my plans for the year to come. First, let’s talk about my work in 2019.&lt;/p&gt;
&lt;div id=&#34;highlights-of-2019&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Highlights of 2019&lt;/h1&gt;
&lt;p&gt;The year of 2019 was not particularly fruitful in journal publications. I only had two: &lt;em&gt;Accessing Financial Reports and Corporate Events with GetDFPData&lt;/em&gt;, &lt;a href=&#34;http://bibliotecadigital.fgv.br/ojs/index.php/rbfin/issue/view/4431&#34;&gt;published in RBfin&lt;/a&gt; and &lt;em&gt;A consumer credit risk structural model based on affordability: balance at risk&lt;/em&gt; &lt;a href=&#34;https://www.risk.net/journal-of-credit-risk/6743521/a-consumer-credit-risk-structural-model-based-on-affordability-balance-at-risk&#34;&gt;published in JCR&lt;/a&gt;. Both are papers I wrote back in 2017 and 2018 and not new articles. Most of the papers I worked this year will be published in 2020 or 2021.&lt;/p&gt;
&lt;p&gt;This year, I’m mostly proud of the publication of my book about investing in the fixed income markets &lt;a href=&#34;https://www.amazon.com.br/dp/B07RR9K9PV&#34;&gt;Poupando e Investindo em Renda Fixa: Uma Abordagem Baseada em Dados&lt;/a&gt;. This was a special project, very different from the usual writing style of scientific research and, lots of fun to write. As a side effect, I learned a lot about the fixed income market in Brasil and it forced me to think objectively about a problem that is inherently subjective, personal finance and investing. Hopefully, in the future, I’ll write another book about the stock market and real state investing, a topic that I’m also very interested.&lt;/p&gt;
&lt;p&gt;My main project this year is the work in the second edition of my R book &lt;em&gt;Analyzing Financial and Economic Data with R&lt;/em&gt;. It took a major part of my working weeks and weekends, but its coming together. Soon I’ll be publishing it in Amazon. You can find more details about it in this &lt;a href=&#34;https://www.msperlin.com/post/2019-11-25-feedback-toc-afedr/&#34;&gt;previous post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In the programming side, I wrote two new CRAN packages in 2019: simfinR and GetQuandlData. Both are featured in the new edition of my R book (soon to be published).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;my-blog-posts-in-2018&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;My blog posts in 2018&lt;/h1&gt;
&lt;p&gt;Let’s have a look at my blog posts so so far.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my.blog.folder &amp;lt;- &amp;#39;~/Dropbox/11-My Website/01-msperlin.com/content/post/&amp;#39;
post.files &amp;lt;- list.files(path = my.blog.folder, pattern = &amp;#39;.Rmd&amp;#39;)

post.files&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   [1] &amp;quot;2017-02-16-Writing-a-book.Rmd&amp;quot;                           
##   [2] &amp;quot;2017-02-16-Writing-a-book.Rmd.lock~&amp;quot;                     
##   [3] &amp;quot;2017-12-06-Package-GetDFPData.Rmd&amp;quot;                       
##   [4] &amp;quot;2017-12-06-Package-GetDFPData.Rmd.lock~&amp;quot;                 
##   [5] &amp;quot;2017-12-13-Serving-shiny-apps-internet.Rmd&amp;quot;              
##   [6] &amp;quot;2017-12-13-Serving-shiny-apps-internet.Rmd.lock~&amp;quot;        
##   [7] &amp;quot;2017-12-30-Looking-Back-2017.Rmd&amp;quot;                        
##   [8] &amp;quot;2017-12-30-Looking-Back-2017.Rmd.lock~&amp;quot;                  
##   [9] &amp;quot;2018-01-22-Update-BatchGetSymbols.Rmd&amp;quot;                   
##  [10] &amp;quot;2018-01-22-Update-BatchGetSymbols.Rmd.lock~&amp;quot;             
##  [11] &amp;quot;2018-03-16-Writing_Papers_About_Pkgs.Rmd&amp;quot;                
##  [12] &amp;quot;2018-03-16-Writing_Papers_About_Pkgs.Rmd.lock~&amp;quot;          
##  [13] &amp;quot;2018-04-22-predatory-scientometrics.Rmd&amp;quot;                 
##  [14] &amp;quot;2018-04-22-predatory-scientometrics.Rmd.lock~&amp;quot;           
##  [15] &amp;quot;2018-05-12-Investing-Long-Run.Rmd&amp;quot;                       
##  [16] &amp;quot;2018-05-12-Investing-Long-Run.Rmd.lock~&amp;quot;                 
##  [17] &amp;quot;2018-06-12-padfR-ed2.Rmd&amp;quot;                                
##  [18] &amp;quot;2018-06-12-padfR-ed2.Rmd.lock~&amp;quot;                          
##  [19] &amp;quot;2018-06-29-BenchmarkingSSD.Rmd&amp;quot;                          
##  [20] &amp;quot;2018-06-29-BenchmarkingSSD.Rmd.lock~&amp;quot;                    
##  [21] &amp;quot;2018-10-10-BatchGetSymbols-NewVersion.Rmd&amp;quot;               
##  [22] &amp;quot;2018-10-10-BatchGetSymbols-NewVersion.Rmd.lock~&amp;quot;         
##  [23] &amp;quot;2018-10-11-Update-GetLattesData.Rmd&amp;quot;                     
##  [24] &amp;quot;2018-10-11-Update-GetLattesData.Rmd.lock~&amp;quot;               
##  [25] &amp;quot;2018-10-13-NewPackage-PkgsFromFiles.Rmd&amp;quot;                 
##  [26] &amp;quot;2018-10-13-NewPackage-PkgsFromFiles.Rmd.lock~&amp;quot;           
##  [27] &amp;quot;2018-10-19-R-and-loops.Rmd&amp;quot;                              
##  [28] &amp;quot;2018-10-19-R-and-loops.Rmd.lock~&amp;quot;                        
##  [29] &amp;quot;2018-10-20-Linux-and-R.Rmd&amp;quot;                              
##  [30] &amp;quot;2018-10-20-Linux-and-R.Rmd.lock~&amp;quot;                        
##  [31] &amp;quot;2018-11-03-NewBlog.Rmd&amp;quot;                                  
##  [32] &amp;quot;2018-11-03-NewBlog.Rmd.lock~&amp;quot;                            
##  [33] &amp;quot;2018-11-03-RstudioTricks.Rmd&amp;quot;                            
##  [34] &amp;quot;2018-11-03-RstudioTricks.Rmd.lock~&amp;quot;                      
##  [35] &amp;quot;2019-01-08-Looking-Back-2018.Rmd&amp;quot;                        
##  [36] &amp;quot;2019-01-08-Looking-Back-2018.Rmd.lock~&amp;quot;                  
##  [37] &amp;quot;2019-01-12-GetDFPData-ver14.Rmd&amp;quot;                         
##  [38] &amp;quot;2019-01-12-GetDFPData-ver14.Rmd.lock~&amp;quot;                   
##  [39] &amp;quot;2019-03-09-pafdR-promotion.Rmd&amp;quot;                          
##  [40] &amp;quot;2019-03-09-pafdR-promotion.Rmd.lock~&amp;quot;                    
##  [41] &amp;quot;2019-03-10-pafdR-promotion_2.Rmd&amp;quot;                        
##  [42] &amp;quot;2019-03-10-pafdR-promotion_2.Rmd.lock~&amp;quot;                  
##  [43] &amp;quot;2019-03-23-Bettina-Case.Rmd&amp;quot;                             
##  [44] &amp;quot;2019-03-23-Bettina-Case.Rmd.lock~&amp;quot;                       
##  [45] &amp;quot;2019-04-13-Parallel-BatchGetsymbols.Rmd&amp;quot;                 
##  [46] &amp;quot;2019-04-13-Parallel-BatchGetsymbols.Rmd.lock~&amp;quot;           
##  [47] &amp;quot;2019-04-15-GetBCBData.Rmd&amp;quot;                               
##  [48] &amp;quot;2019-04-15-GetBCBData.Rmd.lock~&amp;quot;                         
##  [49] &amp;quot;2019-05-01-MeanVariance.Rmd&amp;quot;                             
##  [50] &amp;quot;2019-05-01-MeanVariance.Rmd.lock~&amp;quot;                       
##  [51] &amp;quot;2019-05-17-R-in-Brazil.Rmd&amp;quot;                              
##  [52] &amp;quot;2019-05-17-R-in-Brazil.Rmd.lock~&amp;quot;                        
##  [53] &amp;quot;2019-05-20-Lindy-Effect.Rmd&amp;quot;                             
##  [54] &amp;quot;2019-05-20-Lindy-Effect.Rmd.lock~&amp;quot;                       
##  [55] &amp;quot;2019-07-01-ftp-shutdown.Rmd&amp;quot;                             
##  [56] &amp;quot;2019-07-01-ftp-shutdown.Rmd.lock~&amp;quot;                       
##  [57] &amp;quot;2019-08-08-ftp-NOT-shutdown.Rmd&amp;quot;                         
##  [58] &amp;quot;2019-08-08-ftp-NOT-shutdown.Rmd.lock~&amp;quot;                   
##  [59] &amp;quot;2019-10-01-new-package-GetQuandlData.Rmd&amp;quot;                
##  [60] &amp;quot;2019-10-01-new-package-GetQuandlData.Rmd.lock~&amp;quot;          
##  [61] &amp;quot;2019-10-12-support-GetDFPData-shiny.Rmd&amp;quot;                 
##  [62] &amp;quot;2019-10-12-support-GetDFPData-shiny.Rmd.lock~&amp;quot;           
##  [63] &amp;quot;2019-10-16-new-package-GetEdgarData.Rmd&amp;quot;                 
##  [64] &amp;quot;2019-10-16-new-package-GetEdgarData.Rmd.lock~&amp;quot;           
##  [65] &amp;quot;2019-11-01-new-package-simfinR.Rmd&amp;quot;                      
##  [66] &amp;quot;2019-11-01-new-package-simfinR.Rmd.lock~&amp;quot;                
##  [67] &amp;quot;2019-11-25-feedback-TOC-afedR.Rmd&amp;quot;                       
##  [68] &amp;quot;2019-11-25-feedback-TOC-afedR.Rmd.lock~&amp;quot;                 
##  [69] &amp;quot;2019-12-02-dynamic-exercises-afedR.Rmd&amp;quot;                  
##  [70] &amp;quot;2019-12-02-dynamic-exercises-afedR.Rmd.lock~&amp;quot;            
##  [71] &amp;quot;2019-12-15-Looking-Back-2019.Rmd&amp;quot;                        
##  [72] &amp;quot;2019-12-15-Looking-Back-2019.Rmd.lock~&amp;quot;                  
##  [73] &amp;quot;2020-01-15-afedR-ed2-announcement.Rmd&amp;quot;                   
##  [74] &amp;quot;2020-01-15-afedR-ed2-announcement.Rmd.lock~&amp;quot;             
##  [75] &amp;quot;2020-02-25-afedR-ed2-slides-available.Rmd&amp;quot;               
##  [76] &amp;quot;2020-02-25-afedR-ed2-slides-available.Rmd.lock~&amp;quot;         
##  [77] &amp;quot;2020-03-29-garch-tutorial-in-r.Rmd&amp;quot;                      
##  [78] &amp;quot;2020-03-29-garch-tutorial-in-r.Rmd.lock~&amp;quot;                
##  [79] &amp;quot;2020-04-17-update-getdfpdata.Rmd&amp;quot;                        
##  [80] &amp;quot;2020-04-17-update-getdfpdata.Rmd.lock~&amp;quot;                  
##  [81] &amp;quot;2020-04-20-free-compiled-data-in-site.Rmd&amp;quot;               
##  [82] &amp;quot;2020-04-20-free-compiled-data-in-site.Rmd.lock~&amp;quot;         
##  [83] &amp;quot;2020-04-20-new-package-GetCVMData.Rmd&amp;quot;                   
##  [84] &amp;quot;2020-04-20-new-package-GetCVMData.Rmd.lock~&amp;quot;             
##  [85] &amp;quot;2020-04-25-investments-costs.Rmd&amp;quot;                        
##  [86] &amp;quot;2020-04-25-investments-costs.Rmd.lock~&amp;quot;                  
##  [87] &amp;quot;2020-05-24-pirf-is-online.Rmd&amp;quot;                           
##  [88] &amp;quot;2020-05-24-pirf-is-online.Rmd.lock~&amp;quot;                     
##  [89] &amp;quot;2020-05-27-call-for-papers-rac.Rmd&amp;quot;                      
##  [90] &amp;quot;2020-05-27-call-for-papers-rac.Rmd.lock~&amp;quot;                
##  [91] &amp;quot;2020-07-07-garch-tutorial-in-r-REVISED.Rmd&amp;quot;              
##  [92] &amp;quot;2020-07-07-garch-tutorial-in-r-REVISED.Rmd.lock~&amp;quot;        
##  [93] &amp;quot;2020-07-18-new_packages-GetFREData-GetDFPData2.Rmd&amp;quot;      
##  [94] &amp;quot;2020-07-18-new_packages-GetFREData-GetDFPData2.Rmd.lock~&amp;quot;
##  [95] &amp;quot;2020-12-22-Looking-Back-2020.Rmd&amp;quot;                        
##  [96] &amp;quot;2020-12-22-Looking-Back-2020.Rmd.lock~&amp;quot;                  
##  [97] &amp;quot;2021-02-18-dynamic-exercises-adfeR.Rmd&amp;quot;                  
##  [98] &amp;quot;2021-02-18-dynamic-exercises-adfeR.Rmd.lock~&amp;quot;            
##  [99] &amp;quot;2021-02-19-dynamic-exercises-adfeR.Rmd.lock~&amp;quot;            
## [100] &amp;quot;2021-02-20-adfeR-ed3-announcement.Rmd&amp;quot;                   
## [101] &amp;quot;2021-02-20-adfeR-ed3-announcement.Rmd.lock~&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The blog started in january of 2017 and, over time, I wrote 101 posts, around 33.6666667 per year. Let’s get more information from the .Rmd files. I’ll write function &lt;code&gt;read_blog_files&lt;/code&gt; and use it for all post files.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;read_blog_files &amp;lt;- function(f.in) {
  require(tidyverse)
  my.front.matter &amp;lt;- rmarkdown::yaml_front_matter(f.in)

  df.out &amp;lt;- data_frame(post.title = my.front.matter$title,
                       post.date = lubridate::ymd(my.front.matter$date),
                       post.month = as.Date(format(post.date, &amp;#39;%Y-%m-01&amp;#39;)),
                       tags = paste0(my.front.matter$tags, collapse = &amp;#39;;&amp;#39;),
                       categories = paste0(my.front.matter$categories, collapse = &amp;#39;;&amp;#39;),
                       content = paste0(read_lines(f.in), collapse = &amp;#39; &amp;#39;))

  return(df.out)
}

df.posts &amp;lt;- dplyr::bind_rows(purrr::map(post.files, read_blog_files))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `data_frame()` is deprecated as of tibble 1.1.0.
## Please use `tibble()` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(df.posts)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 50
## Columns: 6
## $ post.title &amp;lt;chr&amp;gt; &amp;quot;Writing a R book and self-publishing it in Amazon&amp;quot;, &amp;quot;Pack…
## $ post.date  &amp;lt;date&amp;gt; 2017-02-16, 2017-12-06, 2017-12-13, 2017-12-30, 2018-01-2…
## $ post.month &amp;lt;date&amp;gt; 2017-02-01, 2017-12-01, 2017-12-01, 2017-12-01, 2018-01-0…
## $ tags       &amp;lt;chr&amp;gt; &amp;quot;R;book;self-publish&amp;quot;, &amp;quot;R;GetDFPData;corporate events;fina…
## $ categories &amp;lt;chr&amp;gt; &amp;quot;R;book;self-publish&amp;quot;, &amp;quot;R;GetDFPData;B3&amp;quot;, &amp;quot;R;shiny;webserv…
## $ content    &amp;lt;chr&amp;gt; &amp;quot;--- title: \&amp;quot;Writing a R book and self-publishing it in A…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, let’s look at the frequency of posts over time.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df.posts &amp;lt;- df.posts %&amp;gt;%
  filter(post.date &amp;gt;= as.Date(&amp;#39;2019-01-01&amp;#39;), 
         post.date &amp;lt;= as.Date(&amp;#39;2020-01-01&amp;#39;))

print( ggplot(df.posts, aes(x = post.month)) + geom_histogram(stat=&amp;#39;count&amp;#39;) +
         theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
         labs(y = &amp;#39;Number of posts&amp;#39;, x = &amp;#39;&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Ignoring unknown parameters: binwidth, bins, pad&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2019-12-15-Looking-Back-2019_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;checking-2019s-plans&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Checking 2019’s plans&lt;/h1&gt;
&lt;p&gt;At the end of 2018, my plans for 2019 &lt;a href=&#34;https://www.msperlin.com/post/2019-01-08-looking-back-2018/&#34;&gt;were&lt;/a&gt;:&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;New edition of “Analyzing Financial and Economic Data with R”&lt;/dt&gt;
&lt;dd&gt;in progress!
&lt;/dd&gt;
&lt;dt&gt;Work on my new book: “Investing For the Long Term” (provisory title)&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;https://www.msperlin.com/publication/2019_book-pirf/&#34;&gt;Done!&lt;/a&gt; The first idea was to write a book about investing in general. I soon realized I would not be able to complete such task within one year. So, I decided to first write about the fixed income market and later, perhaps, write about stock markets and real state.
&lt;/dd&gt;
&lt;dt&gt;Solidify my research agenda in Board Composition&lt;/dt&gt;
&lt;dd&gt;In progress. I’ve got four papers in development, two already submitted and two in the pipeline.
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div id=&#34;plans-for-2020&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Plans for 2020&lt;/h1&gt;
&lt;dl&gt;
&lt;dt&gt;Publish afedR (analyzing financial and economic data with R)&lt;/dt&gt;
&lt;dd&gt;My expectation is to publish the book in the first months of the year. I believe it is quite doable, unless something unexpected happens.
&lt;/dd&gt;
&lt;dt&gt;Finish board papers&lt;/dt&gt;
&lt;dd&gt;Also doable. The working papers are in a good shape and should be submitted soon.
&lt;/dd&gt;
&lt;dt&gt;Start “personal finance project”&lt;/dt&gt;
&lt;dd&gt;I’m not yet sure how to call it, but I’ve got a couple of ideas for creating a project all about helping people with their finances.
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Static and Dynamic Book Exercises with R</title>
      <link>https://www.msperlin.com/post/2019-12-02-dynamic-exercises-afedr/</link>
      <pubDate>Mon, 02 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2019-12-02-dynamic-exercises-afedr/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div class=&#34;alert alert-warning&#34;&gt;
&lt;p&gt;
This post is deprecated due to changes in package code. See the new post in &lt;a href=&#34;https://www.msperlin.com/post/2021-02-28-dynamic-exercises-afedr/&#34;&gt;this link&lt;/a&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In the new edition of my R book, to be released in early 2020 (see &lt;a href=&#34;https://www.msperlin.com/files/afedr-files/afedR-TOC-2019-11-25.pdf&#34;&gt;current TOC&lt;/a&gt;, &lt;a href=&#34;https://www.msperlin.com/post/2019-11-25-feedback-toc-afedr/&#34;&gt;new packages&lt;/a&gt; and &lt;a href=&#34;https://forms.gle/3x3mj2zzXqcqmT6x9&#34;&gt;notification form&lt;/a&gt;), I’m giving special attention to its use in the classroom. For that, I’ve created class slides and R exercises in the static and dynamic form. All the extra content will be freely available in the internet and distributed with package &lt;code&gt;afedR&lt;/code&gt;. Anyone can use it, without the need of purchasing the book (but off course it would help).&lt;/p&gt;
&lt;p&gt;To access the files, first install the package from Github with &lt;code&gt;devtools&lt;/code&gt; (ignore warning messages about long paths):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;#39;msperlin/afedR&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can copy all book content to a local folder using the following function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_tempdir &amp;lt;- tempdir()
afedR::afedR_get_book_files(path_to_copy = my_tempdir)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The static exercises for all chapters are available in the &lt;code&gt;afedR files/eoc-exercises&lt;/code&gt; folder:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list.files(file.path(my_tempdir, &amp;#39;afedR files/eoc-exercises/&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Every .Rmd file is self-contained and should compile without any problems in your computer.&lt;/p&gt;
&lt;p&gt;Now, the real benefit of the package is in the &lt;strong&gt;dynamic R exercises&lt;/strong&gt; you can create with package &lt;code&gt;exams&lt;/code&gt;. &lt;a href=&#34;https://www.msperlin.com/post/2017-01-30-exams-with-dynamic-content/&#34;&gt;Back in 2017&lt;/a&gt; I already talked about my admiration and use of &lt;code&gt;exams&lt;/code&gt; in all of my university classes. In short, you can use &lt;code&gt;exams&lt;/code&gt; to create an unique version of a exercise for each student by randomizing numbers and text. All questions are written in .Rmd/.Rnw files and, since its all RMarkdown code, you can make it as dynamic as possible. The amount of hours it saved me so far in creating and grading exams is unbelievable! I even changed the structure of all my classes to a more activity-oriented coursework based on single-choice exercises. The feedback I get from the students has been very positive.&lt;/p&gt;
&lt;p&gt;As a result of using &lt;code&gt;exams&lt;/code&gt; for many years, I wrote a significant database of R single-choice questions that I use in my university courses. It amounts to 91 questions, covering R basics, functions, class objects, programming, econometrics, and much more. All of these exam questions are included in the package and I’ll add more with time. You can find all of them in a compiled html file in this &lt;a href=&#34;https://www.msperlin.com/files/Introduction%20to%20R_John%20Wick_Ver%2001.html&#34;&gt;link&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;creating-a-dynamic-exam&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Creating a Dynamic Exam&lt;/h2&gt;
&lt;p&gt;Creating a dynamic R exam is simple. All you need is the names of all students among other options. Function &lt;code&gt;afedR_build_exam&lt;/code&gt; will grab all exercise templates, compile each exam, and output a different .html file for each student. Have a look at a reproducible example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(afedR)
library(tidyverse)

set.seed(1)

student_names &amp;lt;- c(&amp;#39;Roger Federer&amp;#39;, &amp;#39;John Wick&amp;#39;, &amp;#39;Robert Engle&amp;#39;, 
                   &amp;#39;Getulio Vargas&amp;#39;, &amp;#39;Mario Quintana&amp;#39;, &amp;#39;Elis Regina&amp;#39;) 
my_ids &amp;lt;- c(sample(seq(length(student_names)))) # ids (usually a numeric and unique symbol given by the university)
class_name &amp;lt;- &amp;#39;R Workshop&amp;#39;
exercise_name &amp;lt;- &amp;#39;Introduction to R&amp;#39;
temp_dir &amp;lt;- file.path(tempdir(), &amp;#39;html exams&amp;#39;) # where to create exam files

l_out &amp;lt;- afedR_build_exam(students_names = student_names, 
                          students_ids = my_ids, 
                          class_name = class_name, 
                          exercise_name = &amp;#39;Introduction to R&amp;#39;,
                          chapters_to_include = 2, # single chapter for simplicity (it goes from 1-13)
                          dir_out = temp_dir)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Done. All exams files are available in folder &lt;code&gt;temp_dir&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list.files(temp_dir)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As an example of html output, file &lt;code&gt;Introduction to R_Roger Federer_Ver 01.html&lt;/code&gt; is available in this &lt;a href=&#34;https://www.msperlin.com/files/Introduction%20to%20R_Roger%20Federer_Ver%2001.html&#34;&gt;link&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Going further, the output of &lt;code&gt;afedR_build_exam&lt;/code&gt; is a list that includes the correct answers for each student/question:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(l_out$answer_key)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can use this table for grading all exams. Currently I use &lt;a href=&#34;https://www.google.com/forms/about/&#34;&gt;Google Forms&lt;/a&gt; to register student’s answers with an online questionnaire. This helps because I can turn all answers in a single Google Spreadsheet, import it in R with package &lt;code&gt;googlesheets4&lt;/code&gt;, and effortlessly grade all exams in a R script. Soon, in another post, I’ll write about my detailed workflow in using &lt;code&gt;exams&lt;/code&gt; with Google Forms and Google Classroom.&lt;/p&gt;
&lt;p&gt;I hope this content helps all R instructions around the world. But, it is a work in progress. If you find any issue, please let me know by &lt;a href=&#34;emailto:marceloperlin@gmail.com&#34;&gt;email&lt;/a&gt; or posting an issue event at the &lt;a href=&#34;https://github.com/msperlin/afedR&#34;&gt;github code&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The book is finally reaching its final version&lt;/strong&gt; and I’m very excited about it. Its been a long journey. You can find more details about the new book &lt;a href=&#34;https://www.msperlin.com/post/2019-11-25-feedback-toc-afedr/&#34;&gt;here&lt;/a&gt;. If you want to be notified about the publication, just sign this &lt;a href=&#34;https://forms.gle/3x3mj2zzXqcqmT6x9&#34;&gt;form&lt;/a&gt; and I’ll email you as soon as the book becomes available.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Feedback on new book TOC (Table of Contents)</title>
      <link>https://www.msperlin.com/post/2019-11-25-feedback-toc-afedr/</link>
      <pubDate>Mon, 25 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2019-11-25-feedback-toc-afedr/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Back in 2017 I wrote the first international&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; edition of my book “&lt;a href=&#34;https://www.msperlin.com/publication/2017_book-pafdr-en/&#34;&gt;Analyzing Financial and Economic Data with R&lt;/a&gt;” (&lt;a href=&#34;https://www.msperlin.com/pafdR/&#34;&gt;online version&lt;/a&gt;) . While I was happy with the content of the book at the time of publication, today I know I can make it better. As of early 2019, &lt;strong&gt;I’m working in the new edition of the book&lt;/strong&gt;, taking my time (and weekends!) in fixing all issues, expanding chapters and writing new CRAN packages.&lt;/p&gt;
&lt;p&gt;The current TOC is available &lt;a href=&#34;https://www.msperlin.com/files/afedr-files/afedR-TOC-2019-11-25.pdf&#34;&gt;here&lt;/a&gt;. Let me summarize the main changes from the previous edition:&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;New content with the tidyverse&lt;/dt&gt;
&lt;dd&gt;&lt;ul&gt;
&lt;li&gt;Total alignment with the tidyverse. Some base function are presented but priority is for readr, ggplot2, dplyr, stringr, purrr and so on.&lt;/li&gt;
&lt;li&gt;100+ pages of new content (a 25% overall increase from previous edition).&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;dt&gt;Teaching Material&lt;/dt&gt;
&lt;dd&gt;&lt;ul&gt;
&lt;li&gt;Static end of chapter exercises, with solutions publicly available in the internet;&lt;/li&gt;
&lt;li&gt;Slides for each chapter available in the internet;&lt;/li&gt;
&lt;li&gt;Dynamic 90+ exercises with the &lt;a href=&#34;http://www.r-exams.org/&#34;&gt;&lt;code&gt;exams&lt;/code&gt; package&lt;/a&gt;. This means you can create and grade randomized unique tests for your students (&lt;strong&gt;more on this in a future post&lt;/strong&gt;);&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;dt&gt;Book package &lt;code&gt;afedR&lt;/code&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;ul&gt;
&lt;li&gt;This package makes it easier to import book datasets, copy all content files and reproduce all code in the book. Available in &lt;a href=&#34;https://github.com/msperlin/afedR&#34;&gt;GitHub&lt;/a&gt; only.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;dt&gt;Three new chapters&lt;/dt&gt;
&lt;dd&gt;&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Cleaning and Structuring Financial and Economic Data&lt;/em&gt; – How to clean financial and economic data by dealing with long/wide dataframes, outlier detection/removal and desinflating prices and indexes.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Reporting Results&lt;/em&gt; – Using &lt;code&gt;xtable&lt;/code&gt; and &lt;code&gt;texreg&lt;/code&gt; to report tables and models. Includes a special section on RMarkdown.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Optimizing Code&lt;/em&gt; – Profiling code for bottlenecks and using vectorization, &lt;code&gt;rcpp&lt;/code&gt; and &lt;code&gt;memoise&lt;/code&gt; to speed up R computations.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;dt&gt;Two new packages&lt;/dt&gt;
&lt;dd&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;simfinR&lt;/code&gt; – grabs data from the &lt;a href=&#34;https://simfin.com/&#34;&gt;SimFin project&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GetQuandlData&lt;/code&gt;– uses &lt;a href=&#34;https://www.quandl.com/&#34;&gt;Quandl&lt;/a&gt; json api and caching for easier and faster data importation;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;&lt;strong&gt;Right now, I could use some feedback from the community&lt;/strong&gt;. Have a look in the &lt;a href=&#34;https://www.msperlin.com/files/afedr-files/afedR-TOC-2019-11-25.pdf&#34;&gt;TOC&lt;/a&gt; and let me know what you liked or disliked and if I missed something about using R in finance and economics. You can reach me in my email (&lt;a href=&#34;emailto:marceloperlin@gmail.com&#34;&gt;marceloperlin@gmail.com&lt;/a&gt;) or using the comment section of this post.&lt;/p&gt;
&lt;p&gt;My expectation is to finish the book in early 2020. If you want to be notified when I release it, fill up this &lt;a href=&#34;https://forms.gle/3x3mj2zzXqcqmT6x9&#34;&gt;form&lt;/a&gt; and I’ll email you when the book becomes available in Amazon.&lt;/p&gt;
&lt;p&gt;This book is a special and life-long project. I plan to keep improving it as long as I can. As for access to the content, I’ll follow the same pricing structure from previous edition: the ebook will sell for 9.99 USD in Amazon, the online version will have the first 6 chapters for free in the internet (see previous edition &lt;a href=&#34;https://www.msperlin.com/pafdR/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;I also wrote a &lt;a href=&#34;https://www.msperlin.com/padfeR/&#34;&gt;local version&lt;/a&gt;. written in portuguese.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>New package: simfinR</title>
      <link>https://www.msperlin.com/post/2019-11-01-new-package-simfinr/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2019-11-01-new-package-simfinr/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In my &lt;a href=&#34;https://www.msperlin.com/post/2019-10-16-new-package-getedgardata/&#34;&gt;latest post&lt;/a&gt; I wrote about package GetEdgarData, which downloaded structured data from the SEC. I’ve been working on this project and soon realized that the available data at the SEC/DERA section is not complete. For example, all Q4 statements are missing. This seems to be the way all exchanges release the financial documents. I’ve found the same problem here in the Brazilian exchange.&lt;/p&gt;
&lt;p&gt;It came to my attention that there is an alternative way of fetching corporate data and adjusted prices, the &lt;a href=&#34;https://simfin.com/&#34;&gt;SimFin project&lt;/a&gt;. From its own website:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Our core goal is to make financial data as freely available as possible because we believe that  having the right tools for investing/research shouldn&amp;#39;t be the privilege of those that can afford to spend thousands of dollars per year on data.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The platform is free with a daily limit of 2000 api calls. This is not bad and should suffice for most users. If you need more calls, the &lt;a href=&#34;https://simfin.com/simfin-plus&#34;&gt;premium version&lt;/a&gt; is just 10 euros a month, a fraction of what other data vendors usually request.&lt;/p&gt;
&lt;p&gt;Package &lt;code&gt;simfinR&lt;/code&gt;, available in &lt;a href=&#34;https://github.com/msperlin/simfinR/&#34;&gt;Github&lt;/a&gt; and soon in CRAN, facilitates all calls to the simfin API. It first makes sure the requested data exists and only then calls the api. As usual, all api queries are saved locally using package &lt;code&gt;memoise&lt;/code&gt;. This means that the second time you ask for a particular data about a company/year, the function will load a local copy, and will not call the web api.&lt;/p&gt;
&lt;p&gt;Package &lt;code&gt;GetEdgarData&lt;/code&gt;, however, will be discontinued. I’ll keep the files in &lt;a href=&#34;https://github.com/msperlin/GetEdgarData/&#34;&gt;Github&lt;/a&gt; but will no longer develop it. It takes a lot of time to write and maintain R packages, and I fell that simfinR has far more potential.&lt;/p&gt;
&lt;p&gt;As mentioned before, both new packages, &lt;a href=&#34;https://www.msperlin.com/post/2019-10-01-new-package-getquandldata/&#34;&gt;GetQuandlData&lt;/a&gt; and simfinR will be part of my next book, “Analyzing Financial and Economic Data with R”, which should be released in early 2020.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;installation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# not in CRAN yet (need to test it further)
#install.packages(&amp;#39;simfinR&amp;#39;)

# from Github
devtools::install_github(&amp;#39;msperlin/simfinR&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;example-01---apples-quarterly-net-profit&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example 01 - Apples Quarterly Net Profit&lt;/h3&gt;
&lt;p&gt;The first step in using &lt;code&gt;simfinR&lt;/code&gt; is finding information about available companies:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(simfinR)
library(tidyverse)

# You need to get your own api key at https://simfin.com/
my_api_key &amp;lt;- readLines(&amp;#39;~/Dropbox/98-pass_and_bash/.api_key_simfin.txt&amp;#39;)

# get info
df_info_companies &amp;lt;- simfinR_get_available_companies(my_api_key)

# check it
glimpse(df_info_companies)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 2,760
## Columns: 3
## $ simId  &amp;lt;int&amp;gt; 171401, 901704, 901866, 45730, 378251, 987611, 896477, 418866,…
## $ ticker &amp;lt;chr&amp;gt; &amp;quot;ZYXI&amp;quot;, &amp;quot;ZYNE&amp;quot;, &amp;quot;ZVO&amp;quot;, &amp;quot;ZUMZ&amp;quot;, &amp;quot;ZTS&amp;quot;, &amp;quot;ZSAN&amp;quot;, &amp;quot;ZS&amp;quot;, &amp;quot;ZNGA&amp;quot;, &amp;quot;Z…
## $ name   &amp;lt;chr&amp;gt; &amp;quot;ZYNEX INC&amp;quot;, &amp;quot;Zynerba Pharmaceuticals, Inc.&amp;quot;, &amp;quot;Zovio Inc&amp;quot;, &amp;quot;Zu…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We find information about 2760 companies. Digging deeper we find that the simfin id of Apple is 111052. Let’s use it to download the annual financial information since 2009.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;id_companies &amp;lt;- 111052 # id of APPLE INC
type_statements &amp;lt;- &amp;#39;pl&amp;#39; # profit/loss
periods = &amp;#39;FY&amp;#39; # final year
years = 2009:2018

df_fin_FY &amp;lt;- simfinR_get_fin_statements(id_companies,
                                     type_statements = type_statements,
                                     periods = periods,
                                     year = years,
                                     api_key = my_api_key)

glimpse(df_fin_FY)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 580
## Columns: 13
## $ company_name   &amp;lt;chr&amp;gt; &amp;quot;APPLE INC&amp;quot;, &amp;quot;APPLE INC&amp;quot;, &amp;quot;APPLE INC&amp;quot;, &amp;quot;APPLE INC&amp;quot;, &amp;quot;A…
## $ company_sector &amp;lt;chr&amp;gt; &amp;quot;Computer Hardware&amp;quot;, &amp;quot;Computer Hardware&amp;quot;, &amp;quot;Computer Ha…
## $ type_statement &amp;lt;fct&amp;gt; pl, pl, pl, pl, pl, pl, pl, pl, pl, pl, pl, pl, pl, pl…
## $ period         &amp;lt;fct&amp;gt; FY, FY, FY, FY, FY, FY, FY, FY, FY, FY, FY, FY, FY, FY…
## $ year           &amp;lt;int&amp;gt; 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, …
## $ ref_date       &amp;lt;date&amp;gt; 2009-12-31, 2009-12-31, 2009-12-31, 2009-12-31, 2009-…
## $ acc_name       &amp;lt;chr&amp;gt; &amp;quot;Revenue&amp;quot;, &amp;quot;Sales &amp;amp; Services Revenue&amp;quot;, &amp;quot;Financing Reve…
## $ acc_value      &amp;lt;dbl&amp;gt; 4.2905e+10, NA, NA, NA, -2.5683e+10, NA, NA, NA, 1.722…
## $ tid            &amp;lt;chr&amp;gt; &amp;quot;1&amp;quot;, &amp;quot;3&amp;quot;, &amp;quot;5&amp;quot;, &amp;quot;6&amp;quot;, &amp;quot;2&amp;quot;, &amp;quot;7&amp;quot;, &amp;quot;8&amp;quot;, &amp;quot;9&amp;quot;, &amp;quot;4&amp;quot;, &amp;quot;10&amp;quot;, &amp;quot;11…
## $ uid            &amp;lt;chr&amp;gt; &amp;quot;1&amp;quot;, &amp;quot;0&amp;quot;, &amp;quot;0&amp;quot;, &amp;quot;0&amp;quot;, &amp;quot;2&amp;quot;, &amp;quot;0&amp;quot;, &amp;quot;0&amp;quot;, &amp;quot;0&amp;quot;, &amp;quot;4&amp;quot;, &amp;quot;10&amp;quot;, &amp;quot;11…
## $ parent_tid     &amp;lt;chr&amp;gt; &amp;quot;4&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;4&amp;quot;, &amp;quot;2&amp;quot;, &amp;quot;2&amp;quot;, &amp;quot;2&amp;quot;, &amp;quot;19&amp;quot;, &amp;quot;19&amp;quot;, &amp;quot;1…
## $ display_level  &amp;lt;chr&amp;gt; &amp;quot;0&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;0&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;0&amp;quot;, &amp;quot;0&amp;quot;, &amp;quot;0&amp;quot;,…
## $ check_possible &amp;lt;lgl&amp;gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now we plot the results of the “Net Income” (profit/loss) for all years:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;net_income &amp;lt;- df_fin_FY %&amp;gt;% 
              filter(acc_name == &amp;#39;Net Income&amp;#39;)

p &amp;lt;- ggplot(net_income,
            aes(x = ref_date, y = acc_value)) +
  geom_col()  + 
  labs(title = &amp;#39;Yearly Profit of APPLE INC&amp;#39;,
       x = &amp;#39;&amp;#39;,
       y = &amp;#39;Yearly Profit&amp;#39;,
       subtitle = &amp;#39;&amp;#39;,
       caption = &amp;#39;Data from simfin &amp;lt;https://simfin.com/&amp;gt;&amp;#39;) + 
  theme_bw()

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2019-11-01-new-package-simfinR_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Not bad!&lt;/p&gt;
&lt;p&gt;We can also grab data for all quarters:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;type_statements &amp;lt;- &amp;#39;pl&amp;#39; # profit/loss
periods = c(&amp;#39;Q1&amp;#39;, &amp;#39;Q2&amp;#39;, &amp;#39;Q3&amp;#39;, &amp;#39;Q4&amp;#39;) # final year
years = 2009:2018

df_fin_quarters &amp;lt;- simfinR_get_fin_statements(id_companies,
                                     type_statements = type_statements,
                                     periods = periods,
                                     year = years,
                                     api_key = my_api_key)

glimpse(df_fin_quarters)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 2,320
## Columns: 13
## $ company_name   &amp;lt;chr&amp;gt; &amp;quot;APPLE INC&amp;quot;, &amp;quot;APPLE INC&amp;quot;, &amp;quot;APPLE INC&amp;quot;, &amp;quot;APPLE INC&amp;quot;, &amp;quot;A…
## $ company_sector &amp;lt;chr&amp;gt; &amp;quot;Computer Hardware&amp;quot;, &amp;quot;Computer Hardware&amp;quot;, &amp;quot;Computer Ha…
## $ type_statement &amp;lt;fct&amp;gt; pl, pl, pl, pl, pl, pl, pl, pl, pl, pl, pl, pl, pl, pl…
## $ period         &amp;lt;fct&amp;gt; Q1, Q1, Q1, Q1, Q1, Q1, Q1, Q1, Q1, Q1, Q1, Q1, Q1, Q1…
## $ year           &amp;lt;int&amp;gt; 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, …
## $ ref_date       &amp;lt;date&amp;gt; 2009-03-31, 2009-03-31, 2009-03-31, 2009-03-31, 2009-…
## $ acc_name       &amp;lt;chr&amp;gt; &amp;quot;Revenue&amp;quot;, &amp;quot;Sales &amp;amp; Services Revenue&amp;quot;, &amp;quot;Financing Reve…
## $ acc_value      &amp;lt;dbl&amp;gt; 1.188e+10, NA, NA, NA, -7.373e+09, NA, NA, NA, 4.507e+…
## $ tid            &amp;lt;chr&amp;gt; &amp;quot;1&amp;quot;, &amp;quot;3&amp;quot;, &amp;quot;5&amp;quot;, &amp;quot;6&amp;quot;, &amp;quot;2&amp;quot;, &amp;quot;7&amp;quot;, &amp;quot;8&amp;quot;, &amp;quot;9&amp;quot;, &amp;quot;4&amp;quot;, &amp;quot;10&amp;quot;, &amp;quot;11…
## $ uid            &amp;lt;chr&amp;gt; &amp;quot;1&amp;quot;, &amp;quot;0&amp;quot;, &amp;quot;0&amp;quot;, &amp;quot;0&amp;quot;, &amp;quot;2&amp;quot;, &amp;quot;0&amp;quot;, &amp;quot;0&amp;quot;, &amp;quot;0&amp;quot;, &amp;quot;4&amp;quot;, &amp;quot;10&amp;quot;, &amp;quot;11…
## $ parent_tid     &amp;lt;chr&amp;gt; &amp;quot;4&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;4&amp;quot;, &amp;quot;2&amp;quot;, &amp;quot;2&amp;quot;, &amp;quot;2&amp;quot;, &amp;quot;19&amp;quot;, &amp;quot;19&amp;quot;, &amp;quot;1…
## $ display_level  &amp;lt;chr&amp;gt; &amp;quot;0&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;0&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;0&amp;quot;, &amp;quot;0&amp;quot;, &amp;quot;0&amp;quot;,…
## $ check_possible &amp;lt;lgl&amp;gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And plot the results:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;net_income &amp;lt;- df_fin_quarters %&amp;gt;% 
              filter(acc_name == &amp;#39;Net Income&amp;#39;)

p &amp;lt;- ggplot(net_income,
            aes(x = period, y = acc_value)) +
  geom_col() + facet_grid(~year, scales = &amp;#39;free&amp;#39;) + 
  labs(title = &amp;#39;Quarterly Profit of APPLE INC&amp;#39;,
       x = &amp;#39;Quarters&amp;#39;,
       y = &amp;#39;Net Profit&amp;#39;) + 
  theme_bw()

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2019-11-01-new-package-simfinR_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Nice and impressive profit record. The first quarter (Q1) seems to present the best performance, probably due to end of year holidays.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example-02---quarterly-net-profit-of-many-companies&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example 02 - Quarterly Net Profit of Many Companies&lt;/h3&gt;
&lt;p&gt;Package &lt;code&gt;simfinR&lt;/code&gt; can also fetch information for many companies in a single call. Let’s run another example by selecting four random companies and creating the same previous graph:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(5)
my_ids &amp;lt;- sample(df_info_companies$simId, 4)
type_statements &amp;lt;- &amp;#39;pl&amp;#39; # profit/loss
periods = &amp;#39;FY&amp;#39; # final year
years = 2010:2018

df_fin &amp;lt;- simfinR_get_fin_statements(id_companies = my_ids,
                                     type_statements = type_statements,
                                     periods = periods,
                                     year = years,
                                     api_key = my_api_key)

net_income &amp;lt;- df_fin %&amp;gt;% 
              filter(acc_name == &amp;#39;Net Income&amp;#39;)

p &amp;lt;- ggplot(net_income,
            aes(x = ref_date, y = acc_value)) +
  geom_col() + 
  labs(title = &amp;#39;Annual Profit/Loss of Four Companies&amp;#39;,
       x = &amp;#39;&amp;#39;,
       y = &amp;#39;Net Profit/Loss&amp;#39;) + 
  facet_wrap(~company_name, scales = &amp;#39;free_y&amp;#39;) + 
  theme_bw()

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2019-11-01-new-package-simfinR_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example-03-fetching-price-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example 03: Fetching price data&lt;/h3&gt;
&lt;p&gt;The simfin project also provides adjusted prices of stocks. Have a look:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(5)
my_ids &amp;lt;- sample(df_info_companies$simId, 4)
type_statements &amp;lt;- &amp;#39;pl&amp;#39; # profit/loss
periods = &amp;#39;FY&amp;#39; # final year
years = 2009:2018

df_price &amp;lt;- simfinR_get_price_data(id_companies = my_ids,
                                     api_key = my_api_key)


p &amp;lt;- ggplot(df_price,
            aes(x = ref_date, y = close_adj)) +
  geom_line() + 
  labs(title = &amp;#39;Adjusted stock prices for four companies&amp;#39;,
       x = &amp;#39;&amp;#39;,
       y = &amp;#39;Adjusted Stock Prices&amp;#39;) + 
  facet_wrap(~company_name, scales = &amp;#39;free_y&amp;#39;) + 
  theme_bw()

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2019-11-01-new-package-simfinR_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As you can see, the data is comprehensive and should suffice for many different corporate finance research topics.&lt;/p&gt;
&lt;p&gt;Give it a try and, if you’ve found any problem or bug, please let me know at &lt;a href=&#34;mailto:marceloperlin@gmail.com&#34; class=&#34;email&#34;&gt;marceloperlin@gmail.com&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>New package: GetEdgarData</title>
      <link>https://www.msperlin.com/post/2019-10-16-new-package-getedgardata/</link>
      <pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2019-10-16-new-package-getedgardata/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;As of 2019-10-31, this package is discontinued and will not longer be updated. See &lt;a href=&#34;https://www.msperlin.com/post/2019-11-01-new-package-simfinr/&#34;&gt;this post&lt;/a&gt; for more details about the alternative, package simfinR.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Every company traded in the US stock market must report its quarterly and yearly documents to the SEC and the public in general. This includes its accounting statements (10-K, 10-K) and any other corporate event that is relevant to investors.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.sec.gov/edgar/searchedgar/companysearch.html&#34;&gt;Edgar&lt;/a&gt; is the interface where we can search for a company’s filling information. By looking up a company’s CIK code, one can find all previous filling information. A complete list of available forms can be found in this &lt;a href=&#34;https://www.sec.gov/forms&#34;&gt;link&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Package &lt;code&gt;GetEdgarData&lt;/code&gt; allows the user import the financial documents from such fillings directly into R. Unlike other packages, the information is not taken from the filling’s xml files, but the &lt;a href=&#34;https://www.sec.gov/dera/data&#34;&gt;structured datasets&lt;/a&gt; at the DERA (Division of Economic and Risk Analysis) section . This means we can import a large amount of structured financial data very quickly. The downside is that the available data starts at 2009.&lt;/p&gt;
&lt;p&gt;Like many other packages I’ve wrote for data grabbing, the queries are saved locally using package &lt;code&gt;memoise&lt;/code&gt;. This means that the second time you ask for a particular year of data, the function will load a local copy, and will not download the data again.&lt;/p&gt;
&lt;p&gt;Both new packages, &lt;code&gt;GetEdgarData&lt;/code&gt; and &lt;code&gt;GetQuandlData&lt;/code&gt; (&lt;a href=&#34;https://www.msperlin.com/post/2019-10-01-new-package-getquandldata/&#34;&gt;blog post&lt;/a&gt;) are going to be part of the second edition of my book “Analyzing Financial Data with R” (see first edition &lt;a href=&#34;https://www.msperlin.com/pafdR/&#34;&gt;here&lt;/a&gt;). My expectation is to publish the new book in early 2020.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;installation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# not in CRAN yet (need to test it further)
#install.packages(&amp;#39;GetEdgarData&amp;#39;)

# from github
devtools::install_github(&amp;#39;msperlin/GetEdgarData&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;example-01---apples-quarterly-net-profit&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example 01 - Apples Quarterly Net Profit&lt;/h3&gt;
&lt;p&gt;The first step in using &lt;code&gt;GetEdgarData&lt;/code&gt; is finding information about available companies:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(GetEdgarData)
library(tidyverse)

my_year &amp;lt;- 2018
type_form &amp;lt;- &amp;#39;10-K&amp;#39;

df_info &amp;lt;- get_info_companies(years = my_year, 
                              type_data = &amp;#39;yearly&amp;#39;, 
                              type_form = type_form)

glimpse(df_info)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We find information about &lt;code&gt;nrow(df_info)&lt;/code&gt; companies for the &lt;code&gt;type_form&lt;/code&gt; documents in the year of &lt;code&gt;my_year&lt;/code&gt;. Digging deeper we find that the official name of Apple is ‘APPLE INC’. Let’s use it to download the financial information since 2009.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_company &amp;lt;- &amp;#39;APPLE INC&amp;#39;
my_years &amp;lt;- 2009:2018
type_data &amp;lt;- &amp;#39;quarterly&amp;#39;

df_fin_reports &amp;lt;- get_edgar_fin_data(companies = my_company,
                                     years = my_years,
                                     type_data = type_data)

glimpse(df_fin_reports)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now we filter for the net income (id tag = ‘NetIncomeLoss’) and plot the resulting dataframe:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;net_income &amp;lt;- df_fin_reports %&amp;gt;%
  filter(tag == &amp;#39;NetIncomeLoss&amp;#39;)

p &amp;lt;- ggplot(net_income, 
            aes(x = ref_date, y = value_ref)) +
  geom_col() + 
  labs(title = &amp;#39;APPLE Quarterly Net Income (10-Q)&amp;#39;,
       subtitle = paste0(min(my_years), &amp;#39; - &amp;#39;, max(my_years)),
       x = &amp;#39;&amp;#39;,
       y = &amp;#39;Net Income ($)&amp;#39;,
       caption = paste0(&amp;#39;Data from EDGAR &amp;lt;https://www.sec.gov/edgar/searchedgar/companysearch.html&amp;gt;&amp;#39;, &amp;#39;\n&amp;#39;,
                        &amp;#39;Downloaded with package GetEdgarData&amp;#39;) )

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;example-02---quarterly-net-profit-of-many-companies&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example 02 - Quarterly Net Profit of Many Companies&lt;/h3&gt;
&lt;p&gt;The package is really handy for fetching information for many companies. This is due to the fact that the SEC/DERA stores data of all companies by year and the package creates a local cache of the resulting data. This means that, by fetching data for one company, we indirectly have information for all companies.&lt;/p&gt;
&lt;p&gt;Let’s see an example by selecting four random companies and creating the same previous graph:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(5)
my_companies &amp;lt;- sample(df_info$current_name, 4)
my_years &amp;lt;- 2009:2018
type_data &amp;lt;- &amp;#39;quarterly&amp;#39;

net_income &amp;lt;- get_edgar_fin_data(companies = my_companies,
                                 years = my_years,
                                 type_data = type_data) %&amp;gt;%
  filter(tag == &amp;#39;NetIncomeLoss&amp;#39;)

p &amp;lt;- ggplot(net_income, 
            aes(x = ref_date, y = value_ref)) +
  geom_col() + facet_wrap(~current_name, scales = &amp;#39;free&amp;#39;) + 
  labs(title = &amp;#39;Quarterly Net Income for Four Random companies&amp;#39;,
       subtitle = paste0(min(my_years), &amp;#39; - &amp;#39;, max(my_years)),
       x = &amp;#39;&amp;#39;,
       y = &amp;#39;Net Income ($)&amp;#39;,
       caption = paste0(&amp;#39;Data from EDGAR &amp;lt;https://www.sec.gov/edgar/searchedgar/companysearch.html&amp;gt;&amp;#39;, &amp;#39;\n&amp;#39;,
                        &amp;#39;Downloaded in R with package GetEdgarData&amp;#39;) )

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Give it a try and, if you’ve found any problem or bug, let me know at &lt;a href=&#34;mailto:marceloperlin@gmail.com&#34; class=&#34;email&#34;&gt;marceloperlin@gmail.com&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Help support GetDFPData</title>
      <link>https://www.msperlin.com/post/2019-10-12-support-getdfpdata-shiny/</link>
      <pubDate>Sat, 12 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2019-10-12-support-getdfpdata-shiny/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;The &lt;a href=&#34;https://www.msperlin.com/shiny/GetDFPData/&#34;&gt;shiny version of GetDFPData&lt;/a&gt; is currently hosted in a private server at DigitalOcean. A problem with the basic (5 USD) server I was using is with the low amount of available memory (RAM and HD). With that, I had to limit all xlsx queries for the data, otherwise the shiny app would ran out of memory. After upgrading R in the server, the xlsx option was no longer working.&lt;/p&gt;
&lt;p&gt;Today I tried all tricks in the book for keeping the 5 USD server and get the code to work. Nothing worked effectively. The Microsoft Excel is a very restrictive format, and you should only use it to small projects. If the volume of data is high, as in GetDFPData, you’re going to run into a lot of issues of cell sizes and memory allocation. Despite my explicit recommendation to avoid Excel format as much as possible, people still use it a lot. Not surprisingly, once I took the “xlsx” option from the shiny interface, people complained to my email – a lot.&lt;/p&gt;
&lt;p&gt;I just upgraded the RAM and HD of the server in DigitalOcean. &lt;strong&gt;The xlsx option is back and working&lt;/strong&gt;. The new bill is 10 USD per month. So far I’ve been paying the bill from my own pocket, using revenues from my &lt;a href=&#34;https://www.msperlin.com/publication/#5&#34;&gt;books&lt;/a&gt;. The GetDFPData has no official financial support and yes, I’ll continue to finance it as much as can. But, support from those using the shiny interface of the CRAN package is very much welcomed and will motive further development to keep things running smoothly.&lt;/p&gt;
&lt;p&gt;If you can, please help &lt;a href=&#34;https://www.msperlin.com/shiny/GetDFPData/&#34;&gt;donating a small value&lt;/a&gt; and keeping the server financed. Once I reach 12 months of payed bills (around 120 USD), I’ll remove the Paypal donation button and only add it back after the cash runs out.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New package: GetQuandlData</title>
      <link>https://www.msperlin.com/post/2019-10-01-new-package-getquandldata/</link>
      <pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2019-10-01-new-package-getquandldata/</guid>
      <description>


&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.quandl.com/search&#34;&gt;Quandl&lt;/a&gt; is one of the best platforms for finding and downloading financial and economic time series. The collection of free databases is solid and I use it intensively in my research and class material.&lt;/p&gt;
&lt;p&gt;But, a couple of things from the native package &lt;code&gt;Quandl&lt;/code&gt; always bothered me:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Multiple data is always returned in the wide (column oriented) format (why??);&lt;/li&gt;
&lt;li&gt;No local caching of data;&lt;/li&gt;
&lt;li&gt;No control for importing error and status;&lt;/li&gt;
&lt;li&gt;Not easy to work within the &lt;code&gt;tidyverse&lt;/code&gt; collection of packages&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As you suspect, I decided to tackle the problem over the weekend. The result is package &lt;code&gt;GetQuandlData&lt;/code&gt;. This is what it does differently:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It uses the json api (and not the Quandl native function), so that some metadata is also returned;&lt;/li&gt;
&lt;li&gt;The resulting dataframe is always returned in the long format, even for multiple series;&lt;/li&gt;
&lt;li&gt;Users can set custom names for input series. This is very useful when using along &lt;code&gt;ggplot&lt;/code&gt; or making tables;&lt;/li&gt;
&lt;li&gt;Uses package &lt;code&gt;memoise&lt;/code&gt; to set a local caching system. This means that the second time you ask for a particular time series, it will grab it from your hard drive (and not the internet);&lt;/li&gt;
&lt;li&gt;Always compares the requested dates against dates available in the platform.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;installation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# not in CRAN yet (need to test it further)
#install.packages(&amp;#39;GetQuandlData&amp;#39;)

# from github
devtools::install_github(&amp;#39;msperlin/GetQuandlData&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;example-01---inflation-in-the-us&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example 01 - Inflation in the US&lt;/h3&gt;
&lt;p&gt;Let’s download and plot information about inflation in the US:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(GetQuandlData)
library(tidyverse)

my_id &amp;lt;- c(&amp;#39;Inflation USA&amp;#39; = &amp;#39;YALE/SP_CPI&amp;#39;)
my_api &amp;lt;- readLines(&amp;#39;~/GDrive/98-pass-and-bash/.quandl_api.txt&amp;#39;) # you need your own API (get it at https://www.quandl.com/sign-up-modal?defaultModal=showSignUp&amp;gt;)
first_date &amp;lt;- &amp;#39;2005-01-01&amp;#39;
last_date &amp;lt;- Sys.Date()

df &amp;lt;- get_Quandl_series(id_in = my_id, 
                        api_key = my_api, 
                        first_date = first_date,
                        last_date = last_date, 
                        cache_folder = tempdir())

glimpse(df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 11
## Columns: 4
## $ Year        &amp;lt;chr&amp;gt; &amp;quot;2005-12-31&amp;quot;, &amp;quot;2006-12-31&amp;quot;, &amp;quot;2007-12-31&amp;quot;, &amp;quot;2008-12-31&amp;quot;, &amp;quot;2…
## $ series_name &amp;lt;chr&amp;gt; &amp;quot;Inflation USA&amp;quot;, &amp;quot;Inflation USA&amp;quot;, &amp;quot;Inflation USA&amp;quot;, &amp;quot;Inflat…
## $ value       &amp;lt;dbl&amp;gt; 190.700, 198.300, 202.416, 211.180, 211.143, 216.687, 220.…
## $ id_quandl   &amp;lt;chr&amp;gt; &amp;quot;YALE/SP_CPI&amp;quot;, &amp;quot;YALE/SP_CPI&amp;quot;, &amp;quot;YALE/SP_CPI&amp;quot;, &amp;quot;YALE/SP_CPI&amp;quot;…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, the data is in the long format. Let’s plot it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

p &amp;lt;- ggplot(df, aes(x = Year, y = value/100)) + 
  geom_col() + 
  labs(y = &amp;#39;Inflation (%)&amp;#39;, 
       x = &amp;#39;&amp;#39;,
       title = &amp;#39;Inflation in the US&amp;#39;) + 
  scale_y_continuous(labels = scales::percent)

p&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2019-10-01-new-package-GetQuandlData_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Beautiful!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example-02---inflation-for-many-countries&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example 02 - Inflation for many countries&lt;/h3&gt;
&lt;p&gt;Next, lets have a look into a more realistic case, where we need inflation data for several countries:&lt;/p&gt;
&lt;p&gt;First, we need to see what are the available datasets from database &lt;code&gt;RATEINF&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(GetQuandlData)
library(tidyverse)

db_id &amp;lt;- &amp;#39;RATEINF&amp;#39;
my_api &amp;lt;- readLines(&amp;#39;~/GDrive/98-pass-and-bash/.quandl_api.txt&amp;#39;) # you need your own API

df &amp;lt;- get_database_info(db_id, my_api)

knitr::kable(df)&lt;/code&gt;&lt;/pre&gt;
&lt;table style=&#34;width:100%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;4%&#34; /&gt;
&lt;col width=&#34;11%&#34; /&gt;
&lt;col width=&#34;60%&#34; /&gt;
&lt;col width=&#34;6%&#34; /&gt;
&lt;col width=&#34;3%&#34; /&gt;
&lt;col width=&#34;3%&#34; /&gt;
&lt;col width=&#34;7%&#34; /&gt;
&lt;col width=&#34;3%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;code&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;name&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;description&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;refreshed_at&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;from_date&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;to_date&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;quandl_code&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;quandl_db&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;CPI_ARG&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Consumer Price Index - Argentina&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2020-10-10 02:03:32&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1988-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2013-12-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/CPI_ARG&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;CPI_AUS&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Consumer Price Index - Australia&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:37&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1948-09-30&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2022-12-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/CPI_AUS&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;CPI_CAN&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Consumer Price Index - Canada&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:37&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1989-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/CPI_CAN&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;CPI_CHE&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Consumer Price Index - Switzerland&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:37&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1983-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/CPI_CHE&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;CPI_DEU&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Consumer Price Index - Germany&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:37&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1991-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/CPI_DEU&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;CPI_EUR&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Consumer Price Index - Euro Area&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:37&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1990-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/CPI_EUR&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;CPI_FRA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Consumer Price Index - France&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:37&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1990-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/CPI_FRA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;CPI_GBR&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Consumer Price Index - UK&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:38&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1988-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/CPI_GBR&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;CPI_ITA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Consumer Price Index - Italy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:38&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2001-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/CPI_ITA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;CPI_JPN&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Consumer Price Index - Japan&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:38&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1970-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/CPI_JPN&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;CPI_NZL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Consumer Price Index - New Zealand&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:38&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1926-03-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2022-12-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/CPI_NZL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;CPI_RUS&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Consumer Price Index - Russia&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:38&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1992-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2022-12-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/CPI_RUS&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;CPI_USA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Consumer Price Index - USA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:38&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1913-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/CPI_USA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;INFLATION_ARG&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Inflation YOY - Argentina&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2020-10-10 02:03:33&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1989-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2013-12-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/INFLATION_ARG&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;INFLATION_AUS&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Inflation YOY - Australia&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:38&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1949-03-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2022-12-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/INFLATION_AUS&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;INFLATION_CAN&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Inflation YOY - Canada&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:38&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1990-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/INFLATION_CAN&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;INFLATION_CHE&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Inflation YOY - Switzerland&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:38&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1984-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/INFLATION_CHE&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;INFLATION_DEU&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Inflation YOY - Germany&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:38&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1992-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/INFLATION_DEU&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;INFLATION_EUR&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Inflation YOY - Euro Area&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:38&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1991-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/INFLATION_EUR&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;INFLATION_FRA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Inflation YOY - France&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:38&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1991-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/INFLATION_FRA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;INFLATION_GBR&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Inflation YOY - UK&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:38&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1989-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/INFLATION_GBR&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;INFLATION_ITA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Inflation YOY - Italy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:38&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2002-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/INFLATION_ITA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;INFLATION_JPN&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Inflation YOY - Japan&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:38&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1971-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/INFLATION_JPN&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;INFLATION_NZL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Inflation YOY - New Zealand&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:38&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2001-03-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2022-12-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/INFLATION_NZL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;INFLATION_RUS&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Inflation YOY - Russia&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:38&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1996-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2022-12-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/INFLATION_RUS&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;INFLATION_USA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Inflation YOY - USA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Please visit &lt;a href=http://www.rateinflation.com/inflation-information/calculate-inflation&gt;http://www.rateinflation.com/inflation-information/calculate-inflation&lt;/a&gt; for more information.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-02-25 02:03:38&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1914-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2023-01-31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF/INFLATION_USA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RATEINF&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Nice. Now we only need to filter the series with YOY inflation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;idx &amp;lt;- stringr::str_detect(df$name, &amp;#39;Inflation YOY&amp;#39;)
df_series &amp;lt;- df[idx, ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and grab the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_id &amp;lt;- df_series$quandl_code
names(my_id) &amp;lt;- df_series$name
first_date &amp;lt;- &amp;#39;2010-01-01&amp;#39;
last_date &amp;lt;- Sys.Date()

df_inflation &amp;lt;- get_Quandl_series(id_in = my_id, 
                                  api_key = my_api,
                                  first_date = first_date,
                                  last_date = last_date)

glimpse(df_inflation)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 1,721
## Columns: 4
## $ series_name &amp;lt;chr&amp;gt; &amp;quot;Inflation YOY - Argentina&amp;quot;, &amp;quot;Inflation YOY - Argentina&amp;quot;, …
## $ ref_date    &amp;lt;date&amp;gt; 2010-01-31, 2010-02-28, 2010-03-31, 2010-04-30, 2010-05-3…
## $ value       &amp;lt;dbl&amp;gt; 8.24, 9.12, 9.66, 10.21, 10.66, 11.00, 11.20, 11.10, 11.09…
## $ id_quandl   &amp;lt;chr&amp;gt; &amp;quot;RATEINF/INFLATION_ARG&amp;quot;, &amp;quot;RATEINF/INFLATION_ARG&amp;quot;, &amp;quot;RATEINF…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And, finally, an elegant plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- ggplot(df_inflation, aes(x = ref_date, y = value/100)) + 
  geom_col() + 
  labs(y = &amp;#39;Inflation (%)&amp;#39;, 
       x = &amp;#39;&amp;#39;,
       title = &amp;#39;Inflation in the World&amp;#39;,
       subtitle = paste0(first_date, &amp;#39; to &amp;#39;, last_date)) + 
  scale_y_continuous(labels = scales::percent) + 
  facet_wrap(~series_name)

p&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2019-10-01-new-package-GetQuandlData_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>B3 is NOT shutting down its ftp site, for now..</title>
      <link>https://www.msperlin.com/post/2019-08-08-ftp-not-shutdown/</link>
      <pubDate>Thu, 08 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2019-08-08-ftp-not-shutdown/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;&lt;strong&gt;Update 2019-08-09: The shutdown is just postponed to 2019-11-14. See the official release &lt;a href=&#34;http://www.b3.com.br/pt_br/noticias/portais-8AE490C86BC98316016BDD1E7BDF14AB.htm?fbclid=IwAR1IY_ILkhkWwsBxFWH4pQEBx-OqxcEDxfmg22Ii5tep_dtzyKw9casag5o&#34;&gt;here&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Surprise, surprise. B3’s ftp site is still up and running.&lt;/p&gt;
&lt;p&gt;Following previous &lt;a href=&#34;https://www.msperlin.com/post/2019-07-01-ftp-shutdown/&#34;&gt;post&lt;/a&gt; regarding the shutdown of B3’s ftp site and its impact over GetHFData, I’m happy to report that the site is up and running.&lt;/p&gt;
&lt;p&gt;We can check it with code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(GetHFData)
library(tidyverse)

df.ftp &amp;lt;- ghfd_get_ftp_contents(type.market = &amp;#39;equity&amp;#39;)

# check time difference
max(df.ftp$dates) - min(df.ftp$dates)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s download some trade data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df.trades &amp;lt;- ghfd_get_HF_data(my.assets = &amp;#39;PETR3&amp;#39;, 
                              type.market = &amp;#39;equity&amp;#39;, 
                              first.date = max(df.ftp$dates)-3, 
                              last.date = max(df.ftp$dates),
                              type.data = &amp;#39;trades&amp;#39;, type.output = &amp;#39;agg&amp;#39;, 
                              first.time =  &amp;#39;11:00:00&amp;#39;, last.time = &amp;#39;18:00:00&amp;#39;, dl.dir = tempdir()
                              )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And check it out:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(df.trades)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Its working fine. The amount of data available at the ftp is more than necessary for research and class material.&lt;/p&gt;
&lt;p&gt;I’m not really sure what happened. It could be a simple delay to the shutdown. Lets keep our fingers crossed.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>B3 is shutting down its ftp site</title>
      <link>https://www.msperlin.com/post/2019-07-01-ftp-shutdown/</link>
      <pubDate>Mon, 01 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2019-07-01-ftp-shutdown/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;&lt;strong&gt;Well, bad news travels fast. &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Over the last couple of weeks I’ve been receiving a couple of emails regarding B3’s &lt;a href=&#34;http://www.b3.com.br/data/files/40/76/60/59/745666102F630666AC094EA8/CE%20018-2019%20-%20Prorroga%C3%A7%C3%A3o%20do%20Prazo%20de%20Desativa%C3%A7%C3%A3o%20do%20Servior%20FTP.pdf&#34;&gt;decision&lt;/a&gt; of shutting down its &lt;a href=&#34;ftp://ftp.bmf.com.br/&#34;&gt;ftp site&lt;/a&gt;. More specifically, users are eager to know how it will impact my data grabbing packages in CRAN. I’ll use this post to explain the situation for everyone.&lt;/p&gt;
&lt;p&gt;The only package affected directly will be &lt;code&gt;GetHFData&lt;/code&gt;, which uses the ftp site for downloading the raw zipped files with trades and quotes. The main function will no longer work as all internet files are not available. However, the function that reads the local files, &lt;code&gt;GetHFData::ghfd_read_file()&lt;/code&gt;, will still work as long as you have the files available in your computer.&lt;/p&gt;
&lt;p&gt;Soon I’ll release an update to &lt;code&gt;GetHFData&lt;/code&gt; that will bypass the ftp checking process. Users will be able to load up the code with local files. Btw, before anyone asks, I’m not aware of any other site that distributes the zipped files. In this topic, everyone should know that B3’s web policy does not allow the redistribution of their data.&lt;/p&gt;
&lt;p&gt;As for my personal opinion on the event, B3 is a private company and can do whatever they want with their data. In fact, it is standard for many international exchanges to sell their high-frequency trade&amp;amp;quote data. However, I fell that they could still offer a free sample of past raw data for students and researchers, keeping &lt;code&gt;GetHFData&lt;/code&gt; alive. I’m not sure how this would hurt their business. In fact, it is easy to argue that the “free” training would help them.&lt;/p&gt;
&lt;p&gt;On the research side, studying microstructure of the Brazilian financial market will become even more difficult now, without easy access to the datasets.&lt;/p&gt;
&lt;p&gt;As a clever stoic man once said, we should only worry about things we can control.&lt;/p&gt;
&lt;p&gt;Life (and research) goes on..&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Effect of Consistency on Corporate Net Income</title>
      <link>https://www.msperlin.com/post/2019-05-20-lindy-effect/</link>
      <pubDate>Mon, 20 May 2019 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2019-05-20-lindy-effect/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;One of the investment concepts that every long term investor should know is the effect of consistency over corporate performance. The main idea is that older and profitable companies are likely to continue to be profitable and even improve its performance in the upcoming years. Likewise, companies with constant losses are likely to continue in the same path.&lt;/p&gt;
&lt;p&gt;This idea is related to the &lt;a href=&#34;https://en.wikipedia.org/wiki/Lindy_effect&#34;&gt;Lindy Effect&lt;/a&gt;. Quoting directly from wikipedia:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The Lindy effect is a theory that the future life expectancy of some non-perishable things like a technology or an idea is proportional to their current age, so that every additional period of survival implies a longer remaining life expectancy.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As you should suspect by now, I am going to test this idea by looking at the predictive effect of consistent net profits/losses for companies traded at B3, the Brazilian financial exchange. First, let’s import the data and take a glimpse at it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(readxl)

my.f &amp;lt;- &amp;#39;~/Dropbox/03-Computer Code/01-R Code/02-Finance Code/Lindy effect on profit/data/LL.xlsx&amp;#39;
df &amp;lt;- read_excel(my.f) %&amp;gt;%
  glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 6,592
## Columns: 3
## $ id         &amp;lt;chr&amp;gt; &amp;quot;AALR&amp;quot;, &amp;quot;AALR&amp;quot;, &amp;quot;AALR&amp;quot;, &amp;quot;AALR&amp;quot;, &amp;quot;AALR&amp;quot;, &amp;quot;ABCB&amp;quot;, &amp;quot;ABCB&amp;quot;, &amp;quot;A…
## $ year       &amp;lt;dbl&amp;gt; 2014, 2015, 2016, 2017, 2018, 2004, 2005, 2006, 2007, 2008…
## $ net_income &amp;lt;dbl&amp;gt; -4, -11, 29, 15, 52, 53, 58, 61, 83, 137, 151, 202, 235, 2…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The structure is straightforward. The data was obtained from a financial portal&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; and already organized in a long format, saving myself from the work of restructuring it. As for the columns, it is all very basics. We have company’s id, year and net income.&lt;/p&gt;
&lt;p&gt;Next I’ll write a function that will do all the dirty work. The idea is to calculate, for each year/company/horizon, the cases where we find a particular result based on &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; results from the past. Confusing right? Let me try again. For example, let’s say you observe at a particular time &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; that a company performed the five past years with profits. What we want to know is if such a information can predict the profit in the next year.&lt;/p&gt;
&lt;p&gt;In other terms, conditional on the information about past results, what is the likelihood that the next net income will also be positive? By answering this question for every possible horizon, we can build a figure that relates the probability with the time consistency. If the Lindy effect is true for companies, we should see a positive association, that is, the longer the horizon of consecutive results, higher the chances of the same result.&lt;/p&gt;
&lt;p&gt;The code for the function is set below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fct_prob_calc_LL &amp;lt;- function(y, years, company) {
  require(tidyverse)
  
  nT &amp;lt;- length(y)
  
  df.res &amp;lt;- tibble()
  for (i.year in 2:length(years)) {
    lags.to.test &amp;lt;- 1:(i.year-1)
    for (i.lag in lags.to.test) {
      
      test.vec &amp;lt;- y[(i.year-i.lag):(i.year-1)]
      
      my.test1&amp;lt;- all(test.vec &amp;gt; 0)
      my.result1 &amp;lt;- y[i.year] &amp;gt; 0
      
      my.test2&amp;lt;- all(test.vec &amp;lt; 0)
      my.result2 &amp;lt;- y[i.year] &amp;lt; 0
      
      my.test3&amp;lt;- all(na.omit(diff(test.vec) &amp;gt; 0))
      my.result3 &amp;lt;- y[i.year] - y[i.year-1] &amp;gt; 0
      
      my.test4&amp;lt;- all(na.omit(diff(test.vec) &amp;lt; 0))
      my.result4 &amp;lt;- y[i.year] - y[i.year-1] &amp;lt; 0
      
      df.res &amp;lt;- bind_rows(df.res, 
                          tibble(company = company[1],
                                 year = years[i.year],
                                 horizon = i.lag,
                                 type.test = c(&amp;#39;Positive Net Income (profit)&amp;#39;,
                                               &amp;#39;Negative Net Income (loss)&amp;#39;,
                                               &amp;#39;Increase Net Income&amp;#39;,
                                                &amp;#39;Decrease Net Income&amp;#39;),
                                 test.flag = c(my.test1, my.test2, 
                                               my.test3, my.test4),
                                 result = c(my.result1, my.result2, 
                                            my.result3, my.result4)) )
    }
    
  }
  
  return(df.res)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now we use it for all companies:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(purrr)
library(furrr)

l.args &amp;lt;- list(y = split(df$net_income, f = df$id),
               years = split(df$year, f = df$id),
               company = split(df$id, f = df$id))

plan(multisession(workers = 10))

# get results
tab.test &amp;lt;- bind_rows(future_pmap(.l = l.args, .f = fct_prob_calc_LL, 
                                  .progress = TRUE)) %&amp;gt;%
  mutate(years = factor(year) ) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
 Progress: ────────────                                        100%
 Progress: ───────────────────                                 100%
 Progress: ────────────────────────────                        100%
 Progress: ─────────────────────────────────────               100%
 Progress: ─────────────────────────────────────────────       100%
 Progress: ─────────────────────────────────────────────────   100%
 Progress: ──────────────────────────────────────────────────  100%
 Progress: ──────────────────────────────────────────────────  100%
 Progress: ──────────────────────────────────────────────────  100%
 Progress: ─────────────────────────────────────────────────── 100%&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# build prob table
tab &amp;lt;- tab.test %&amp;gt;%
  filter(test.flag == TRUE) %&amp;gt;%
  group_by(horizon, type.test) %&amp;gt;%
  summarise(prob = mean(result, na.rm = TRUE),
            n = n(),
            n.companies = length(unique(company)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And finally build the plot with &lt;code&gt;ggplot2&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- ggplot(tab %&amp;gt;%
              filter(horizon &amp;lt;= 10), aes(x = horizon, 
                                         y = prob, group = type.test)) + 
  geom_point(aes(shape= type.test), size = 3) + geom_line(size = 0.75) + 
  #facet_wrap(~type.test, nrow = 2) + 
  labs(x = &amp;#39;Number of consecutive years&amp;#39;, 
       y = &amp;#39;Probability&amp;#39;,
       title = &amp;#39;The effect of Consistency over Net Income (Lindy Effect)&amp;#39;,
       subtitle = str_c(&amp;#39;The plot shows the probability of observing a future profit/loss given a number \n&amp;#39;,
                        &amp;#39; of consecutive profits/losses. See details in \n&amp;#39;,
                        &amp;#39; &amp;lt;https://en.wikipedia.org/wiki/Lindy_effect&amp;gt;&amp;#39;),
       caption = str_c(&amp;#39;Made by Marcelo S. Perlin (www.msperlin.com)\n&amp;#39;,
                       &amp;#39;The data covers net income of Brazilian companies from 2000 to 2019&amp;#39;) ) + 
  scale_y_continuous(labels = scales::percent, 
                     breaks = seq(0, 1, by = 0.1), limits = c(0,1)) + 
  scale_x_continuous(breaks = min(tab$horizon):max(tab$horizon)) + 
  theme_light() + #scale_shape_discrete(name = &amp;#39;Legenda&amp;#39;) + 
  theme(legend.title = element_blank(), legend.key.size = unit(1,&amp;quot;line&amp;quot;),
        legend.position = &amp;#39;bottom&amp;#39;) + 
  guides(shape=guide_legend(nrow=2,byrow=TRUE))

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2019-05-20-Lindy-Effect_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let me summarize the main conclusions from the plot:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Time is an ally to the profit of the company. &lt;strong&gt;The more consistent the company was in producing profit in the past, higher the chances of a profit in the future&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Net losses also cluster, but with a lower probability than profits&lt;/strong&gt;. Notice how the line for losses is always below the line for profits. This means that company with past losses for a given horizon has more chance to turn a profit than a company that shows consecutive profits to turn a loss.&lt;/li&gt;
&lt;li&gt;Changes in net income also have persistence memory, specially for increases. &lt;strong&gt;Companies that have increasing profits are likely to continue to increase its earnings&lt;/strong&gt;. Notice, however, that the probability of increased net income is distributed between 50% and 70%, much lower than for the chance of a positive net income.&lt;/li&gt;
&lt;li&gt;Companies with repeated decreases in its net income are more likely to turn an increase than to continue to decrease (see line at bottom of chart). Notice also that the code can’t find cases for a company with nine or more year of decreases in profit to exist. These are the companies that were bought or bankrupted.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The message from the data and the analysis is clear. &lt;strong&gt;In the corporate world, financial inertia is the rule, not the exception&lt;/strong&gt;. Good and profitable companies continue to be good and profitable enterprises, while bad and unprofitable companies also continue in the same path.&lt;/p&gt;
&lt;p&gt;From the investment point of view, &lt;strong&gt;the results suggests that time is a friend of the investor&lt;/strong&gt;. Overall, companies tend to improve its earnings. This corroborates the results from a &lt;a href=&#34;https://www.msperlin.com/post/2018-05-12-investing-long-run/&#34;&gt;previous post&lt;/a&gt;, where I analyzed the effect of the investment holding period over nominal and real returns to the investor. In short, the more time you stay in the market, the better.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Unfortunately I cannot distribute this structured dataset as it was one of the restrictions on receiving and publishing results based on it.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>R usage in Brazil</title>
      <link>https://www.msperlin.com/post/2019-05-17-r-in-brazil/</link>
      <pubDate>Fri, 17 May 2019 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2019-05-17-r-in-brazil/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I’m using R for at least five years and always been curious about its usage in Brazil. I see some minor personal evidence that the number of users is increasing over time. My &lt;a href=&#34;https://www.amazon.com.br/dp/B07DN4M357&#34;&gt;book in portuguese&lt;/a&gt; is steadily increasing its sales, and I’ve been receiving far more emails about my &lt;a href=&#34;https://www.crantastic.org/authors/5303&#34;&gt;R packages&lt;/a&gt;. Conference are also booming. Every year there are at least two or three R conferences in Brazil.&lt;/p&gt;
&lt;p&gt;What I learned from experience is that software choice is a group decision. It is very likely that you will use whatever your peer group uses. For example, if you are a PhD student, you will never convince your adviser to change research software, even if you have perfectly good reasons!&lt;/p&gt;
&lt;p&gt;It takes some independence and autonomy to be able to break free from bad group choices. In academia, you can only do that later on, when you finish your PhD and start your career. Then you can use whatever rocks your boat. And, even for that, it takes courage and humbleness to relearn all you research tricks, from data acquisition to reporting your results.&lt;/p&gt;
&lt;p&gt;In this post I’ll investigate the use of R in Brazil. Rstudio publishes a &lt;a href=&#34;http://cran-logs.rstudio.com/&#34;&gt;log page&lt;/a&gt; covering all R downloads and package installations. The data is organized by day and very easy to download and parse within R. After downloading it, I organized it by filtering only downloads in Brazil, and saved it in a .rds file. Let’s explore it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

df.dls &amp;lt;- read_rds(&amp;#39;data/r-downloads-brazil.rds&amp;#39;)

glimpse(df.dls)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 72,853
## Columns: 7
## $ date    &amp;lt;date&amp;gt; 2012-10-31, 2012-10-31, 2012-10-31, 2012-10-31, 2012-10-31, …
## $ time    &amp;lt;time&amp;gt; 16:17:34, 18:21:35, 19:26:20, 19:28:03, 19:26:03, 19:06:32, …
## $ size    &amp;lt;dbl&amp;gt; 49351035, 33301364, 49351035, 49351024, 1424794, 66523409, 45…
## $ version &amp;lt;chr&amp;gt; &amp;quot;2.15.2&amp;quot;, &amp;quot;2.15.2&amp;quot;, &amp;quot;2.15.2&amp;quot;, &amp;quot;2.15.2&amp;quot;, &amp;quot;2.15.2&amp;quot;, &amp;quot;2.15.2&amp;quot;, &amp;quot;…
## $ os      &amp;lt;chr&amp;gt; &amp;quot;win&amp;quot;, &amp;quot;win&amp;quot;, &amp;quot;win&amp;quot;, &amp;quot;win&amp;quot;, &amp;quot;win&amp;quot;, &amp;quot;osx&amp;quot;, &amp;quot;win&amp;quot;, &amp;quot;win&amp;quot;, &amp;quot;win&amp;quot;…
## $ country &amp;lt;chr&amp;gt; &amp;quot;BR&amp;quot;, &amp;quot;BR&amp;quot;, &amp;quot;BR&amp;quot;, &amp;quot;BR&amp;quot;, &amp;quot;BR&amp;quot;, &amp;quot;BR&amp;quot;, &amp;quot;BR&amp;quot;, &amp;quot;BR&amp;quot;, &amp;quot;BR&amp;quot;, &amp;quot;BR&amp;quot;, &amp;quot;…
## $ ip_id   &amp;lt;dbl&amp;gt; 30, 59, 73, 30, 87, 90, 143, 213, 231, 260, 260, 134, 181, 10…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, we have the date, time, version, os (platform), country and ip (randomized daily). First of all, let’s see how many downloads per day we have for Brazil. I’m also including the different release dates for major R versions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_by_day &amp;lt;- df.dls %&amp;gt;%
  group_by(ref.date = date) %&amp;gt;%
  summarise(n = n())

df.R.releases &amp;lt;- tibble(ref.date = as.Date(c(&amp;#39;2013-04-03&amp;#39;, &amp;#39;2014-04-10&amp;#39;,&amp;#39;2015-04-16&amp;#39;,
                                             &amp;#39;2016-05-03&amp;#39;, &amp;#39;2017-04-21&amp;#39;,
                                             &amp;#39;2018-04-23&amp;#39;, &amp;#39;2019-04-26&amp;#39;)),
                            R_version  = c(&amp;#39;3.0.0&amp;#39;, &amp;#39;3.1.0&amp;#39;,&amp;#39;3.2.0&amp;#39;, 
                                 &amp;#39;3.3.0&amp;#39;,&amp;#39;3.4.0&amp;#39;, &amp;#39;3.5.0&amp;#39;, 
                                 &amp;#39;3.6.0&amp;#39;) )

p &amp;lt;- ggplot(data = df_by_day, aes(y = n, 
                                  x = ref.date) ) + 
  geom_point() + geom_smooth(size = 2) + 
  labs(x = &amp;#39;Date (day)&amp;#39;, y= &amp;#39;Number of Downloads&amp;#39;, 
       title = paste0(&amp;#39;Number of R downloads in Brazil&amp;#39;),
       subtitle = &amp;#39;Data from Rstudio logs &amp;lt;http://cran-logs.rstudio.com/&amp;gt;&amp;#39;) + 
  geom_vline(data = df.R.releases,
             aes(xintercept = ref.date, color = R_version ), size = 1) + 
  scale_color_grey(start = 0.8, end = 0.2 )

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2019-05-17-R-in-Brazil_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The number of downloads is steadily increasing over time. The new releases of R also seems to explain the outliers in the dataset. Let’s clean it a bit by decreasing the frequency and calculating the number of downloads per month, instead of by day.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_by_month &amp;lt;- df.dls %&amp;gt;%
  group_by(ref.month = lubridate::ymd(format(date, &amp;#39;%Y-%m-01&amp;#39;))) %&amp;gt;%
  summarise(n = n())
  
p &amp;lt;- ggplot(data = df_by_month, aes(y = n, 
                                  x = ref.month) ) + 
  geom_point() + geom_smooth(size = 2) + 
  labs(x = &amp;#39;Date (month)&amp;#39;, y= &amp;#39;Number of Downloads&amp;#39;, 
       title = paste0(&amp;#39;Number of R downloads in Brazil&amp;#39;),
       subtitle = &amp;#39;Data from Rstudio logs &amp;lt;http://cran-logs.rstudio.com/&amp;gt;&amp;#39;) + 
  geom_vline(data = df.R.releases,
             aes(xintercept = ref.date, color = R_version ), size = 1) + 
  scale_color_grey(start = 0.8, end = 0.2 )


print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2019-05-17-R-in-Brazil_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Much better! Overall, R downloads average about 910.7 per month, with a monthly compound rate of 6%. It means that, each month, the number of downloads is increasing by 6% from previous month.&lt;/p&gt;
&lt;p&gt;The data also includes information about the operating system. Let’s check its distribution:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_by_os &amp;lt;- df.dls %&amp;gt;%
  group_by(os) %&amp;gt;%
  count() %&amp;gt;%
  na.omit() %&amp;gt;% ungroup() %&amp;gt;%
  mutate(os = fct_recode(os, 
                         &amp;quot;Windows&amp;quot; = &amp;quot;win&amp;quot;,
                         &amp;#39;Mac OS&amp;#39; = &amp;#39;osx&amp;#39;,
                         &amp;#39;Linux&amp;#39; = &amp;#39;src&amp;#39;))

p &amp;lt;- ggplot(df_by_os, aes(x = os, y = n)) + 
  geom_col() + 
  labs(x = &amp;#39;Operation System&amp;#39;, y = &amp;#39;Number of Download Cases&amp;#39;, 
       title = &amp;#39;Distribution of OS&amp;#39;,
       subtitle = &amp;#39;Data from Rstudio logs &amp;lt;http://cran-logs.rstudio.com/&amp;gt;&amp;#39;)

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2019-05-17-R-in-Brazil_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Not unexpectedly, Windows is the winner! I’m very surprised to see that Mac OS presents more downloads than Linux. With an unfavorable exchange rate and many import taxes, the price of a Mac computer — desktop or laptop — are exorbitantly expensive in Brazil. This tells a lot about the purchase power of R users.&lt;/p&gt;
&lt;p&gt;I hope you liked this post. Next time I’ll analyze the logs of package installation in Brazil.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Risk and return for B3</title>
      <link>https://www.msperlin.com/post/2019-05-01-meanvariance/</link>
      <pubDate>Wed, 01 May 2019 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2019-05-01-meanvariance/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;One of the subjects that I teach in my undergraduate finance class is the relationship between risk and expected returns. In short, the riskier the investment, more returns should be &lt;strong&gt;expected&lt;/strong&gt; by the investor. It is not a difficult argument to make. All that you need to understand is to remember that people are not naive in financial markets. Whenever they make a big gamble, the rewards should also be large. Rational investors, on theory, would not invest in risky stocks that are likelly to yield low returns.&lt;/p&gt;
&lt;p&gt;Going further, one the arguments I make to support this idea is looking at historical data. By assuming that expected returns is the average yearly return rate on a stock and the risk is the standard deviation of the same returns, we can check for a positive relationship by plotting the data in a scatter plot.&lt;/p&gt;
&lt;p&gt;In this post I’ll show how you can do it easily in R using &lt;code&gt;BatchGetSymbols&lt;/code&gt;, &lt;code&gt;GetBCBData&lt;/code&gt; and &lt;code&gt;tidyverse&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;First, we will gather and organize all data sets. Here I’m using the stock components of Ibovespa, the Brazilian market index, and also CDI, a common risk free rate in Brazil. The next code will:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Import the data&lt;/li&gt;
&lt;li&gt;organize it in the same structure (same columns)&lt;/li&gt;
&lt;li&gt;bind it all together&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get stock data
library(tidyverse)
library(BatchGetSymbols)
library(GetBCBData)

first.date &amp;lt;- &amp;#39;2008-01-01&amp;#39; # last date is Sys.Date by default

# get stock data
df.ibov &amp;lt;- GetIbovStocks()
mkt.idx &amp;lt;- c(&amp;#39;^BVSP&amp;#39;)
my.tickers &amp;lt;- c(mkt.idx, paste0(df.ibov$tickers, &amp;#39;.SA&amp;#39;) )

df.prices &amp;lt;- BatchGetSymbols(tickers = my.tickers, first.date = first.date,
                             freq.data = &amp;#39;yearly&amp;#39;, 
                             be.quiet = TRUE)[[2]]

tab.stocks &amp;lt;- df.prices %&amp;gt;%
  na.omit() %&amp;gt;%
  group_by(ticker) %&amp;gt;%
  summarise(mean.ret = mean(ret.adjusted.prices),
            sd.ret = sd(ret.adjusted.prices)) %&amp;gt;%
  mutate(ticker = str_replace_all(ticker, fixed(&amp;#39;.SA&amp;#39;), &amp;#39;&amp;#39;) )

tab.mkt.idx &amp;lt;- tab.stocks %&amp;gt;%
               filter(ticker %in% mkt.idx)

tab.stocks &amp;lt;- tab.stocks %&amp;gt;%
               filter(!(ticker %in% mkt.idx))

# get CDI (risk free rate) 
my.id &amp;lt;- c(CDI = 4389)

tab.CDI &amp;lt;- gbcbd_get_series(my.id, first.date = first.date) %&amp;gt;%
  rename(ticker = series.name ) %&amp;gt;%
  mutate(ref.date = format(ref.date, &amp;#39;%Y&amp;#39;),
         value = value/100) %&amp;gt;%
  group_by(ref.date, ticker) %&amp;gt;%
  summarise(ret = mean(value)) %&amp;gt;%
  group_by(ticker) %&amp;gt;%
  summarise(mean.ret = mean(ret),
            sd.ret = sd(ret))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have the data, lets use &lt;code&gt;ggplot&lt;/code&gt; to build our graph.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

p &amp;lt;- ggplot(tab.stocks, aes(x = sd.ret, y = mean.ret, group = ticker)) + 
  geom_point() + 
  geom_text(data = tab.stocks, aes(x = sd.ret, y = mean.ret, label = ticker), nudge_y = 0.03,
            check_overlap = TRUE, nudge_x = 0.05 ) + 
  geom_point(data = tab.CDI, aes(x = sd.ret, y = mean.ret, color = ticker), size =5) +
  geom_point(data = tab.mkt.idx, 
             aes(x = sd.ret, y = mean.ret, color = ticker), size =5) +
  labs(x = &amp;#39;Risk (standard deviation)&amp;#39;, y =&amp;#39;Expected Returns (average)&amp;#39;, 
       title = &amp;#39;Mean X Variance map for B3&amp;#39;,
       subtitle = paste0(nrow(tab.stocks), &amp;#39; stocks, &amp;#39;, lubridate::year(min(df.prices$ref.date)), 
                         &amp;#39; - &amp;#39;, lubridate::year(max(df.prices$ref.date)))) + 
  scale_x_continuous(labels = scales::percent) + 
  scale_y_continuous(labels = scales::percent)  

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2019-05-01-MeanVariance_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Looks pretty! What do we learn?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Overall, most of the stocks did better than the risk free rate (CDI);&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;There is a positive relationship between risk and return. The higher the standard deviation (x-axis), the higher the mean of returns (y-axis). However, notice that it is not a perfect relationship. If we followed the mean-variance gospel, there are lots of opportunities of arbitrage. We would mostly invest in those stocks in the upper-left part of the plot;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Surprisingly, the market index, Ibovespa (^BVSP), is not well positioned in the graph. Since it is a diversified portfolio, I expected it to be closer to the frontier, around stock EQTL3.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>New package: GetBCBData</title>
      <link>https://www.msperlin.com/post/2019-04-15-getbcbdata/</link>
      <pubDate>Mon, 15 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2019-04-15-getbcbdata/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;The Central Bank of Brazil (BCB) offers access to the SGS system (sistema gerenciador de series temporais) with a official API available &lt;a href=&#34;http://www.bcb.gov.br/?sgs&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Over time, I find myself using more and more of the available datasets in my regular research and studies. Last weekend I decided to write my own API package that would make my life (and others) a lot easier.&lt;/p&gt;
&lt;p&gt;Package GetBCBData can fetch data efficiently and rapidly:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use of a caching system with package &lt;code&gt;memoise&lt;/code&gt; to speed up repeated requests of data;&lt;/li&gt;
&lt;li&gt;Users can utilize all cores of the machine (parallel computing) when fetching a large batch of time series;&lt;/li&gt;
&lt;li&gt;Allows the choice for format output: long (row oriented, tidy data) or wide (column oriented)&lt;/li&gt;
&lt;li&gt;Error handling internally. Even if requested series does not exist, the function will still return all results.&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;installation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# CRAN (official release) - IN CHECK
install.packages(&amp;#39;GetBCBData&amp;#39;)

# Github (dev version)
devtools::install_github(&amp;#39;msperlin/GetBCBData&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;a-simple-example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A simple example&lt;/h2&gt;
&lt;p&gt;Let’s have a look at unemployment rates around the world. After searching for the ids in the &lt;a href=&#34;http://www.bcb.gov.br/?sgs&#34;&gt;SGS system&lt;/a&gt;, we find the ids for 6 countries and set it as input &lt;code&gt;id&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now, let’s download the data with &lt;code&gt;GetBCBData&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#devtools::install_github(&amp;#39;msperlin/GetBCBData&amp;#39;)

library(GetBCBData)
library(tidyverse)

my.countries &amp;lt;- c(&amp;#39;Germany&amp;#39;, &amp;#39;Canada&amp;#39;, &amp;#39;USA&amp;#39;, 
                  &amp;#39;France&amp;#39;, &amp;#39;Italy&amp;#39;, &amp;#39;Japan&amp;#39;)

my.ids &amp;lt;- c(3785:3790)

names(my.ids) &amp;lt;- paste0(&amp;#39;Unemp. rate - &amp;#39;, my.countries)

df.bcb &amp;lt;- gbcbd_get_series(id = my.ids ,
                           first.date = &amp;#39;2000-01-01&amp;#39;,
                           last.date = Sys.Date())

glimpse(df.bcb)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 1,196
## Columns: 4
## $ ref.date    &amp;lt;date&amp;gt; 2000-01-01, 2000-02-01, 2000-03-01, 2000-04-01, 2000-05-…
## $ value       &amp;lt;dbl&amp;gt; 8.2, 8.1, 8.1, 8.0, 8.0, 8.0, 7.9, 7.9, 7.9, 7.8, 7.8, 7.…
## $ id.num      &amp;lt;int&amp;gt; 3785, 3785, 3785, 3785, 3785, 3785, 3785, 3785, 3785, 378…
## $ series.name &amp;lt;chr&amp;gt; &amp;quot;Unemp. rate - Germany&amp;quot;, &amp;quot;Unemp. rate - Germany&amp;quot;, &amp;quot;Unemp.…&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- ggplot(df.bcb, aes(x = ref.date, y = value) ) +
  geom_line() + 
  labs(title = &amp;#39;Unemploymnent Rates Around the World&amp;#39;, 
       subtitle = paste0(min(df.bcb$ref.date), &amp;#39; to &amp;#39;, max(df.bcb$ref.date)),
       x = &amp;#39;&amp;#39;, y = &amp;#39;Percentage*100&amp;#39;) + facet_wrap(~series.name)


print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2019-04-15-GetBCBData_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>BatchGetSymbols is now parallel!</title>
      <link>https://www.msperlin.com/post/2019-04-13-parallel-batchgetsymbols/</link>
      <pubDate>Sat, 13 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2019-04-13-parallel-batchgetsymbols/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;&lt;a href=&#34;https://github.com/msperlin/BatchGetSymbols&#34;&gt;BatchGetSymbols&lt;/a&gt; is my most downloaded package by any count. Computation time, however, has always been an issue. While downloading data for 10 or less stocks is fine, doing it for a large ammount of tickers, say the SP500 composition, gets very boring.&lt;/p&gt;
&lt;p&gt;I’m glad to report that time is no longer an issue. Today I implemented a parallel option for BatchGetSymbols. If you have a high number of cores in your computer, you can seriously speep up the importation process. Importing SP500 compositition, over 500 stocks, is a breeze.&lt;/p&gt;
&lt;p&gt;Give a try. The new version is already available in Github:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;#39;msperlin/BatchGetSymbols&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It should be in CRAN soon.&lt;/p&gt;
&lt;div id=&#34;how-to-use-parallel&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How to use parallel&lt;/h2&gt;
&lt;p&gt;Very simple. Just set you parallel plan with &lt;code&gt;future::plan&lt;/code&gt; and use input &lt;code&gt;do.parallel = TRUE&lt;/code&gt; in &lt;code&gt;BatchGetSymbols&lt;/code&gt;. If you are not sure how many cores you have available, just run the following code to figure it out:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;future::availableCores()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## system 
##     16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#devtools::install_github(&amp;#39;msperlin/BatchGetSymbols&amp;#39;)
library(BatchGetSymbols)

# get tickers from SP500
df.sp500 &amp;lt;- GetSP500Stocks()
tickers &amp;lt;- df.sp500$Tickers
  
future::plan(future::multisession, 
             workers = 10) # use 10 cores (future::availableCores())

# dowload data for 50 stocks  
l.out &amp;lt;- BatchGetSymbols(tickers = tickers[1:50], 
                         first.date = &amp;#39;2010-01-01&amp;#39;, 
                         last.date = &amp;#39;2019-01-01&amp;#39;,
                         do.parallel = TRUE, 
                         do.cache = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
 Progress: ─────────────────────────────────────────           100%
 Progress: ───────────────────────────────────────────────     100%
 Progress: ─────────────────────────────────────────────────   100%
 Progress: ─────────────────────────────────────────────────── 100%&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(l.out)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 2
##  $ df.control: tibble [50 × 6] (S3: tbl_df/tbl/data.frame)
##   ..$ ticker              : chr [1:50] &amp;quot;MMM&amp;quot; &amp;quot;ABT&amp;quot; &amp;quot;ABBV&amp;quot; &amp;quot;ABMD&amp;quot; ...
##   ..$ src                 : chr [1:50] &amp;quot;yahoo&amp;quot; &amp;quot;yahoo&amp;quot; &amp;quot;yahoo&amp;quot; &amp;quot;yahoo&amp;quot; ...
##   ..$ download.status     : chr [1:50] &amp;quot;OK&amp;quot; &amp;quot;OK&amp;quot; &amp;quot;OK&amp;quot; &amp;quot;OK&amp;quot; ...
##   ..$ total.obs           : int [1:50] 2264 2264 1510 2264 2264 2264 2264 2264 2264 2264 ...
##   ..$ perc.benchmark.dates: num [1:50] 1 1 0.667 1 1 ...
##   ..$ threshold.decision  : chr [1:50] &amp;quot;KEEP&amp;quot; &amp;quot;KEEP&amp;quot; &amp;quot;OUT&amp;quot; &amp;quot;KEEP&amp;quot; ...
##  $ df.tickers:&amp;#39;data.frame&amp;#39;:  106408 obs. of  10 variables:
##   ..$ price.open         : num [1:106408] 83.1 82.8 83.9 83.3 83.7 ...
##   ..$ price.high         : num [1:106408] 83.4 83.2 84.6 83.8 84.3 ...
##   ..$ price.low          : num [1:106408] 82.7 81.7 83.5 82.1 83.3 ...
##   ..$ price.close        : num [1:106408] 83 82.5 83.7 83.7 84.3 ...
##   ..$ volume             : num [1:106408] 3043700 2847000 5268500 4470100 3405800 ...
##   ..$ price.adjusted     : num [1:106408] 63.5 63.1 64 64.1 64.5 ...
##   ..$ ref.date           : Date[1:106408], format: &amp;quot;2010-01-04&amp;quot; &amp;quot;2010-01-05&amp;quot; ...
##   ..$ ticker             : chr [1:106408] &amp;quot;MMM&amp;quot; &amp;quot;MMM&amp;quot; &amp;quot;MMM&amp;quot; &amp;quot;MMM&amp;quot; ...
##   ..$ ret.adjusted.prices: num [1:106408] NA -0.006263 0.014182 0.000717 0.007047 ...
##   ..$ ret.closing.prices : num [1:106408] NA -0.006264 0.014182 0.000717 0.007046 ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Can you turn 1500 USD into 1.000.430 USD by investing in the stock market for three years?</title>
      <link>https://www.msperlin.com/post/2019-03-23-bettina-case/</link>
      <pubDate>Sat, 23 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2019-03-23-bettina-case/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;In the last few weeks we’ve seen a great deal of controversy in Brazil regarding financial investments. Too keep it short, &lt;em&gt;Empiricus&lt;/em&gt;, an ad-based company that massively sells online courses and subscriptions, posted a YouTube ad where a young girl, Bettina, &lt;a href=&#34;https://canaltech.com.br/memes/entenda-o-caso-bettina-a-jovem-tia-patinhas-brasileira-que-virou-meme-135035/&#34;&gt;says the following&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Hi, I&amp;#39;m Bettina, I am 22 years old and, starting with R$ 1,500, I now own R$ 1,042,000 of  accumulated wealth.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;She later explains that she &lt;em&gt;earned&lt;/em&gt; the money by investing in the stock market over three years. For my international audience, the proposed investment is equivalent of turning 394 dolars into 263169.2 dolars over a three year period.&lt;/p&gt;
&lt;p&gt;Anyone with a economics or business background will easily spot that the financial returns stated in the ad is simply not possible. Even if Bettina is a very good investor, reaching this level of returns over a three year period in the stock market is unheard of. The yearly rate of return of the investment is equal to 774% per year. The monthly rate proposed in the ad is equivalent to 20% per month.&lt;/p&gt;
&lt;p&gt;Giving perspective, Buffet, one of the greatest long term investor of all times, has reached the approximate rate of 19% &lt;strong&gt;per year&lt;/strong&gt;, around 1.46% per month. So, Bettina is either a financial genius that, with only 22 years old, was able to beat &lt;em&gt;Buffet&lt;/em&gt; in its own game, or the ad is not fully committed to the truth. To be fair, even if we took the difference of inflation rates between Brazil and US into account, the difference is still very impressive and misleading.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/samydana/status/1107104905205039104&#34;&gt;Others&lt;/a&gt; have pointed out that if you compound these return over time, the result will be economically unrealistic. See next what happens to R$ 1.500 if we assume that you can replicate the alledged investment return of Bettina (774% per year) over a 10 year period.&lt;/p&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:unnamed-chunk-3&#34;&gt;Table 1: &lt;/span&gt;Compounding returns for Bettina
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Number of years
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Investiment value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R$ 13.103,89
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R$ 114.474,71
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R$ 1.000.043,00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R$ 8.736.305,50
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R$ 76.319.752,11
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R$ 666.724.001,23
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R$ 5.824.454.109,93
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R$ 50.882.022.569,93
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R$ 444.501.780.243,15
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R$ 3.883.136.374.301,74
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;If Bettina is a genius and can replicate her result over the years, she will be a billionaire in 7 years and a trillionaire in 10. If she waited one more year, she could even buy the whole country if she wanted to. The current GDP of Brazil is around 2 trillion USD (7.5 trillion in R$). She can easily reach this amount of cash in 12 years or more.&lt;/p&gt;
&lt;p&gt;But lets go further in this endeavor. Let’s stop being skeptic about her returns and see whether its possible to achieve such returns in the stock market. As you can expect, I’m taking a data based approach. I’ll compare the returns of Bettina to &lt;em&gt;GodBot&lt;/em&gt;, a computer algorithm that can perfectly predict stock prices.&lt;/p&gt;
&lt;p&gt;First, let’s download some stock data from B3, the Brazilian stock exchange.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(BatchGetSymbols)

df.ibov &amp;lt;- GetIbovStocks()

my.tickers &amp;lt;- paste0(df.ibov$tickers, &amp;#39;.SA&amp;#39;)

df.stocks &amp;lt;- BatchGetSymbols(tickers = my.tickers,
                            first.date = &amp;#39;2010-01-01&amp;#39;, 
                            last.date = &amp;#39;2019-01-01&amp;#39;, 
                            cache.folder = &amp;#39;~/.mem_cache/BGS_Cache&amp;#39;)[[2]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;My god bot has a single and simple rule:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For each month, it will always invest 100% in the stock with the highest return for the month&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Next we code this &lt;em&gt;bot&lt;/em&gt; using &lt;code&gt;tidyverse&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

res.inv &amp;lt;- df.stocks %&amp;gt;%
 mutate(ref.month = as.Date(format(ref.date, &amp;#39;%Y-%m-01&amp;#39;))) %&amp;gt;%
 group_by(ref.month, ticker) %&amp;gt;%
 summarise(ret.month = last(price.adjusted)/first(price.adjusted) - 1) %&amp;gt;%
 group_by(ref.month) %&amp;gt;%
 summarise(best.ticker = ticker[which.max(ret.month)],
           best.return = ret.month[which.max(ret.month)])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s have a look in those returns:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

# bettinas returns
initial.cash &amp;lt;- 1500
last.cash &amp;lt;- 1000043
my.T &amp;lt;- 3 # years

r.aa &amp;lt;- (last.cash/initial.cash)^(1/3) -1 
r.am &amp;lt;- (last.cash/initial.cash)^(1/(3*12)) -1 

p &amp;lt;- ggplot(res.inv, aes(x = ref.month, y = best.return)) + 
 geom_col() + 
 geom_hline(yintercept =r.am, color = &amp;#39;red&amp;#39;, size =1.5) + 
 labs(x = &amp;#39;Time&amp;#39;, y = &amp;#39;Monthly Returns&amp;#39;,
      title = &amp;#39;Monthly Returns of Bettina and GodBot&amp;#39;,
      subtitle = paste0(&amp;#39;- This plot shows the &amp;quot;alleged&amp;quot; returns from Bettina against a perfect predictor \n for the BR stock market\n&amp;#39;,
                        &amp;#39;- The horizontal red line represents the return of Bettina (19.79% monthly)&amp;#39;),
      caption = &amp;#39;www.msperlin.com&amp;#39;
       ) + 
 scale_y_continuous(labels = scales::percent)

p&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2019-03-23-Bettina-Case_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As you can see, Bettina did good with a constant monthly return of 20%. But, &lt;em&gt;GodBot&lt;/em&gt; is better. Bettina is clearly missing something out!&lt;/p&gt;
&lt;p&gt;When looking at the nominal value of the investment, the effect of compound returns explodes the value of the portfolio.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyr)

format.cash &amp;lt;- function(x) {
 require(scales)

 x.formatted &amp;lt;- dollar(x,
                       prefix = &amp;#39;R$ &amp;#39;,
                       decimal.mark = &amp;#39;,&amp;#39;,
                       big.mark = &amp;#39;.&amp;#39;,
                       largest_with_cents = Inf)

 return(x.formatted)
}

df.cumret &amp;lt;- res.inv %&amp;gt;%
 mutate(cumret.godbot = initial.cash*cumprod(1+res.inv$best.return),
        cumret.bettina =initial.cash*cumprod(1+rep(r.am, n())) ) %&amp;gt;%
 select(-best.ticker, -best.return)

df.to.plot &amp;lt;- gather(df.cumret, &amp;#39;Investor&amp;#39;, &amp;quot;Value&amp;quot;, -ref.month )

p &amp;lt;- ggplot(df.to.plot, aes(x = ref.month, y = Value, color = Investor)) + 
 geom_line(size =2) + 
 labs(x = &amp;#39;Time&amp;#39;, 
      y = &amp;#39;Value of Return&amp;#39;,
      title = &amp;#39;Accumulated Value of Portfolio&amp;#39;,
      subtitle = &amp;#39;This figure shows the value of accumulated return for Bettina in comparison to GodBot, a perfect predictor of stock markets&amp;#39;) + 
 scale_y_continuous(labels = format.cash)

p&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2019-03-23-Bettina-Case_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The results show that Bettina’s returns are possible. All you need to do is to perfectly predict, for each month, which stock will do best in the market. If you haven’t sensed my irony, let me be crystal clear: &lt;strong&gt;Market prices are impossible to predict&lt;/strong&gt;. The result I just showed you is only possible in my computer. No one will ever be able to replicate it in practice.&lt;/p&gt;
&lt;p&gt;The ad from &lt;em&gt;Empiricus&lt;/em&gt; is very misleading. In my opinion as a finance professor, the real problem in this episode is that the great majority of the Brazilian population is not financially educated. Many people &lt;strong&gt;will believe&lt;/strong&gt; that is legally possible to reach a 20% return over a month.&lt;/p&gt;
&lt;p&gt;I’ve seen countless cases of financial pyramids, usually tied to some exotic cryptocurrency, to rise and shortly burn here in Brazil. This is specially – and sadly – most frequent in the poorer areas of the country. Those that follow &lt;em&gt;Empiricus&lt;/em&gt; advice will soon learn its lesson. Making money in short run in stocks is very difficult.&lt;/p&gt;
&lt;p&gt;Unfortunately, every disapointed person that followed &lt;em&gt;Empiricus&lt;/em&gt; advice is never going back to investing in financial markets. They will miss what is probably the greatest system ever designed for investing and passively creating wealth in the long run.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>(2/2) Book promotion (paperback edition) - &#34;Processing and Analyzing Financial Data with R&#34;</title>
      <link>https://www.msperlin.com/post/2019-03-10-pafdr-promotion_2/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2019-03-10-pafdr-promotion_2/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I received many messages regarding my &lt;a href=&#34;https://www.amazon.com/dp/B071DTSCPS&#34;&gt;book promotion&lt;/a&gt; (see &lt;a href=&#34;https://www.msperlin.com/post/2019-03-09-pafdr-promotion/&#34;&gt;previous post&lt;/a&gt; ). I’ll use this post to answer the most frequent questions:&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Does the paperback edition have a discount?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;No. The price drop is only valid for the &lt;strong&gt;ebook edition&lt;/strong&gt; but not by choice. Unfortunately, Amazon does not let me do &lt;em&gt;countdown promotions&lt;/em&gt; for the &lt;strong&gt;paperback edition&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;So, in favor of those, like myself, that like the smell of a fresh book page, I manually dropped the price of the paperback to 17.99 USD (it was 24.99 USD). Printings costs are heavy, which is why I can’t go all the way to a 50% discount. The system tells me that the new price should be live within the next 72 hours. I’ll keep the new price until the end of this week.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;em&gt;When will the second edition be released?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;My schedule is to start to work on the new edition of &lt;em&gt;Processing and Analyzing..&lt;/em&gt; on june 2019. Hopefully I can publish it before january 2020. Sorry but I can’t give much detail about the new content yet. But be sure I’ll keep you guys posted.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;Best.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Book promotion - &#34;Processing and Analyzing Financial Data with R&#34;</title>
      <link>https://www.msperlin.com/post/2019-03-09-pafdr-promotion/</link>
      <pubDate>Sat, 09 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2019-03-09-pafdr-promotion/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/img/CAPADigital_FinancialDataR.jpg&#34; style=&#34;width:30.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I recently did a book promotion for my &lt;a href=&#34;https://www.amazon.com.br/dp/B07DN4M357&#34;&gt;R book in portuguese&lt;/a&gt; and it was a big sucess!&lt;/p&gt;
&lt;p&gt;My english book is now being sold with the same promotion. You can purchase it with a 50% discount if you buy it on the 10th day of march. See it &lt;a href=&#34;https://www.amazon.com/dp/B071DTSCPS&#34;&gt;here&lt;/a&gt;. The discount will be valid throughout the week, with daily price increases.&lt;/p&gt;
&lt;p&gt;If you want to learn more about R and its use in Finance and Economics, this book is a great opportunity.&lt;/p&gt;
&lt;p&gt;You can find more details about the book, including datasets, R code and all that good stuff &lt;a href=&#34;https://www.msperlin.com/publication/2017_book-pafdr-en/&#34;&gt;here&lt;/a&gt;. An online and public version with the first 7 chapters is available in this &lt;a href=&#34;https://www.msperlin.com/pafdR/&#34;&gt;link&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you liked the work (or not), please provide a honest review at Amazon.com. As an author, I certainly apreciate it and will use the feedback for the next edition of the book.&lt;/p&gt;
&lt;p&gt;Best,&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GetDFPData Ver 1.4</title>
      <link>https://www.msperlin.com/post/2019-01-12-getdfpdata-ver14/</link>
      <pubDate>Sat, 12 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2019-01-12-getdfpdata-ver14/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I just released a major update to package GetDFPData. Here are the main changes:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Naming conventions for caching system are improved so that it reflects different versions of FRE and DFP files&lt;/strong&gt;. This means the old caching system no longer works. If you have built yourself your own cache folder with many companies, do clean up the cache by deleting all folders. Run your code again and it will rebuild all files. Unfortinatelly this is a “brute force”, but necessary step. The code and data is now explicit about the version of downloaded files. If a company updates its FRE files, for example, the package will detect it and download and read the new information.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fixed issue with dates in FRE&lt;/strong&gt;. Many people reported that the dates from the FRE tables did not match the ones in the website. The reason is that the FRE column “ref.date” was set as (year.fre -1)-12-31. This made sense for many of the FRE tables, but not all. The idea was to use column ref.date to bind the DFP and FRE datasets together. In order to be more transparent about this choice, a new column “year.fre” is added to all FRE data. It contains the original year of the FRE file. This way the user will always know where the FRE datasets are coming from.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Many improvements&lt;/strong&gt;. Bugs were chased and fixed. The code is now more mantainable and runs with more smoothly.&lt;/p&gt;
&lt;p&gt;The new version is already available at github and should be in CRAN in a few days.&lt;/p&gt;
&lt;p&gt;The datasets from the &lt;a href=&#34;https://www.msperlin.com/shiny/GetDFPData/&#34;&gt;shinny version&lt;/a&gt; are also updated with this new dataset.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Looking back at 2018 and plans for 2019</title>
      <link>https://www.msperlin.com/post/2019-01-08-looking-back-2018/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2019-01-08-looking-back-2018/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;At the end of every year I plan to write about the highlight of the current year and set plans for the future. First, let’s talk about my work in 2018.&lt;/p&gt;
&lt;div id=&#34;highlights-of-2018&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Highlights of 2018&lt;/h1&gt;
&lt;p&gt;Research wise, my scientometrics paper &lt;a href=&#34;https://www.msperlin.com/publication/2018_scientometrics-predatory/&#34;&gt;Is predatory publishing a real threat? Evidence from a large database study&lt;/a&gt; was featured in many &lt;a href=&#34;https://www.msperlin.com/research/on-the-news/&#34;&gt;news outlets&lt;/a&gt;. Its &lt;a href=&#34;https://springeropen.altmetric.com/details/38773966&#34;&gt;altmetric page&lt;/a&gt; is doing great, with over 1100 downloads and featured at top 5% of &lt;strong&gt;all&lt;/strong&gt; research output measured by altmetric. This is, by far, the most impactful research piece I ever wrote. Its rewarding to see my work featured in the local and international media.&lt;/p&gt;
&lt;p&gt;This year I also released the first version of &lt;a href=&#34;https://www.msperlin.com/post/2017-12-06-package-getdfpdata/&#34;&gt;GetDFPData&lt;/a&gt;, a R package for accessing a large database of financial information from B3, the Brazilian exchange. I’m glad to report that many people are using it for their own research. I can see the number of visits in the web interface and the frequent emails I get about the package. The feedback from other researchers has been great but, off course, there are always ways to improve the code. I’ve been constantly developing it over time.&lt;/p&gt;
&lt;p&gt;The GetDFPData package also had an impact in my own research. I’ve always been biased towards the topic of capital markets and now I’m doing research in corporate finance, mostly due to the new access to a large database of corporate events. Currently, I have three paper initiatives in analyzing the effect of boards formation towards financial performance of Brazilian companies. These will likely probably be published in 2019 or 2020.&lt;/p&gt;
&lt;p&gt;In late 2018 I started my YouTube series &lt;a href=&#34;https://www.youtube.com/watch?v=CFd8O4f5bm4&amp;amp;list=PLO0YoYcxF6WFR1i45IRTnJ7-Xosrsx-Hl&#34;&gt;padfeR&lt;/a&gt;, with video tutorials about using R for Finance and Economics. The idea is to have a greater impact and help those that are starting to use R. So far, all videos are in Portuguese but I do have plans for doing it in english in the future. Hopefully I’ll find some time in 2019 to start it.&lt;/p&gt;
&lt;p&gt;Overall, 2018 was a great year. I’m always thankful for having the opportunity of working in a job that I love and look forward to work (almost) every single day.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;my-blog-posts-in-2018&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;My blog posts in 2018&lt;/h1&gt;
&lt;p&gt;In november I changed the technology behind my blog from &lt;a href=&#34;https://www.msperlin.com/post/2018-11-03-new&#34;&gt;Jekyll to Hugo&lt;/a&gt;. Can’t stress enough how much I’m liking the Academic template built with blogdown and hosted in my own server. It is far easier to write posts and maintain the website.&lt;/p&gt;
&lt;p&gt;First, let’s see how many posts I have so far.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my.blog.folder &amp;lt;- &amp;#39;~/Dropbox/11-My Website/01-msperlin.com/content/post/&amp;#39;
post.files &amp;lt;- list.files(path = my.blog.folder, pattern = &amp;#39;.Rmd&amp;#39;)

post.files&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   [1] &amp;quot;2017-02-16-Writing-a-book.Rmd&amp;quot;                           
##   [2] &amp;quot;2017-02-16-Writing-a-book.Rmd.lock~&amp;quot;                     
##   [3] &amp;quot;2017-12-06-Package-GetDFPData.Rmd&amp;quot;                       
##   [4] &amp;quot;2017-12-06-Package-GetDFPData.Rmd.lock~&amp;quot;                 
##   [5] &amp;quot;2017-12-13-Serving-shiny-apps-internet.Rmd&amp;quot;              
##   [6] &amp;quot;2017-12-13-Serving-shiny-apps-internet.Rmd.lock~&amp;quot;        
##   [7] &amp;quot;2017-12-30-Looking-Back-2017.Rmd&amp;quot;                        
##   [8] &amp;quot;2017-12-30-Looking-Back-2017.Rmd.lock~&amp;quot;                  
##   [9] &amp;quot;2018-01-22-Update-BatchGetSymbols.Rmd&amp;quot;                   
##  [10] &amp;quot;2018-01-22-Update-BatchGetSymbols.Rmd.lock~&amp;quot;             
##  [11] &amp;quot;2018-03-16-Writing_Papers_About_Pkgs.Rmd&amp;quot;                
##  [12] &amp;quot;2018-03-16-Writing_Papers_About_Pkgs.Rmd.lock~&amp;quot;          
##  [13] &amp;quot;2018-04-22-predatory-scientometrics.Rmd&amp;quot;                 
##  [14] &amp;quot;2018-04-22-predatory-scientometrics.Rmd.lock~&amp;quot;           
##  [15] &amp;quot;2018-05-12-Investing-Long-Run.Rmd&amp;quot;                       
##  [16] &amp;quot;2018-05-12-Investing-Long-Run.Rmd.lock~&amp;quot;                 
##  [17] &amp;quot;2018-06-12-padfR-ed2.Rmd&amp;quot;                                
##  [18] &amp;quot;2018-06-12-padfR-ed2.Rmd.lock~&amp;quot;                          
##  [19] &amp;quot;2018-06-29-BenchmarkingSSD.Rmd&amp;quot;                          
##  [20] &amp;quot;2018-06-29-BenchmarkingSSD.Rmd.lock~&amp;quot;                    
##  [21] &amp;quot;2018-10-10-BatchGetSymbols-NewVersion.Rmd&amp;quot;               
##  [22] &amp;quot;2018-10-10-BatchGetSymbols-NewVersion.Rmd.lock~&amp;quot;         
##  [23] &amp;quot;2018-10-11-Update-GetLattesData.Rmd&amp;quot;                     
##  [24] &amp;quot;2018-10-11-Update-GetLattesData.Rmd.lock~&amp;quot;               
##  [25] &amp;quot;2018-10-13-NewPackage-PkgsFromFiles.Rmd&amp;quot;                 
##  [26] &amp;quot;2018-10-13-NewPackage-PkgsFromFiles.Rmd.lock~&amp;quot;           
##  [27] &amp;quot;2018-10-19-R-and-loops.Rmd&amp;quot;                              
##  [28] &amp;quot;2018-10-19-R-and-loops.Rmd.lock~&amp;quot;                        
##  [29] &amp;quot;2018-10-20-Linux-and-R.Rmd&amp;quot;                              
##  [30] &amp;quot;2018-10-20-Linux-and-R.Rmd.lock~&amp;quot;                        
##  [31] &amp;quot;2018-11-03-NewBlog.Rmd&amp;quot;                                  
##  [32] &amp;quot;2018-11-03-NewBlog.Rmd.lock~&amp;quot;                            
##  [33] &amp;quot;2018-11-03-RstudioTricks.Rmd&amp;quot;                            
##  [34] &amp;quot;2018-11-03-RstudioTricks.Rmd.lock~&amp;quot;                      
##  [35] &amp;quot;2019-01-08-Looking-Back-2018.Rmd&amp;quot;                        
##  [36] &amp;quot;2019-01-08-Looking-Back-2018.Rmd.lock~&amp;quot;                  
##  [37] &amp;quot;2019-01-12-GetDFPData-ver14.Rmd&amp;quot;                         
##  [38] &amp;quot;2019-01-12-GetDFPData-ver14.Rmd.lock~&amp;quot;                   
##  [39] &amp;quot;2019-03-09-pafdR-promotion.Rmd&amp;quot;                          
##  [40] &amp;quot;2019-03-09-pafdR-promotion.Rmd.lock~&amp;quot;                    
##  [41] &amp;quot;2019-03-10-pafdR-promotion_2.Rmd&amp;quot;                        
##  [42] &amp;quot;2019-03-10-pafdR-promotion_2.Rmd.lock~&amp;quot;                  
##  [43] &amp;quot;2019-03-23-Bettina-Case.Rmd&amp;quot;                             
##  [44] &amp;quot;2019-03-23-Bettina-Case.Rmd.lock~&amp;quot;                       
##  [45] &amp;quot;2019-04-13-Parallel-BatchGetsymbols.Rmd&amp;quot;                 
##  [46] &amp;quot;2019-04-13-Parallel-BatchGetsymbols.Rmd.lock~&amp;quot;           
##  [47] &amp;quot;2019-04-15-GetBCBData.Rmd&amp;quot;                               
##  [48] &amp;quot;2019-04-15-GetBCBData.Rmd.lock~&amp;quot;                         
##  [49] &amp;quot;2019-05-01-MeanVariance.Rmd&amp;quot;                             
##  [50] &amp;quot;2019-05-01-MeanVariance.Rmd.lock~&amp;quot;                       
##  [51] &amp;quot;2019-05-17-R-in-Brazil.Rmd&amp;quot;                              
##  [52] &amp;quot;2019-05-17-R-in-Brazil.Rmd.lock~&amp;quot;                        
##  [53] &amp;quot;2019-05-20-Lindy-Effect.Rmd&amp;quot;                             
##  [54] &amp;quot;2019-05-20-Lindy-Effect.Rmd.lock~&amp;quot;                       
##  [55] &amp;quot;2019-07-01-ftp-shutdown.Rmd&amp;quot;                             
##  [56] &amp;quot;2019-07-01-ftp-shutdown.Rmd.lock~&amp;quot;                       
##  [57] &amp;quot;2019-08-08-ftp-NOT-shutdown.Rmd&amp;quot;                         
##  [58] &amp;quot;2019-08-08-ftp-NOT-shutdown.Rmd.lock~&amp;quot;                   
##  [59] &amp;quot;2019-10-01-new-package-GetQuandlData.Rmd&amp;quot;                
##  [60] &amp;quot;2019-10-01-new-package-GetQuandlData.Rmd.lock~&amp;quot;          
##  [61] &amp;quot;2019-10-12-support-GetDFPData-shiny.Rmd&amp;quot;                 
##  [62] &amp;quot;2019-10-12-support-GetDFPData-shiny.Rmd.lock~&amp;quot;           
##  [63] &amp;quot;2019-10-16-new-package-GetEdgarData.Rmd&amp;quot;                 
##  [64] &amp;quot;2019-10-16-new-package-GetEdgarData.Rmd.lock~&amp;quot;           
##  [65] &amp;quot;2019-11-01-new-package-simfinR.Rmd&amp;quot;                      
##  [66] &amp;quot;2019-11-01-new-package-simfinR.Rmd.lock~&amp;quot;                
##  [67] &amp;quot;2019-11-25-feedback-TOC-afedR.Rmd&amp;quot;                       
##  [68] &amp;quot;2019-11-25-feedback-TOC-afedR.Rmd.lock~&amp;quot;                 
##  [69] &amp;quot;2019-12-02-dynamic-exercises-afedR.Rmd&amp;quot;                  
##  [70] &amp;quot;2019-12-02-dynamic-exercises-afedR.Rmd.lock~&amp;quot;            
##  [71] &amp;quot;2019-12-15-Looking-Back-2019.Rmd&amp;quot;                        
##  [72] &amp;quot;2019-12-15-Looking-Back-2019.Rmd.lock~&amp;quot;                  
##  [73] &amp;quot;2020-01-15-afedR-ed2-announcement.Rmd&amp;quot;                   
##  [74] &amp;quot;2020-01-15-afedR-ed2-announcement.Rmd.lock~&amp;quot;             
##  [75] &amp;quot;2020-02-25-afedR-ed2-slides-available.Rmd&amp;quot;               
##  [76] &amp;quot;2020-02-25-afedR-ed2-slides-available.Rmd.lock~&amp;quot;         
##  [77] &amp;quot;2020-03-29-garch-tutorial-in-r.Rmd&amp;quot;                      
##  [78] &amp;quot;2020-03-29-garch-tutorial-in-r.Rmd.lock~&amp;quot;                
##  [79] &amp;quot;2020-04-17-update-getdfpdata.Rmd&amp;quot;                        
##  [80] &amp;quot;2020-04-17-update-getdfpdata.Rmd.lock~&amp;quot;                  
##  [81] &amp;quot;2020-04-20-free-compiled-data-in-site.Rmd&amp;quot;               
##  [82] &amp;quot;2020-04-20-free-compiled-data-in-site.Rmd.lock~&amp;quot;         
##  [83] &amp;quot;2020-04-20-new-package-GetCVMData.Rmd&amp;quot;                   
##  [84] &amp;quot;2020-04-20-new-package-GetCVMData.Rmd.lock~&amp;quot;             
##  [85] &amp;quot;2020-04-25-investments-costs.Rmd&amp;quot;                        
##  [86] &amp;quot;2020-04-25-investments-costs.Rmd.lock~&amp;quot;                  
##  [87] &amp;quot;2020-05-24-pirf-is-online.Rmd&amp;quot;                           
##  [88] &amp;quot;2020-05-24-pirf-is-online.Rmd.lock~&amp;quot;                     
##  [89] &amp;quot;2020-05-27-call-for-papers-rac.Rmd&amp;quot;                      
##  [90] &amp;quot;2020-05-27-call-for-papers-rac.Rmd.lock~&amp;quot;                
##  [91] &amp;quot;2020-07-07-garch-tutorial-in-r-REVISED.Rmd&amp;quot;              
##  [92] &amp;quot;2020-07-07-garch-tutorial-in-r-REVISED.Rmd.lock~&amp;quot;        
##  [93] &amp;quot;2020-07-18-new_packages-GetFREData-GetDFPData2.Rmd&amp;quot;      
##  [94] &amp;quot;2020-07-18-new_packages-GetFREData-GetDFPData2.Rmd.lock~&amp;quot;
##  [95] &amp;quot;2020-12-22-Looking-Back-2020.Rmd&amp;quot;                        
##  [96] &amp;quot;2020-12-22-Looking-Back-2020.Rmd.lock~&amp;quot;                  
##  [97] &amp;quot;2021-02-18-dynamic-exercises-adfeR.Rmd&amp;quot;                  
##  [98] &amp;quot;2021-02-18-dynamic-exercises-adfeR.Rmd.lock~&amp;quot;            
##  [99] &amp;quot;2021-02-19-dynamic-exercises-adfeR.Rmd.lock~&amp;quot;            
## [100] &amp;quot;2021-02-20-adfeR-ed3-announcement.Rmd&amp;quot;                   
## [101] &amp;quot;2021-02-20-adfeR-ed3-announcement.Rmd.lock~&amp;quot;             
## [102] &amp;quot;2021-02-28-dynamic-exercises-afedR.Rmd&amp;quot;                  
## [103] &amp;quot;2021-02-28-dynamic-exercises-afedR.Rmd.lock~&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The blog started in january 2017 and, over time, I wrote 103 posts. That feels alright. I’m not felling forced to write and I do it whenever I fell like I have something to share.&lt;/p&gt;
&lt;p&gt;Let’s get more information from the .Rmd files. I’ll write function &lt;code&gt;read_blog_files&lt;/code&gt; and use it for all post files.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;read_blog_files &amp;lt;- function(f.in) {
  require(tidyverse)
  my.front.matter &amp;lt;- rmarkdown::yaml_front_matter(f.in)

  df.out &amp;lt;- data_frame(post.title = my.front.matter$title,
                       post.date = lubridate::ymd(my.front.matter$date),
                       post.month = as.Date(format(post.date, &amp;#39;%Y-%m-01&amp;#39;)),
                       tags = paste0(my.front.matter$tags, collapse = &amp;#39;;&amp;#39;),
                       categories = paste0(my.front.matter$categories, collapse = &amp;#39;;&amp;#39;),
                       content = paste0(read_lines(f.in), collapse = &amp;#39; &amp;#39;))

  return(df.out)
}

df.posts &amp;lt;- dplyr::bind_rows(purrr::map(post.files, read_blog_files))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: tidyverse&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✔ ggplot2 3.3.3     ✔ purrr   0.3.4
## ✔ tibble  3.1.0     ✔ dplyr   1.0.4
## ✔ tidyr   1.1.2     ✔ stringr 1.4.0
## ✔ readr   1.4.0     ✔ forcats 0.5.1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `data_frame()` was deprecated in tibble 1.1.0.
## Please use `tibble()` instead.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(df.posts)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 51
## Columns: 6
## $ post.title &amp;lt;chr&amp;gt; &amp;quot;Writing a R book and self-publishing it in Amazon&amp;quot;, &amp;quot;Packa…
## $ post.date  &amp;lt;date&amp;gt; 2017-02-16, 2017-12-06, 2017-12-13, 2017-12-30, 2018-01-22…
## $ post.month &amp;lt;date&amp;gt; 2017-02-01, 2017-12-01, 2017-12-01, 2017-12-01, 2018-01-01…
## $ tags       &amp;lt;chr&amp;gt; &amp;quot;R;book;self-publish&amp;quot;, &amp;quot;R;GetDFPData;corporate events;finan…
## $ categories &amp;lt;chr&amp;gt; &amp;quot;R;book;self-publish&amp;quot;, &amp;quot;R;GetDFPData;B3&amp;quot;, &amp;quot;R;shiny;webserve…
## $ content    &amp;lt;chr&amp;gt; &amp;quot;--- title: \&amp;quot;Writing a R book and self-publishing it in Am…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, we’ll look at the frequency of posts over time.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df.posts.2018 &amp;lt;- df.posts %&amp;gt;%
  filter(post.date &amp;gt; as.Date(&amp;#39;2018-01-01&amp;#39;))

print( ggplot(df.posts.2018, aes(x = post.month)) + geom_histogram(stat=&amp;#39;count&amp;#39;) +
         theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
         labs(y = &amp;#39;Number of posts&amp;#39;, x = &amp;#39;&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Ignoring unknown parameters: binwidth, bins, pad&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2019-01-08-Looking-Back-2018_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Seems to average about once a month. The blank spaces show that I did not write for a couple of months.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;checking-2018s-plans&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Checking 2018’s plans&lt;/h1&gt;
&lt;p&gt;In the end of 2017 my plans for 2018 &lt;a href=&#34;https://www.msperlin.com/post/2017-12-30-looking-back-2017/&#34;&gt;were&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Work on the second edition of the &lt;a href=&#34;https://sites.google.com/view/r-financas/&#34;&gt;portuguese book&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Done! I’m glad to report that the second edition of the book was &lt;a href=&#34;https://www.msperlin.com/post/2018-06-12-padfr-ed2/&#34;&gt;published in June 2018&lt;/a&gt;. It was great to review the book and add several new chapters and sections. As I mentioned in the publication post, this is the largest and longest project I ever worked and it is very satisfying to see it develop over time. Even more satisfying is to receive positive feedback of readers that are reading and using the book to learn to code in R! Many teachers in Economics and Business are also starting to use it in the classroom.&lt;/p&gt;
&lt;p&gt;The book will continue to be update every couple of years. One of the greatest things about R, among many others, is that the language is continually evolving and changing. I have no doubt that there will always be new material to write about.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Start a portal for financial data in Brazil&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Unfortunately this project did not launch. I wrote a couple of R scripts for fetching and saving data automatically in my server but it never became a webpage. I started to work on other projects and the website was not a priority.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;plans-for-2019&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Plans for 2019&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;New edition of “Processing and Analyzing Financial Data with R”&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The international version of my book &lt;a href=&#34;https://www.msperlin.com/publication/2017_book-pafdr-en/&#34;&gt;pafdR&lt;/a&gt; was published in january 2017. I fell its time to update it with the new chapters and structure from the second edition in portuguese. There are many improvements to the book, with an emphasis in the tidyverse universe.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Work on my new book: “Investing For the Long Term” (provisory title)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There is a huge deficit of financial knowledge in Brazil, specially in saving and investing. I’ve been a long term investor for most of my career as an academic and I fell there is a lot I can contribute to the topic of financial education by bringing data science into the problem of investing.&lt;/p&gt;
&lt;p&gt;The book will be a introduction to investments for the common person in Brazil, with a heavy data-based approach. It will not be about trading strategies or anything related to short term trading. The idea is to bring data analysis for the common long term investor, showing how the financial market works and how one can build passive income by constantly buying &lt;em&gt;good&lt;/em&gt; financial contracts.&lt;/p&gt;
&lt;p&gt;I have no clue if it will be published em 2019. Unlike my previous book, I’m taking my time to write this one. No rush and no deadlines :).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Solidify my research agenda in Board Composition&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As I mentioned before, my research agenda has shifted from capital markets to board compositions. This is a very interesting topic with many implications for listed companies. I’m leaning a lot from researching into these topics.&lt;/p&gt;
&lt;p&gt;Currently, I have four initiatives with different co-authors:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Gender and board composition&lt;/li&gt;
&lt;li&gt;Politics and board composition&lt;/li&gt;
&lt;li&gt;Professors in the Board of Companies&lt;/li&gt;
&lt;li&gt;Board description of Brazilian Companies&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hoepfully, these will be published in 2019 or 2020.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>New blog site: From Jekyll to Hugo</title>
      <link>https://www.msperlin.com/post/2018-11-03-newblog/</link>
      <pubDate>Sat, 03 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2018-11-03-newblog/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I while ago I &lt;a href=&#34;https://www.msperlin.com/post/2017-12-13-serving-shiny-apps-internet/&#34;&gt;wrote about purchasing my own webserver in digital ocean and hosting my shinny applications&lt;/a&gt;. Last week I finally got some time to migrate my blog from &lt;a href=&#34;https://msperlin.github.io/&#34;&gt;Github&lt;/a&gt; to my new domain, &lt;a href=&#34;https://www.msperlin.com&#34;&gt;www.msperlin.com&lt;/a&gt;. While doing that, I also decided to change the technology behind making the blog, from Jekyll to Hugo. Here are my reasons.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://jekyllrb.com/&#34;&gt;Jekyll&lt;/a&gt; is great for making simple static sites, specially with this &lt;a href=&#34;https://deanattali.com/beautiful-jekyll/&#34;&gt;template&lt;/a&gt; from Dean Attali. It was easy to set it up and host it in &lt;a href=&#34;https://msperlin.github.io/&#34;&gt;Github&lt;/a&gt;. My problems with this configuration are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;With Jekyll, all posts in the blog are created as .md files and not as original .Rmd. For every post with R code I had to compile the .Rmd file to .md and manually add figures and other files to the site directory. In Hugo, and using blogdown, I can compile it directly from Rmarkdown (.Rmd).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The Jekyll template in msperlin.github.io is very clean and simple. This is exactly what I needed at the time. Hugo’s template &lt;a href=&#34;https://sourcethemes.com/academic/&#34;&gt;academic&lt;/a&gt; is specially made for academics and offers lots of new functionalities.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The github internet address doesn’t fell very profissional. I know this can personal opinion but a custom url tells me that the author has spend some time and money to set its webpage properly.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;There is a lag between writing changes in files and seeing it live in msperlin.github.io. This can get annoying. With my own domain, all changes are instantaneous.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hosting the static website in www.msperlin.com is very easy. I wrote a simple bash script that compiles the site locally using &lt;code&gt;blogdown::build_site()&lt;/code&gt; and copy all files to my server with ssh. Going further, I also added documentation about my CRAN packages using &lt;code&gt;pkgdown&lt;/code&gt;. See an example for PkgsFromFiles &lt;a href=&#34;https://www.msperlin.com/docs/PkgsFromFiles/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I am very pleased with this setup and I hope that I won’t need to change it in the next couple of years. The transition is a lot of work! I had to recompile all Rmd posts and copy and paste all other textual content.&lt;/p&gt;
&lt;p&gt;If you are a teacher or researcher, you &lt;strong&gt;really&lt;/strong&gt; should look into &lt;a href=&#34;https://sourcethemes.com/academic/&#34;&gt;Hugo-Academic&lt;/a&gt;. This is specially true if you use R, as you can integrate you Rmd files with blogdown.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Some Useful Tricks in RStudio</title>
      <link>https://www.msperlin.com/post/2018-11-03-rstudiotricks/</link>
      <pubDate>Sat, 03 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2018-11-03-rstudiotricks/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I’ve been using Rstudio for a long time and I got some tricks to share. These are simple and useful commands and shortcuts that really help the productivity of my students. If you got a suggestion of trick, use the comment section and I’ll add it in this post.&lt;/p&gt;
&lt;div id=&#34;package-rstudioapi&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Package &lt;code&gt;rstudioapi&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;When using Rstudio, package &lt;code&gt;rstudioapi&lt;/code&gt; gives you lots of information about your session. The most useful one is the script location. You can use it to automatically change the working folder to where you have the file locally saved.&lt;/p&gt;
&lt;p&gt;Function &lt;code&gt;rstudioapi::getActiveDocumentContext&lt;/code&gt; gives you details about the file being currently edited in RStudio. Have a look:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my.d &amp;lt;- rstudioapi::getActiveDocumentContext()
print(my.d)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Document Context: 
## - id:        &amp;#39;FA202F79&amp;#39;
## - path:      &amp;#39;~/Dropbox/11-My Website/www.msperlin.com-content/post/2018-11-03-RstudioTricks.Rmd&amp;#39;
## - contents:  &amp;lt;69 rows&amp;gt;
## Document Selection:
## - [24, 6] -- [24, 6]: &amp;#39;&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can see that the file location is available in &lt;code&gt;path&lt;/code&gt;. Let’s grab it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my.file.location &amp;lt;- rstudioapi::getActiveDocumentContext()$path&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, if we want the name of the directory, just call &lt;code&gt;dirname(my.file.location)&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my.dir &amp;lt;- dirname(my.file.location)
print(my.dir)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;/home/msperlin/Dropbox/11-My Website/www.msperlin.com-content/post&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, if you want to change the working directory automatically to where the script is locally saved, just write:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my.dir &amp;lt;- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(my.dir)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is very practical and I use it in all of my R scripts. If you copy the script to another folder, it will run without any directory problem. If you send the script to someone else within a zipped folder, he/she can run it without modifications as the working directory will change automatically.&lt;/p&gt;
&lt;p&gt;Be aware, however, this &lt;strong&gt;only works in RStudio&lt;/strong&gt;. If you run the code without the IDE, in a bash script for example, package &lt;code&gt;rstudioapi&lt;/code&gt; will not be available. In this case, you’ll need to set the directory explicitly.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;dark-theme-for-rstudio&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Dark theme for Rstudio&lt;/h2&gt;
&lt;p&gt;A dark theme is a productivity life-changer if you spend a lot of time in front of a computer. Before I used it, my eyes were always strained after a long period of work. By the end of the day, using tablets or even my phone was disconforting. You can change the theme in Rstudio by going into “tools” -&amp;gt; “global options” -&amp;gt; “appearance”. There are many dark themes available. Pick one that pleases you the most. See the difference between a white and dark theme next:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/img/rstudio-whitetheme.png&#34; /&gt; &lt;img src=&#34;https://www.msperlin.com/img/rstudio-darktheme.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Going further, I also advise to change the theme of you operating system. I can assure you that, in the long run, it is worth it!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;autocomplete-tab-is-your-friend&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Autocomplete (tab) is your friend!&lt;/h2&gt;
&lt;p&gt;A commom misconception about programming is that you must memorize lot of names. This is far from the truth. You never need to memorize anything when using Rstudio! From function arguments to variable names and names of files, everything can be searched by pressing the &lt;em&gt;tab&lt;/em&gt; key on your keyboard. When using naming conventions for functions and objects, this becomes even more useful. For example, every dataframe in my code starts with “df”, like in “df.prices”, “df.tickers” and so on. When I’m looking for the name of a dataframe, I just write “df.” and press &lt;em&gt;tab&lt;/em&gt;. The result is a list of object names.&lt;/p&gt;
&lt;p&gt;The autocomplete function also works for function arguments, directory and file locations and packages. In my book I have a whole section about it. &lt;a href=&#34;https://www.msperlin.com/pafdR/basicoperations.html#using-code-completion-with-tab&#34;&gt;Check it out&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://www.msperlin.com/img/autocomplete_arquivos.png&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Autocomplete for files&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://www.msperlin.com/img/autocomplete_pacotes.png&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Autocomplete for packages&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;section-naming-with-----&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Section naming with &lt;code&gt;----&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;You can name a section in any R script in Rstudio using the textual clue &lt;code&gt;----&lt;/code&gt;. This section will show up in the bottom left of the RStudio editor screen. When you want to jump to that section, just press the key. So, you can organized your code with sections like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Get data ----

## code here

# clean data ----

## code here

# report results ----

## code here&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Loops and Pizzas</title>
      <link>https://www.msperlin.com/post/2018-10-19-r-and-loops/</link>
      <pubDate>Fri, 19 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2018-10-19-r-and-loops/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;loops-in-r&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Loops in R&lt;/h1&gt;
&lt;p&gt;First, if you are new to programming, you should know that loops are a way to tell the computer that you want to repeat some operation for a number of times. This is a very common task that can be found in many programming languages. For example, let’s say you invited five friends for dinner at your home and the whole cost of four pizzas will be split evenly. Assume now that you &lt;strong&gt;must&lt;/strong&gt; give instructions to a computer on calculating how much each one will pay at the end of dinner. For that, you need to sum up the individual tabs and divide by the number of people. Your instructions to the computer could be: &lt;em&gt;start with a value of x = zero, take each individual pizza cost and sum it to x until all costs are processed, dividing the result by the number of friends at the end&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The great thing about &lt;em&gt;loops&lt;/em&gt; is that the length of it is dynamically set. Using the previous example, if we had 500 friends (and a large dinner table!), we could use the same instructions for calculating the individual tabs. That means we can encapsulate a generic procedure for processing any given number of friends at dinner. With it, you have at your reach a tool for the execution of any sequential process. In other words, you are the boss of your computer and, as long as you can write it down clearly, you can set it to do any kind of repeated task for you.&lt;/p&gt;
&lt;p&gt;Now, about the code, we could write the solution to the &lt;em&gt;pizza problem&lt;/em&gt; in R as:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pizza.costs &amp;lt;- c(50, 80, 30, 60) # each cost of pizza
n.friends &amp;lt;- 5 # number of friends

x &amp;lt;- 0 # set first cost to zero
for (i.cost in pizza.costs) {
  x &amp;lt;- x + i.cost # sum it up
}

x &amp;lt;- x/n.friends # divide for average per friend
print(x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 44&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Don’t worry if you didn’t understand the code. We’ll get to the structure of a loop soon.&lt;/p&gt;
&lt;p&gt;Back to our case, each friend would pay 44 for the meal. We can check the result against function &lt;code&gt;sum&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x == sum(pizza.costs)/n.friends&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output &lt;code&gt;TRUE&lt;/code&gt; shows that the results are equal.&lt;/p&gt;
&lt;div id=&#34;the-structure-of-a-loop&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Structure of a Loop&lt;/h2&gt;
&lt;p&gt;Knowing how to use loops can be a powerful ally in a complex data related problem. Let’s talk more about how &lt;em&gt;loops&lt;/em&gt; are defined in R. The structure of a &lt;em&gt;loop&lt;/em&gt; in R follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;for (i in i.vec){
  ...
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the previous code, command &lt;code&gt;for&lt;/code&gt; indicates the beginning of a &lt;em&gt;loop&lt;/em&gt;. Object &lt;code&gt;i&lt;/code&gt; in &lt;code&gt;(i in i.vec)&lt;/code&gt; is the iterator of the &lt;em&gt;loop&lt;/em&gt;. This iterator will change its value in each iteration, taking each individual value contained in &lt;code&gt;i.vec&lt;/code&gt;. Note the &lt;em&gt;loop&lt;/em&gt; is encapsulated by curly braces (&lt;code&gt;{}&lt;/code&gt;). These are important, as they define where the &lt;em&gt;loop&lt;/em&gt; starts and where it ends. The indentation (use of bigger margins) is also important for visual cues, but not necessary. Consider the following practical example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set seq
my.seq &amp;lt;- seq(-5,5)

# do loop
for (i in my.seq){
  cat(paste(&amp;#39;\nThe value of i is&amp;#39;,i))
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## The value of i is -5
## The value of i is -4
## The value of i is -3
## The value of i is -2
## The value of i is -1
## The value of i is 0
## The value of i is 1
## The value of i is 2
## The value of i is 3
## The value of i is 4
## The value of i is 5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the code, we created a sequence from -5 to 5 and presented a text for each element with the &lt;code&gt;cat&lt;/code&gt; function. Notice how we also broke the prompt line with &lt;code&gt;&#39;\n&#39;&lt;/code&gt;. The &lt;em&gt;loop&lt;/em&gt; starts with &lt;code&gt;i=-5&lt;/code&gt;, execute command &lt;code&gt;cat(paste(&#39;\nThe value of i is&#39;, -5))&lt;/code&gt;, proceed to the next iteration by setting &lt;code&gt;i=-4&lt;/code&gt;, rerun the &lt;code&gt;cat&lt;/code&gt; command, and so on. At its final iteration, the value of &lt;code&gt;i&lt;/code&gt; is &lt;code&gt;5&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The iterated sequence in the &lt;em&gt;loop&lt;/em&gt; is not exclusive to numerical vectors. Any type of vector or list may be used. See next:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set char vec
my.char.vec &amp;lt;- letters[1:5]

# loop it!
for (i.char in my.char.vec){
  cat(paste(&amp;#39;\nThe value of i.char is&amp;#39;, i.char))
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## The value of i.char is a
## The value of i.char is b
## The value of i.char is c
## The value of i.char is d
## The value of i.char is e&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The same goes for &lt;code&gt;lists&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set list
my.l &amp;lt;- list(x = 1:5, 
             y = c(&amp;#39;abc&amp;#39;,&amp;#39;dfg&amp;#39;), 
             z = factor(&amp;#39;A&amp;#39;,&amp;#39;B&amp;#39;,&amp;#39;C&amp;#39;,&amp;#39;D&amp;#39;))

# loop list
for (i.l in my.l){
  
  cat(paste0(&amp;#39;\nThe class of i.l is &amp;#39;, class(i.l), &amp;#39;. &amp;#39;))
  cat(paste0(&amp;#39;The number of elements is &amp;#39;, length(i.l), &amp;#39;.&amp;#39;))
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## The class of i.l is integer. The number of elements is 5.
## The class of i.l is character. The number of elements is 2.
## The class of i.l is factor. The number of elements is 1.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the definition of &lt;em&gt;loops&lt;/em&gt;, the iterator does not have to be the only object incremented in each iteration. We can create other objects and increment them using a simple sum operation. See next:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set vec and iterators
my.vec &amp;lt;- seq(1:5)
my.x &amp;lt;- 5
my.z &amp;lt;- 10

for (i in my.vec){
  # iterate &amp;quot;manually&amp;quot;
  my.x &amp;lt;- my.x + 1
  my.z &amp;lt;- my.z + 2
  
  cat(&amp;#39;\nValue of i = &amp;#39;, i, 
      &amp;#39; | Value of my.x = &amp;#39;, my.x, 
      &amp;#39; | Value of my.z = &amp;#39;, my.z)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Value of i =  1  | Value of my.x =  6  | Value of my.z =  12
## Value of i =  2  | Value of my.x =  7  | Value of my.z =  14
## Value of i =  3  | Value of my.x =  8  | Value of my.z =  16
## Value of i =  4  | Value of my.x =  9  | Value of my.z =  18
## Value of i =  5  | Value of my.x =  10  | Value of my.z =  20&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using nested &lt;em&gt;loops&lt;/em&gt;, that is, a &lt;em&gt;loop&lt;/em&gt; inside of another &lt;em&gt;loop&lt;/em&gt; is also possible. See the following example, where we present all the elements of a matrix:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set matrix
my.mat &amp;lt;- matrix(1:9, nrow = 3)

# loop all values of matrix
for (i in seq(1,nrow(my.mat))){
  for (j in seq(1,ncol(my.mat))){
    cat(paste0(&amp;#39;\nElement [&amp;#39;, i, &amp;#39;, &amp;#39;, j, &amp;#39;] = &amp;#39;, my.mat[i,j]))
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Element [1, 1] = 1
## Element [1, 2] = 4
## Element [1, 3] = 7
## Element [2, 1] = 2
## Element [2, 2] = 5
## Element [2, 3] = 8
## Element [3, 1] = 3
## Element [3, 2] = 6
## Element [3, 3] = 9&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;a-real-world-example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A Real World Example&lt;/h2&gt;
&lt;p&gt;Now, the computational needs of the real world is far more complex than dividing a dinner expense. A practical example of using &lt;em&gt;loops&lt;/em&gt; is processing data according to groups. Using an example from Finance, if we have a return dataset for several stocks and we want to calculate the average return of each stock, we can use a &lt;em&gt;loop&lt;/em&gt; for that. In this example, we will use &lt;em&gt;Yahoo Finance&lt;/em&gt; data from three stocks: FB, GE and AA. The first step is downloading it with package &lt;code&gt;BatchGetSymbols&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(BatchGetSymbols)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: rvest&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: xml2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: dplyr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;dplyr&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:stats&amp;#39;:
## 
##     filter, lag&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:base&amp;#39;:
## 
##     intersect, setdiff, setequal, union&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my.tickers &amp;lt;-  c(&amp;#39;FB&amp;#39;, &amp;#39;GE&amp;#39;, &amp;#39;AA&amp;#39;)

df.stocks &amp;lt;- BatchGetSymbols(tickers = my.tickers, 
                             first.date = &amp;#39;2012-01-01&amp;#39;, 
                             freq.data = &amp;#39;yearly&amp;#39;)[[2]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Running BatchGetSymbols for:&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##    tickers =FB, GE, AA
##    Downloading data for benchmark ticker
## ^GSPC | yahoo (1|1) | Found cache file
## FB | yahoo (1|3) | Not Cached | Saving cache - Got 95% of valid prices | Nice!
## GE | yahoo (2|3) | Not Cached | Saving cache - Got 100% of valid prices | Good job!
## AA | yahoo (3|3) | Not Cached | Saving cache - Got 100% of valid prices | Good job!&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It worked fine. Let’s check the contents of the dataframe:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dplyr::glimpse(df.stocks)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 27
## Columns: 10
## $ ticker              &amp;lt;chr&amp;gt; &amp;quot;AA&amp;quot;, &amp;quot;AA&amp;quot;, &amp;quot;AA&amp;quot;, &amp;quot;AA&amp;quot;, &amp;quot;AA&amp;quot;, &amp;quot;AA&amp;quot;, &amp;quot;AA&amp;quot;, &amp;quot;AA&amp;quot;, &amp;quot;…
## $ ref.date            &amp;lt;date&amp;gt; 2012-01-03, 2013-01-02, 2014-01-02, 2015-01-02, …
## $ volume              &amp;lt;dbl&amp;gt; 2217410500, 2149575500, 2146821400, 2683551700, 2…
## $ price.open          &amp;lt;dbl&amp;gt; 21.482821, 21.338640, 25.303591, 38.135609, 22.87…
## $ price.high          &amp;lt;dbl&amp;gt; 25.85628, 25.68807, 42.29280, 41.01921, 32.05000,…
## $ price.low           &amp;lt;dbl&amp;gt; 19.272060, 18.503099, 24.270300, 18.791460, 16.19…
## $ price.close         &amp;lt;dbl&amp;gt; 22.179689, 21.602970, 25.303591, 38.159641, 23.33…
## $ price.adjusted      &amp;lt;dbl&amp;gt; 20.893423, 20.621868, 24.485683, 37.242069, 23.00…
## $ ret.adjusted.prices &amp;lt;dbl&amp;gt; NA, -0.01299715, 0.18736494, 0.52097326, -0.38221…
## $ ret.closing.prices  &amp;lt;dbl&amp;gt; NA, -0.02600212, 0.17130149, 0.50807215, -0.38853…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All financial data is there. Notice that the return series is available at column ret.adjusted.prices.&lt;/p&gt;
&lt;p&gt;Now we will use a loop to build a table with the mean return of each stock:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# find unique tickers in column ticker
unique.tickers &amp;lt;- unique(df.stocks$ticker)

# create empty df
tab.out &amp;lt;- data.frame()

# loop tickers
for (i.ticker in unique.tickers){
  
  # create temp df with ticker i.ticker
  temp &amp;lt;- df.stocks[df.stocks$ticker==i.ticker, ]
  
  # row bind i.ticker and mean.ret
  tab.out &amp;lt;- rbind(tab.out, 
                   data.frame(ticker = i.ticker,
                              mean.ret = mean(temp$ret.adjusted.prices, na.rm = TRUE)))
  
}

# print result
print(tab.out)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   ticker   mean.ret
## 1     AA 0.09646911
## 2     FB 0.30161873
## 3     GE 0.05304138&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the code, we used function &lt;code&gt;unique&lt;/code&gt; to find out the names of all the tickers in the dataset. Soon after, we create an empty &lt;em&gt;dataframe&lt;/em&gt; to save the results and a loop to filter the data of each stock sequentially and average its returns. At the end of the &lt;em&gt;loop&lt;/em&gt;, we use function &lt;code&gt;rbind&lt;/code&gt; to paste the results of each stock with the results of the main table. As you can see, we can use the data to perform group calculations with &lt;em&gt;loop&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;By now, I must be forward in saying that the previous loop is by no means the best way of performing the data operation. What we just did by loops is called a &lt;em&gt;split-apply-combine&lt;/em&gt; procedure. There are base function in R such as &lt;code&gt;tapply&lt;/code&gt;, &lt;code&gt;split&lt;/code&gt; and &lt;code&gt;lapply&lt;/code&gt;/&lt;code&gt;sapply&lt;/code&gt; that can do the same job but with a more intuitive and functional approach. Going further, functions from package &lt;code&gt;tidyverse&lt;/code&gt; can do the same procuedure with an even more intuitive approach. In a future post I shall discuss this possibilities further.&lt;/p&gt;
&lt;p&gt;I hope you guys liked the post. Got a question? Just drop it at the comment section.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>New package in CRAN: PkgsFromFiles</title>
      <link>https://www.msperlin.com/post/2018-10-13-newpackage-pkgsfromfiles/</link>
      <pubDate>Sat, 13 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2018-10-13-newpackage-pkgsfromfiles/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Its been a while since I develop a CRAN package and this weekend I decided
to work on a idea I had some time ago. The result is package
&lt;code&gt;PkgsFromFiles&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;When working with different computers at home or work, one of the
problems I have is installing missing packages across different
computers. As an example, a script that works in my &lt;strong&gt;work computer&lt;/strong&gt; may
not work in my &lt;strong&gt;home computer&lt;/strong&gt;. This is specially annoying when I have a
fresh install of the operating system or R. In this case, I must
manually install all packages, case by case. Instead of focusing on the
script at hand, I spend considerable time finding and installing missing
packages. When using laptops for teaching R, many times I had to wait
for the installation of a package before continuing the class. With my
new package, PkgsFromFiles, I can scan any folder of my computer and
install all necessary packages &lt;strong&gt;before&lt;/strong&gt; using them, as we will soon
learn.&lt;/p&gt;
&lt;p&gt;One of the available solutions to this problem is to use package
&lt;a href=&#34;https://CRAN.R-project.org/package=pacman&#34;&gt;pacman&lt;/a&gt;. It includes
function &lt;code&gt;p_load&lt;/code&gt; that will check if a package is available and, if not,
install it from CRAN. However, for me, I like using &lt;code&gt;library&lt;/code&gt; and
&lt;code&gt;require&lt;/code&gt; as it is consistent with my code format. Also, in a fresh R
install, I rather install all my required packages in a single run so
that I don’t have to wait later.&lt;/p&gt;
&lt;p&gt;Package PkgsFromFiles solves this issue by finding and parsing all R
related files (.R, .Rmd, .Rnw) from a given folder. It finds all calls
to library() and require() and installs all packages that are not
available locally.&lt;/p&gt;
&lt;div id=&#34;installation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Installation&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# from cran (soon!)
install.packages(&amp;#39;PkgsFromFiles&amp;#39;)

# from github
if (!require(devtools)) install.packages(&amp;#39;devtools&amp;#39;)
devtools::install_github(&amp;#39;msperlin/PkgsFromFiles&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;usage&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Usage&lt;/h1&gt;
&lt;p&gt;The main function of the package is &lt;code&gt;pff_find_and_install_pkgs&lt;/code&gt;, which will search and install missing packages from R files at a given directory. As an example, we’ll use my research folder from Dropbox. It contains all R scripts I have ever used in my research work. Let’s try it out:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Evaluation is disable so it passes CRAN CHECKS, but you should be able to run it in your computer
library(PkgsFromFiles)

# target folder
my.dir &amp;lt;- &amp;#39;~/Dropbox/01-Pesquisa/&amp;#39;

df &amp;lt;- pff_find_and_install_pkgs(folder.in = my.dir)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Searching folder  ~/Dropbox/01-Pesquisa/
##  Found 74 files in 18 folders
##       R Scripts: 72 files
##       Rmarkdown files: 2 files
##       Sweave files: 0 files&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `data_frame()` is deprecated as of tibble 1.1.0.
## Please use `tibble()` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Checking available pkgs from https://cloud.r-project.org
## Checking and installing missing pkgs
## Installing rvest Already installed
## Installing tidyverse Already installed
## Installing furrr Already installed
## Installing XML   Already installed
## Installing fst   Already installed
## Installing stringr   Already installed
## Installing lubridate Already installed
## Installing ggplot2   Already installed
## Installing GetDFPData    Already installed
## Installing genderBR  Already installed
## Installing purrr Already installed
## Installing xlsx  Already installed
## Installing sandwich  Already installed
## Installing stargazer Already installed
## Installing Hmisc Already installed
## Installing plm   Already installed
## Installing lmtest    Already installed
## Installing MatchIt   Already installed
## Installing devtools  Already installed
## Installing RSelenium Already installed
## Installing GetLattesData Already installed
## Installing xtable    Already installed
## Installing httr  Already installed
## Installing parallel  Installation failed, pkg not in CRAN
## Installing BatchGetSymbols   Already installed
## Installing readxl    Already installed
## Installing RSQLite   Already installed
## Installing pbapply   Already installed
## Installing ggmap Already installed
## Installing memoise   Already installed
## Installing gganimate Already installed
## Installing texreg    Already installed
## Installing pglm  Already installed
## Installing estimatr  Already installed
## Installing AER   Already installed
## Installing quantreg  Already installed
## Installing nnet  Already installed
## Installing simfinR   Already installed
## Installing fGarch    Already installed
## Installing MTS   Already installed
## Installing DescTools Already installed
## 
## Summary:
##  Found 40 packages already installed
##  Had to install 0 packages
##  Installation failed for 1 packages
##      1 due to package not being found in CRAN
##      0 due to missing dependencies or other problems
## 
## Check output dataframe for more details about failed packages&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, function &lt;code&gt;pff_find_and_install_pkgs&lt;/code&gt; will find all R related files recursively in the given folder. In this case, I have all packages locally so no installation was required. A summary in text is shown at the end of execution.&lt;/p&gt;
&lt;p&gt;The output of the function is a dataframe with the details of the operation. Have a look:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dplyr::glimpse(df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 41
## Columns: 3
## $ pkg            &amp;lt;chr&amp;gt; &amp;quot;rvest&amp;quot;, &amp;quot;tidyverse&amp;quot;, &amp;quot;furrr&amp;quot;, &amp;quot;XML&amp;quot;, &amp;quot;fst&amp;quot;, &amp;quot;stringr&amp;quot;…
## $ status.message &amp;lt;chr&amp;gt; &amp;quot;Already installed&amp;quot;, &amp;quot;Already installed&amp;quot;, &amp;quot;Already ins…
## $ installation   &amp;lt;lgl&amp;gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, …&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The package also includes function &lt;code&gt;pff_find_R_files_from_folder&lt;/code&gt;, which will find all packages used in R related files from a given folder. It outputs a dataframe with several information about packages used in the found scripts.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df.files &amp;lt;- pff_find_R_files_from_folder(folder.in = my.dir)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Searching folder  ~/Dropbox/01-Pesquisa/
##  Found 74 files in 18 folders
##       R Scripts: 72 files
##       Rmarkdown files: 2 files
##       Sweave files: 0 files&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dplyr::glimpse(df.files)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 74
## Columns: 5
## $ files      &amp;lt;chr&amp;gt; &amp;quot;/home/msperlin/Dropbox/01-Pesquisa//01-Working Papers/01-…
## $ file.names &amp;lt;chr&amp;gt; &amp;quot;01-01_S-unzip_affiliation_tables.R&amp;quot;, &amp;quot;01-02_S-read_affili…
## $ extensions &amp;lt;chr&amp;gt; &amp;quot;R&amp;quot;, &amp;quot;R&amp;quot;, &amp;quot;R&amp;quot;, &amp;quot;R&amp;quot;, &amp;quot;R&amp;quot;, &amp;quot;R&amp;quot;, &amp;quot;R&amp;quot;, &amp;quot;R&amp;quot;, &amp;quot;R&amp;quot;, &amp;quot;R&amp;quot;, &amp;quot;R&amp;quot;, &amp;quot;R&amp;quot;…
## $ pkgs       &amp;lt;chr&amp;gt; &amp;quot;rvest ; tidyverse ; furrr ; XML&amp;quot;, &amp;quot;tidyverse ; furrr ; fs…
## $ n.pkgs     &amp;lt;int&amp;gt; 4, 3, 8, 6, 6, 6, 8, 8, 8, 1, 1, 8, 8, 8, 4, 1, 7, 9, 4, 8…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I also wrote a simple function for plotting the most used packages for a given folder:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# target folder
my.dir &amp;lt;- &amp;#39;~/Dropbox/01-Pesquisa/&amp;#39;

# plot most used pkgs
p &amp;lt;- pff_plot_summary_pkgs(folder.in = my.dir)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Searching folder  ~/Dropbox/01-Pesquisa/
##  Found 74 files in 18 folders
##       R Scripts: 72 files
##       Rmarkdown files: 2 files
##       Sweave files: 0 files&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2018-10-13-NewPackage-PkgsFromFiles_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As you can see, I’m a big fan of the &lt;code&gt;tidyverse&lt;/code&gt;!&lt;/p&gt;
&lt;p&gt;Hope you guys find the package useful! Fell free to send any question to the comment section of the post or my email (&lt;a href=&#34;mailto:marceloperlin@gmail.com&#34; class=&#34;email&#34;&gt;marceloperlin@gmail.com&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Update to GetLattesData</title>
      <link>https://www.msperlin.com/post/2018-10-11-update-getlattesdata/</link>
      <pubDate>Thu, 11 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2018-10-11-update-getlattesdata/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Last year I released &lt;code&gt;GetLattesData&lt;/code&gt;. This package is very handy for anyone that researches bibliometric data of Brazilian scholars. You could easily import the whole academic history of any researcher registered at the platform. More details about Lattes and &lt;code&gt;GetLattesData&lt;/code&gt; in the this &lt;a href=&#34;https://msperlin.github.io/2017-09-04-Package-GetLattesData/&#34;&gt;post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;However, a couple months ago CNPQ introduced a captcha in the webpage. This made it impossible to download the xml files directly, breaking my code. It seems that those changes are now permanent. The update to GetLattesData will address this issue by asking the user to download the files manually and input its location to function &lt;code&gt;gld_get_lattes_data_from_zip&lt;/code&gt;. Unfortunately, one can no longer download the files automatically.&lt;/p&gt;
&lt;p&gt;Next I provide an example of usage from the vignette:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(GetLattesData)

# get files from pkg (you can download from other researchers in lattes website)
f.in &amp;lt;- c(system.file(&amp;#39;extdata/3262699324398819.zip&amp;#39;, package = &amp;#39;GetLattesData&amp;#39;),
          system.file(&amp;#39;extdata/8373564643000623.zip&amp;#39;, package = &amp;#39;GetLattesData&amp;#39;))

# set qualis
field.qualis = &amp;#39;ADMINISTRAÇÃO PÚBLICA E DE EMPRESAS, CIÊNCIAS CONTÁBEIS E TURISMO&amp;#39;

# get data
l.out &amp;lt;- gld_get_lattes_data_from_zip(f.in, 
                                      field.qualis = field.qualis )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Reading  3262699324398819.zip -  Marcelo Scherer Perlin
##  Found 21 published papers
##  Found 2 accepted paper(s)
##  Found 10 supervisions
##  Found 2 published books
##  Found 0 book chapters
##  Found 17 conference papers
## Reading  8373564643000623.zip -  Denis Borenstein
##  Found 75 published papers
##  Found 2 accepted paper(s)
##  Found 97 supervisions
##  Found 1 published books
##  Found 6 book chapters
##  Found 89 conference papers&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output &lt;code&gt;my.l&lt;/code&gt; is a list with the following dataframes:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;names(l.out)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;tpesq&amp;quot;             &amp;quot;tpublic.published&amp;quot; &amp;quot;tpublic.accepted&amp;quot; 
## [4] &amp;quot;tsupervisions&amp;quot;     &amp;quot;tbooks&amp;quot;            &amp;quot;tconferences&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first is a dataframe with information about researchers:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tpesq &amp;lt;- l.out$tpesq
str(tpesq)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## tibble [2 × 16] (S3: tbl_df/tbl/data.frame)
##  $ name           : chr [1:2] &amp;quot;Marcelo Scherer Perlin&amp;quot; &amp;quot;Denis Borenstein&amp;quot;
##  $ last.update    : Date[1:2], format: &amp;quot;2018-09-24&amp;quot; &amp;quot;2018-08-24&amp;quot;
##  $ bsc.institution: chr [1:2] &amp;quot;Universidade Federal de Santa Maria&amp;quot; &amp;quot;Universidade Federal do Rio de Janeiro&amp;quot;
##  $ bsc.start.year : chr [1:2] &amp;quot;2001&amp;quot; &amp;quot;1981&amp;quot;
##  $ bsc.end.year   : chr [1:2] &amp;quot;2005&amp;quot; &amp;quot;1986&amp;quot;
##  $ bsc.course     : chr [1:2] &amp;quot;Administração de empresas&amp;quot; &amp;quot;Engenharia Naval&amp;quot;
##  $ msc.institution: chr [1:2] &amp;quot;Universidade Federal do Rio Grande do Sul&amp;quot; &amp;quot;Universidade Federal do Rio Grande do Sul&amp;quot;
##  $ msc.start.year : chr [1:2] &amp;quot;2005&amp;quot; &amp;quot;1989&amp;quot;
##  $ msc.end.year   : chr [1:2] &amp;quot;2007&amp;quot; &amp;quot;1991&amp;quot;
##  $ phd.institution: chr [1:2] &amp;quot;University of Reading&amp;quot; &amp;quot;University of Strathclyde&amp;quot;
##  $ phd.start.year : num [1:2] 2007 1991
##  $ phd.end.year   : num [1:2] 2010 1995
##  $ country.origin : chr [1:2] &amp;quot;Brasil&amp;quot; &amp;quot;Brasil&amp;quot;
##  $ major.field    : chr [1:2] &amp;quot;CIENCIAS_SOCIAIS_APLICADAS&amp;quot; &amp;quot;ENGENHARIAS&amp;quot;
##  $ minor.field    : chr [1:2] &amp;quot;Administração&amp;quot; &amp;quot;Engenharia de Produção&amp;quot;
##  $ id.file        : chr [1:2] &amp;quot;3262699324398819.zip&amp;quot; &amp;quot;8373564643000623.zip&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The second dataframe contains information about all published publications, including Qualis and SJR:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dplyr::glimpse(l.out$tpublic.published)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 96
## Columns: 13
## $ id.file            &amp;lt;chr&amp;gt; &amp;quot;3262699324398819.zip&amp;quot;, &amp;quot;3262699324398819.zip&amp;quot;, &amp;quot;3…
## $ name               &amp;lt;chr&amp;gt; &amp;quot;Marcelo Scherer Perlin&amp;quot;, &amp;quot;Marcelo Scherer Perlin&amp;quot;…
## $ article.title      &amp;lt;chr&amp;gt; &amp;quot;Teoria do Caos aplicada aos Contratos de Café no …
## $ year               &amp;lt;dbl&amp;gt; 2006, 2009, 2007, 2011, 2013, 2013, 2013, 2013, 20…
## $ language           &amp;lt;chr&amp;gt; &amp;quot;Português&amp;quot;, &amp;quot;Inglês&amp;quot;, &amp;quot;Inglês&amp;quot;, &amp;quot;Inglês&amp;quot;, &amp;quot;Portug…
## $ journal.title      &amp;lt;chr&amp;gt; &amp;quot;READ - Revista Eletrônica da Administração (UFRGS…
## $ contry.publication &amp;lt;chr&amp;gt; &amp;quot;Brasil&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, …
## $ ISSN               &amp;lt;chr&amp;gt; &amp;quot;-&amp;quot;, &amp;quot;1753-9641&amp;quot;, &amp;quot;1413-2311&amp;quot;, &amp;quot;1749-9135&amp;quot;, &amp;quot;1679-…
## $ order.aut          &amp;lt;dbl&amp;gt; 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 1, 3, 1, 3,…
## $ n.authors          &amp;lt;dbl&amp;gt; 2, 1, 2, 2, 1, 3, 3, 3, 2, 2, 3, 2, 4, 5, 3, 2, 5,…
## $ qualis             &amp;lt;chr&amp;gt; NA, NA, &amp;quot;B1&amp;quot;, NA, &amp;quot;B1&amp;quot;, &amp;quot;A2&amp;quot;, &amp;quot;B1&amp;quot;, &amp;quot;A1&amp;quot;, &amp;quot;B1&amp;quot;, &amp;quot;B…
## $ SJR                &amp;lt;dbl&amp;gt; NA, 0.213, NA, NA, NA, 0.886, NA, 0.429, NA, NA, N…
## $ H.SJR              &amp;lt;int&amp;gt; NA, 6, NA, NA, NA, 17, NA, 38, NA, NA, NA, NA, 45,…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Other dataframes in &lt;code&gt;l.out&lt;/code&gt; included information about accepted papers, supervisions, books and conferences.&lt;/p&gt;
&lt;div id=&#34;an-application-of-getlattesdata&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;An application of &lt;code&gt;GetLattesData&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;GetLattesData&lt;/code&gt; makes it easy to create academic reports for a large number of researchers. See next, where I plot the number of publications for each researcher, conditioning on Qualis ranking.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tpublic.published &amp;lt;- l.out$tpublic.published

library(ggplot2)

p &amp;lt;- ggplot(tpublic.published, aes(x = qualis)) +
  geom_bar(position = &amp;#39;identity&amp;#39;) + facet_wrap(~name) +
  labs(x = paste0(&amp;#39;Qualis: &amp;#39;, field.qualis))
print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2018-10-11-Update-GetLattesData_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can also use &lt;code&gt;dplyr&lt;/code&gt; to do some simple assessment of academic productivity:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;dplyr&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:stats&amp;#39;:
## 
##     filter, lag&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:base&amp;#39;:
## 
##     intersect, setdiff, setequal, union&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my.tab &amp;lt;- tpublic.published %&amp;gt;%
  group_by(name) %&amp;gt;%
  summarise(n.papers = n(),
            max.SJR = max(SJR, na.rm = T),
            mean.SJR = mean(SJR, na.rm = T),
            n.A1.qualis = sum(qualis == &amp;#39;A1&amp;#39;, na.rm = T),
            n.A2.qualis = sum(qualis == &amp;#39;A2&amp;#39;, na.rm = T),
            median.authorship = median(as.numeric(order.aut), na.rm = T ))

knitr::kable(my.tab)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;name&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n.papers&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;max.SJR&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mean.SJR&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n.A1.qualis&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n.A2.qualis&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;median.authorship&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Denis Borenstein&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;75&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.674&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.2808113&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;27&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Marcelo Scherer Perlin&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;21&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.029&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7204444&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>BatchGetSymbols 2.2</title>
      <link>https://www.msperlin.com/post/2018-10-10-batchgetsymbols-newversion/</link>
      <pubDate>Wed, 10 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2018-10-10-batchgetsymbols-newversion/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;One of the main requests I get for package &lt;code&gt;BatchGetSymbols&lt;/code&gt; is to add the choice of frequency of the financial dataset. Today I finally got some time to work on it. I just posted a new version of BatchGetSymbols in CRAN. The major change is that users can now set the time frequency of the financial data: dailly, weekly, monthly or yearly. Let’s check it out:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(BatchGetSymbols)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: rvest&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: xml2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: dplyr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;dplyr&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:stats&amp;#39;:
## 
##     filter, lag&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:base&amp;#39;:
## 
##     intersect, setdiff, setequal, union&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(purrr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;purrr&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &amp;#39;package:rvest&amp;#39;:
## 
##     pluck&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

my.fct &amp;lt;- function(my.freq) {
  
  df &amp;lt;- BatchGetSymbols(tickers = c(&amp;#39;GE&amp;#39;), 
                      first.date = &amp;#39;2010-01-01&amp;#39;,
                      last.date = Sys.Date(), do.cache = FALSE,
                      freq.data = my.freq)$df.tickers
  
  df$freq &amp;lt;- my.freq

  return(df)
}

my.possible.freq &amp;lt;-  c(&amp;#39;daily&amp;#39;, &amp;#39;weekly&amp;#39;, &amp;#39;monthly&amp;#39;, &amp;#39;yearly&amp;#39;)

df.allfreq &amp;lt;- bind_rows(map(.x = my.possible.freq, .f = my.fct))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Running BatchGetSymbols for:&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##    tickers =GE
##    Downloading data for benchmark ticker
## ^GSPC | yahoo (1|1)
## GE | yahoo (1|1) - Got 100% of valid prices | Good job!
## Running BatchGetSymbols for:
##    tickers =GE
##    Downloading data for benchmark ticker
## ^GSPC | yahoo (1|1)
## GE | yahoo (1|1) - Got 100% of valid prices | You got it!
## Running BatchGetSymbols for:
##    tickers =GE
##    Downloading data for benchmark ticker
## ^GSPC | yahoo (1|1)
## GE | yahoo (1|1) - Got 100% of valid prices | Feels good!
## Running BatchGetSymbols for:
##    tickers =GE
##    Downloading data for benchmark ticker
## ^GSPC | yahoo (1|1)
## GE | yahoo (1|1) - Got 100% of valid prices | You got it!&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- ggplot(df.allfreq, aes(x=ref.date, y = price.adjusted)) + 
  geom_point() + geom_line() + facet_grid(freq ~ ticker)

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2018-10-10-BatchGetSymbols-NewVersion_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Benchmarking a SSD drive in reading and writing files with R</title>
      <link>https://www.msperlin.com/post/2018-06-29-benchmarkingssd/</link>
      <pubDate>Fri, 29 Jun 2018 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2018-06-29-benchmarkingssd/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I recently bought a new computer for home and it came with two drives, one HDD and other SSD. The later is used for the OS and the former stores all of my personal files. From all computers I had, both home and work, this is definitely the fastest. While some of the merits are due to the newer CPUS and RAM, the SSD drive can make all the difference in file operations.&lt;/p&gt;
&lt;p&gt;My research usually deals with large files from financial markets. Being efficient in reading those files is key to my productivity. Given that, I was very curious in understanding how much I would benefit in speed when reading/writing files in my SSD drive instead of the HDD. For that, I wrote a simple function that will time a particular operation. The function will take as input the number of rows in the data (1..Inf), the type of function used to save the file (&lt;em&gt;rds&lt;/em&gt;, &lt;em&gt;csv&lt;/em&gt;, &lt;em&gt;fst&lt;/em&gt;) and the type of drive (&lt;em&gt;HDD&lt;/em&gt; or &lt;em&gt;SSD&lt;/em&gt;). See next.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bench.fct &amp;lt;- function(N = 2500000, type.file = &amp;#39;rds&amp;#39;, type.hd = &amp;#39;HDD&amp;#39;) {
  # Function for timing read and write operations
  #
  # INPUT: N - Number of rows in dataframe to be read and write
  #        type.file - format of output file (rds, csv, fst)
  #        type.hd - where to save (hdd or ssd)
  #
  # OUTPUT: A dataframe with results
  require(tidyverse)
  require(fst)
  
  my.df &amp;lt;- data_frame(x = runif(N),
                      char.vec = sample(letters, size = N, 
                                        replace = TRUE))
  
  path.file &amp;lt;- switch(type.hd,
                      &amp;#39;SSD&amp;#39; = &amp;#39;~&amp;#39;,
                      &amp;#39;HDD&amp;#39; = &amp;#39;/mnt/HDD/&amp;#39;)
  
  my.file &amp;lt;- file.path(path.file, 
                       switch (type.file,
                               &amp;#39;rds-base&amp;#39; = &amp;#39;temp_rds.rds&amp;#39;,
                               &amp;#39;rds-readr&amp;#39; = &amp;#39;temp_rds.rds&amp;#39;,
                               &amp;#39;fst&amp;#39; = &amp;#39;temp_fst.fst&amp;#39;,
                               &amp;#39;csv-readr&amp;#39; = &amp;#39;temp_csv.csv&amp;#39;,
                               &amp;#39;csv-base&amp;#39; = &amp;#39;temp_csv.csv&amp;#39;))
  
  if (type.file == &amp;#39;rds-base&amp;#39;) {
    time.write &amp;lt;- system.time(saveRDS(my.df, my.file, compress = FALSE))
    time.read &amp;lt;- system.time(readRDS(my.file))
  } else if (type.file == &amp;#39;rds-readr&amp;#39;) {
    time.write &amp;lt;- system.time(write_rds(x = my.df, path =  my.file, compress = &amp;#39;none&amp;#39;))
    time.read &amp;lt;- system.time(read_rds(path = my.file ))
  } else if (type.file == &amp;#39;fst&amp;#39;) {
    time.write &amp;lt;- system.time(write.fst(x = my.df, path = my.file))
    time.read &amp;lt;- system.time(read_fst(my.file))
  } else if (type.file == &amp;#39;csv-readr&amp;#39;) {
    time.write &amp;lt;- system.time(write_csv(x = my.df, path = my.file))
    time.read &amp;lt;- system.time(read_csv(file = my.file, col_types = cols(x = col_double(),
                                                                       char.vec = col_character())))
  } else if (type.file == &amp;#39;csv-base&amp;#39;) {
    time.write &amp;lt;- system.time(write.csv(x = my.df, file = my.file))
    time.read &amp;lt;- system.time(read.csv(file = my.file))
  }
  
  # clean up
  file.remove(my.file)
  
  # save output
  df.out &amp;lt;- data_frame(type.file = type.file,
                       type.hd = type.hd,
                       N = N,
                       type.time = c(&amp;#39;write&amp;#39;, 
                                     &amp;#39;read&amp;#39;),
                       times = c(time.write[3], 
                                 time.read[3]))
  
  return(df.out)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have my function, its time to use it for all combinations between number of rows, the formats of the file and type of drive:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(purrr)
df.grid &amp;lt;- expand.grid(N = seq(1, 500000, by = 50000), 
                       type.file = c(&amp;#39;rds-readr&amp;#39;, &amp;#39;rds-base&amp;#39;, &amp;#39;fst&amp;#39;, &amp;#39;csv-readr&amp;#39;, &amp;#39;csv-base&amp;#39;), 
                       type.hd = c(&amp;#39;HDD&amp;#39;, &amp;#39;SSD&amp;#39;), stringsAsFactors = F)

l.out &amp;lt;- pmap(list(N = df.grid$N,
               type.file = df.grid$type.file,
               type.hd = df.grid$type.hd), .f = bench.fct)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `data_frame()` is deprecated as of tibble 1.1.0.
## Please use `tibble()` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df.res &amp;lt;- do.call(what = bind_rows, args = l.out)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Lets check the result in a nice plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

p &amp;lt;- ggplot(df.res, aes(x = N, y = times, linetype = type.hd)) + 
  geom_line() + facet_grid(type.file ~ type.time)

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2018-06-29-BenchmarkingSSD_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As you can see, the &lt;code&gt;csv-base&lt;/code&gt; format is messing with the y axis. Let’s remove it for better visualization:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

p &amp;lt;- ggplot(filter(df.res, !(type.file %in% c(&amp;#39;csv-base&amp;#39;))),
            aes(x = N, y = times, linetype = type.hd)) + 
  geom_line() + facet_grid(type.file ~ type.time)

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2018-06-29-BenchmarkingSSD_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;When it comes to the file format, we learn:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;By far, the &lt;code&gt;fst&lt;/code&gt; format is the best&lt;/strong&gt;. It takes less time to read and write than the others. However, it’s probably unfair to compare it to &lt;code&gt;csv&lt;/code&gt; and &lt;code&gt;rds&lt;/code&gt; as it uses the 16 cores of my computer.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;code&gt;readr&lt;/code&gt; is a great package for writing and reading &lt;em&gt;csv&lt;/em&gt; files&lt;/strong&gt;. You can see a large difference of time from using the &lt;code&gt;base&lt;/code&gt; functions. This is likely due to the use of low level functions to write and read the text files.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;When using the &lt;em&gt;rds&lt;/em&gt; format, the base function do not differ much from the &lt;code&gt;readr&lt;/code&gt; functions&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As for the effect of using SSD, its clear that it &lt;strong&gt;DOES NOT&lt;/strong&gt; effect the time of reading and writing. The differences between using HDD and SSD looks like noise. Seeking to provide a more robust analysis, let’s formally test this hypothesis using a simple t-test for the means:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tab &amp;lt;- df.res %&amp;gt;%
  group_by(type.file, type.time) %&amp;gt;%
  summarise(mean.HDD = mean(times[type.hd == &amp;#39;HDD&amp;#39;]),
            mean.SSD = mean(times[type.hd == &amp;#39;SSD&amp;#39;]),
            p.value = t.test(times[type.hd == &amp;#39;SSD&amp;#39;],
                             times[type.hd == &amp;#39;HDD&amp;#39;])$p.value)


print(tab)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 x 5
## # Groups:   type.file [5]
##    type.file type.time mean.HDD mean.SSD p.value
##    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
##  1 csv-base  read        0.381   0.307     0.562
##  2 csv-base  write       0.457   0.453     0.981
##  3 csv-readr read        0.148   0.144     0.922
##  4 csv-readr write       0.0716  0.0732    0.942
##  5 fst       read        0.0108  0.00630   0.343
##  6 fst       write       0.0083  0.00800   0.890
##  7 rds-base  read        0.0362  0.0373    0.921
##  8 rds-base  write       0.0266  0.0278    0.882
##  9 rds-readr read        0.0375  0.0367    0.943
## 10 rds-readr write       0.0278  0.0279    0.991&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see, the null hypothesis of equal means easily fails to be rejected for almost all types of files and operations at 10%. The exception was for the &lt;em&gt;fst&lt;/em&gt; format in a reading operation. In other words, statistically, it does not make any difference in time from using SSD or HDD to read or write files in different formats.&lt;/p&gt;
&lt;p&gt;I am very surprised by this result. Independently of the type of format, I expected a large difference as SSD drives are much faster within an OS. Am I missing something? Is this due to the OS being in the SSD? What you guys think?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Second Edition of &#34;Processamento e Analise de Dados Financeiros e Econômicos com o R&#34;</title>
      <link>https://www.msperlin.com/post/2018-06-12-padfr-ed2/</link>
      <pubDate>Tue, 12 Jun 2018 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2018-06-12-padfr-ed2/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div class=&#34;alert alert-success&#34;&gt;
&lt;p&gt;
IMPORTANT: The third edition of the book was released in 2021 – more details in this &lt;a href=&#34;https://www.msperlin.com/publication/2021_book-adfer-pt/&#34;&gt;link&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;It is with great pleasure that I announce the second edition of the portuguese version of my book, Processing and Analyzing Financial Data with R. This edition updates the material significantly. The portuguese version is now not only in par with the &lt;a href=&#34;https://www.amazon.com/dp/B084LSNXMN&#34;&gt;international version of the book&lt;/a&gt;, but much more!&lt;/p&gt;
&lt;p&gt;Here are the main changes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The structure of chapters changed towards the stages of a research, from obtaining the raw data, cleaning it, manipulating it and, finally, reporting tables and figures.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Many new additions of packages for obtaining data, including my own and from other authors.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Added new chapter for reporting results, exporting tables and also including a whole section about using Rmarkdown.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Alignment with the tidyverse. I have no doubt that the packages from the tidyverse are here to stay. While the native function are presented, there is an emphasis in using the tidyverse, specially in reading local data, manipulating dataframes and functional programming.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Exercises are available at the end of each chapter, including hard questions that will challenge your programming ability.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can find the new edition of the book in &lt;a href=&#34;https://www.amazon.com.br/dp/B08WNC27ZY&#34;&gt;Amazon&lt;/a&gt;. See this &lt;a href=&#34;https://www.msperlin.com/books&#34;&gt;section&lt;/a&gt; for more details. As usual, an online (and free) version of the book is available at &lt;a href=&#34;http://www.msperlin.com/padfeR/&#34;&gt;http://www.msperlin.com/padfeR/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It was a lot of work (and fun) to write the new edition. I’m very happy with the result. I hope you enjoy it!&lt;/p&gt;
&lt;p&gt;Best,&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Investing for the Long Run</title>
      <link>https://www.msperlin.com/post/2018-05-12-investing-long-run/</link>
      <pubDate>Sat, 12 May 2018 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2018-05-12-investing-long-run/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I often get asked about how to invest in the stock market. Not surprisingly, this has been a common topic in my classes. Brazil is experiencing a big change in its financial scenario. Historically, fixed income instruments paid a large premium over the stock market and that is no longer the case. Interest rates are low, without the pressure from inflation. This means a more sustainable scenario for low-interest rates in the future. Without the premium in the fixed income market, people turn to the stock market.&lt;/p&gt;
&lt;p&gt;We can separate investors according to their horizon. Traders try to profit in the short term, usually within a day, and long-term investors buy a stock without the intent to sell it in the near future. This type of investment strategy is called BH (&lt;em&gt;buy and hold&lt;/em&gt;). At the extreme, you buy a stock and hold it forever. The most famous spokesperson of BH is Warren Buffet, among many others.&lt;/p&gt;
&lt;p&gt;Investing in the long run works for me because it doesn’t require much of my time. You just need to keep up with the quarterly and yearly financial reports of companies. You can easily do it as a side activity, parallel to your main job. You don’t need a lot of brain power to do it either, but it does require knowledge of accounting practices to understand all printed material released by companies.&lt;/p&gt;
&lt;p&gt;I read many books before starting to invest and one of the most interesting tables I’ve found portrays the relationship between investment horizon and profitability. The idea is that the more time you hold a stock or index, higher the chance of a profit. The table, originally from Taleb’s &lt;em&gt;Fooled by Randomness&lt;/em&gt;, is as follows.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://imgur.com/a/d5VnMaF&#34; /&gt;&lt;/p&gt;
&lt;p&gt;My problem with the table is that it seems pretty off. My experience tells me that a 67% chance of positive return every month seems exaggerated. If that was the case, making money in the stock market would be easy. Digging deeper, I found out that the data behind the table is simulated and, therefore, doesn’t really give good an estimate about the improvement in the probability of profits as a function of the investment horizon.&lt;/p&gt;
&lt;p&gt;As you probably suspect, I decided to tackle the problem using real data and R. I wrote a simple &lt;a href=&#34;https://www.msperlin.com/content/others/fct_invest_horizon.R&#34;&gt;function&lt;/a&gt; that will grab data, simulate investments of different horizons many times and plot the results. Let’s try it for the SP500 index:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;source(&amp;#39;fct_invest_horizon.R&amp;#39;)

my.ticker &amp;lt;- &amp;#39;^GSPC&amp;#39; # ticker from yahoo finance
max.horizon = 255*50 # 50 years
first.date &amp;lt;- &amp;#39;1950-01-01&amp;#39; 
last.date &amp;lt;- Sys.Date()
n.points &amp;lt;- 50 # number of points in figure 
rf.year &amp;lt;- 0 # risk free return (or inflation)

l.out &amp;lt;- get.figs.invest.horizon(ticker.in = my.ticker, 
                                 first.date = first.date, 
                                 last.date = last.date,
                                 max.horizon = max.horizon, 
                                 n.points = n.points, 
                                 rf.year = rf.year)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `data_frame()` is deprecated as of tibble 1.1.0.
## Please use `tibble()` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(l.out$p1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2018-05-12-Investing-Long-Run_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(l.out$p2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2018-05-12-Investing-Long-Run_files/figure-html/unnamed-chunk-3-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As the investment horizon increases, the chances of a positive return increases. This result suggests that, if you invest for more than 13 years, it is very unlikely that you’ll see a negative return. When looking at the distribution of total returns by the horizon, we find that it increases significantly with time. Someone that invested for 50 years is likely to receive a 2500% return on the investment.&lt;/p&gt;
&lt;p&gt;With input input &lt;code&gt;rf.year&lt;/code&gt; we can also set a desired rate of return. Let’s try it with 5% return per year, with is pretty standard for financial markets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my.ticker &amp;lt;- &amp;#39;^GSPC&amp;#39; # ticker from yahoo finance
max.horizon = 255*50 # 50 years
first.date &amp;lt;- &amp;#39;1950-01-01&amp;#39; 
last.date &amp;lt;- Sys.Date()
n.points &amp;lt;- 50 # number of points in figure 
rf.year &amp;lt;- 0.05 # risk free return (or inflation) - yearly

l.out &amp;lt;- get.figs.invest.horizon(ticker.in = my.ticker, 
                                 first.date = first.date, 
                                 last.date = last.date,
                                 max.horizon = max.horizon, 
                                 n.points = n.points, 
                                 rf.year = rf.year)

print(l.out$p1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2018-05-12-Investing-Long-Run_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As expected, the curve of probabilities has a lower slope, meaning that you need more time investing in the SP500 index to guarantee a return of more than 5% a year.&lt;/p&gt;
&lt;p&gt;Now, let’s try the same setup for Berkshire stock (BRK-A). This is Buffet’s company and looking at its share price we can have a good understanding of how successful Buffet has been as a BH (&lt;em&gt;buy and hold&lt;/em&gt;) investor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my.ticker &amp;lt;- &amp;#39;BRK-A&amp;#39; # ticker from yahoo finance
max.horizon = 255*25 # 50 years
first.date &amp;lt;- &amp;#39;1980-01-01&amp;#39; 
last.date &amp;lt;- Sys.Date()
n.points &amp;lt;- 50 # number of points in figure 
rf.year &amp;lt;- 0.05 # risk free return (or inflation) - yearly

l.out &amp;lt;- get.figs.invest.horizon(ticker.in = my.ticker, 
                                 first.date = first.date, 
                                 last.date = last.date,
                                 max.horizon = max.horizon, 
                                 n.points = n.points, 
                                 rf.year = rf.year)

print(l.out$p1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2018-05-12-Investing-Long-Run_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(l.out$p2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2018-05-12-Investing-Long-Run_files/figure-html/unnamed-chunk-5-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Well, needless to say that, historically, Buffet has done very well in his investments! If you bought the stock and kept it for more 1 year, there is a 70% chance that you got a profit.&lt;/p&gt;
&lt;p&gt;I hope this post convinced you to start investing. The results are clear, its better to start as early as possible.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Predatory Journals and R</title>
      <link>https://www.msperlin.com/post/2018-04-22-predatory-scientometrics/</link>
      <pubDate>Sun, 22 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2018-04-22-predatory-scientometrics/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;My paper about the penetration of predatory journals in Brazil, &lt;strong&gt;Is predatory publishing a real threat? Evidence from a large database study&lt;/strong&gt;, just got &lt;a href=&#34;https://link.springer.com/article/10.1007/s11192-018-2750-6?wt_mc=Internal.Event.1.SEM.ArticleAuthorOnlineFirst&#34;&gt;published in Scientometrics!&lt;/a&gt;. The working paper version is available in &lt;a href=&#34;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3067958&#34;&gt;SSRN&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This is a nice example of a data-intensive scientific work cycle, from gathering data to reporting results. Everything was done in R, using web scrapping algorithms, parallel processing, tidyverse packages and more. This was a special project for me, given its implications in science making in Brazil. It took me nearly one year to produce and execute the whole code. It is also a nice case of the capabilities of package ggplot2 in producing publication-ready figures. As a side output, our database of predatory journals is available as a &lt;a href=&#34;http://www.msperlin.com/shiny/predatory/&#34;&gt;shiny app&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;More details about the study itself is available in the paper. Our abstract is as follows:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Using a database of potential, possible, or probable predatory scholarly open-access journals, the objective of this research is to study the penetration of predatory publications in the Brazilian academic system and the profile of authors in a cross-section empirical study. Based on a massive amount of publications from Brazilian researchers of all disciplines during the 2000–2015 period, we were able to analyze the extent of predatory publications using an econometric modeling. Descriptive statistics indicate that predatory publications represent a small overall proportion, but grew exponentially in the last 5 years. Departing from prior studies, our analysis shows that experienced researchers with a high number of non-indexed publications and PhD obtained locally are more likely to publish in predatory journals. Further analysis shows that once a journal regarded as predatory is listed in the local ranking system, the Qualis, it starts to receive more publications than non-predatory ones.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Writing papers about packages</title>
      <link>https://www.msperlin.com/post/2018-03-16-writing_papers_about_pkgs/</link>
      <pubDate>Fri, 16 Mar 2018 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2018-03-16-writing_papers_about_pkgs/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Back in 2007 I wrote a &lt;a href=&#34;https://github.com/msperlin/MS_Regress-Matlab&#34;&gt;Matlab package&lt;/a&gt; for estimating regime switching models. I was just starting to learn to code and this project was my way of doing it. After publishing it in FEX (Matlab file exchange site), I got so many repeated questions on my email that eventually I realized it would be easier to write a manual for people to read. Some time and effort would be spend writing it, but less time replying to repeated questions on my email.&lt;/p&gt;
&lt;p&gt;This &lt;a href=&#34;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1714016&#34;&gt;manual&lt;/a&gt; about the code became, by far, my most cited paper in &lt;a href=&#34;https://scholar.google.com.br/citations?user=n3LTk-UAAAAJ&amp;amp;hl=en&#34;&gt;Google Scholar&lt;/a&gt;. It is not even published, just a permanent working paper. When attending conferences and seminars, I was always surprised to hear that, at that time, people knew me as the &lt;em&gt;matlab regime switching&lt;/em&gt; guy.&lt;/p&gt;
&lt;p&gt;Moving forward a few years, I stopped using Matlab for R and I continue to invest a lot of time writing papers about packages and publishing them in standard scientific journals. I can testify for a greater contribution and impact for research papers about code. I strongly believe that this format will become more popular in the years to come. The new generation of researchers is far more aware of code than the previous. In that sense, nothing beats R and CRAN at the diversity and depth of packages.&lt;/p&gt;
&lt;p&gt;In this subject, I frequently review papers in the same topic and I see common mistakes that researchers do when writing their papers. Here’s some tips for those that wish to pursue such a type of publication:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;A problem must be clearly stated&lt;/strong&gt;: Every paper is a solution to a problem. This is also true for a paper about code. Identify it and make it painfully clear how the code solves it. Simply put, do your homework.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;The paper is NOT an extended manual&lt;/strong&gt;: Don’t write a paper simply showing its functions. We have that from CRAN or other repository of code.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Make sure you know what’s available&lt;/strong&gt;: How people did it before? Is there a competing package? How does your code improves it?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;A bibliometric study is mandatory&lt;/strong&gt;: Same as the previous point. Looking at the previous published research papers, can you find out how they handled the problem your code solves?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Not everyone uses R, so make it easier for people to use you software&lt;/strong&gt;: Make sure you keep a simple and accessible code. Explain what is R and why you should use it. Case in point, not everyone know what a &lt;em&gt;tibble&lt;/em&gt; is.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Think about your example of usage&lt;/strong&gt;: You should always add a reproducible example of usage. This is what everyone will try! Make sure it is a simple example, not too deep in the literature. Something everyone can understand. Your code should also be accessible and reproducible.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is a lot of work to publish a research paper about code. But, it is all worth it! The impact is much greater than a standard research paper. Your academic career will certainly move forward with it.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Major update to BatchGetSymbols</title>
      <link>https://www.msperlin.com/post/2018-01-22-update-batchgetsymbols/</link>
      <pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2018-01-22-update-batchgetsymbols/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I just released a long due update to package &lt;code&gt;BatchGetSymbols&lt;/code&gt;. The files are under review in CRAN and you should get the update soon. Meanwhile, you can install the new version from Github:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if (!require(devtools)) install.packages(&amp;#39;devtools&amp;#39;)
devtools::install_github(&amp;#39;msperlin/BatchGetSymbols&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The main innovations are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Clever cache system&lt;/strong&gt;: By default, every new download of data will be saved in a local file located in a directory chosen by user. Every new request of data is compared to the available local information. If data is missing, the function only downloads the piece of data that is missing. This make the call to function &lt;code&gt;BatchGetSymbols&lt;/code&gt; a lot faster! When updating an existing dataset of prices, the function only downloads the missing part of the data.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Returns calculation&lt;/strong&gt;: Function now returns a return vector in &lt;code&gt;df.tickers&lt;/code&gt;. Returns are used a lot more than prices in research. No reason why they should be keep out of the output.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Wide format&lt;/strong&gt;: Added function for converting data to the wide format. In some situations, such as portfolio analysis, the wide format makes a lot of sense and is required for some methodologies.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Ibovespa composition&lt;/strong&gt;: Added function for downloading current Ibovespa composition directly from Bovespa website.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the next chunks of code I show some of the innovations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(BatchGetSymbols)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: rvest&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: xml2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: dplyr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;dplyr&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:stats&amp;#39;:
## 
##     filter, lag&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:base&amp;#39;:
## 
##     intersect, setdiff, setequal, union&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# download Ibovespa stocks
my.tickers &amp;lt;- GetSP500Stocks()$Tickers[1:5] # lets keep it light

# set dates
first.date &amp;lt;- &amp;#39;2017-01-01&amp;#39;
last.date &amp;lt;- &amp;#39;2019-01-01&amp;#39;

# set folder for cache system
my.temp.cache.folder &amp;lt;- &amp;#39;BGS_CACHE&amp;#39;

# get data and time it
time.nocache &amp;lt;- system.time({
my.l &amp;lt;- BatchGetSymbols(tickers = my.tickers, first.date, last.date, 
                        cache.folder = my.temp.cache.folder, do.cache = FALSE)
})&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Running BatchGetSymbols for:&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##    tickers =MMM, ABT, ABBV, ABMD, ACN
##    Downloading data for benchmark ticker
## ^GSPC | yahoo (1|1)
## MMM | yahoo (1|5) - Got 100% of valid prices | Well done!
## ABT | yahoo (2|5) - Got 100% of valid prices | Good job!
## ABBV | yahoo (3|5) - Got 100% of valid prices | Youre doing good!
## ABMD | yahoo (4|5) - Got 100% of valid prices | Youre doing good!
## ACN | yahoo (5|5) - Got 100% of valid prices | You got it!&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;time.withcache &amp;lt;- system.time({
my.l &amp;lt;- BatchGetSymbols(tickers = my.tickers, first.date, last.date, 
                        cache.folder = my.temp.cache.folder, do.cache = TRUE)
})&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Running BatchGetSymbols for:
##    tickers =MMM, ABT, ABBV, ABMD, ACN
##    Downloading data for benchmark ticker
## ^GSPC | yahoo (1|1) | Not Cached | Saving cache
## MMM | yahoo (1|5) | Not Cached | Saving cache - Got 100% of valid prices | Looking good!
## ABT | yahoo (2|5) | Not Cached | Saving cache - Got 100% of valid prices | Good stuff!
## ABBV | yahoo (3|5) | Not Cached | Saving cache - Got 100% of valid prices | Got it!
## ABMD | yahoo (4|5) | Not Cached | Saving cache - Got 100% of valid prices | Looking good!
## ACN | yahoo (5|5) | Not Cached | Saving cache - Got 100% of valid prices | Good stuff!&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cat(&amp;#39;\nTime with no cache:&amp;#39;, time.nocache[&amp;#39;elapsed&amp;#39;])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Time with no cache: 4.094&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cat(&amp;#39;\nTime with cache:&amp;#39;, time.withcache[&amp;#39;elapsed&amp;#39;])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Time with cache: 2.386&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s check the default output with data in the long format:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dplyr::glimpse(my.l)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 2
##  $ df.control: tibble [5 × 6] (S3: tbl_df/tbl/data.frame)
##   ..$ ticker              : chr [1:5] &amp;quot;MMM&amp;quot; &amp;quot;ABT&amp;quot; &amp;quot;ABBV&amp;quot; &amp;quot;ABMD&amp;quot; ...
##   ..$ src                 : chr [1:5] &amp;quot;yahoo&amp;quot; &amp;quot;yahoo&amp;quot; &amp;quot;yahoo&amp;quot; &amp;quot;yahoo&amp;quot; ...
##   ..$ download.status     : chr [1:5] &amp;quot;OK&amp;quot; &amp;quot;OK&amp;quot; &amp;quot;OK&amp;quot; &amp;quot;OK&amp;quot; ...
##   ..$ total.obs           : int [1:5] 502 502 502 502 502
##   ..$ perc.benchmark.dates: num [1:5] 1 1 1 1 1
##   ..$ threshold.decision  : chr [1:5] &amp;quot;KEEP&amp;quot; &amp;quot;KEEP&amp;quot; &amp;quot;KEEP&amp;quot; &amp;quot;KEEP&amp;quot; ...
##  $ df.tickers:&amp;#39;data.frame&amp;#39;:  2510 obs. of  10 variables:
##   ..$ price.open         : num [1:2510] 179 178 178 177 178 ...
##   ..$ price.high         : num [1:2510] 180 179 179 179 178 ...
##   ..$ price.low          : num [1:2510] 177 178 177 176 177 ...
##   ..$ price.close        : num [1:2510] 178 178 178 178 177 ...
##   ..$ volume             : num [1:2510] 2509300 1542000 1447800 1625000 1622600 ...
##   ..$ price.adjusted     : num [1:2510] 162 163 162 163 162 ...
##   ..$ ref.date           : Date[1:2510], format: &amp;quot;2017-01-03&amp;quot; &amp;quot;2017-01-04&amp;quot; ...
##   ..$ ticker             : chr [1:2510] &amp;quot;MMM&amp;quot; &amp;quot;MMM&amp;quot; &amp;quot;MMM&amp;quot; &amp;quot;MMM&amp;quot; ...
##   ..$ ret.adjusted.prices: num [1:2510] NA 0.00152 -0.00342 0.00293 -0.00539 ...
##   ..$ ret.closing.prices : num [1:2510] NA 0.00152 -0.00342 0.00293 -0.00539 ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And change the format of the long dataframe to wide:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;l.wide &amp;lt;- reshape.wide(my.l$df.tickers) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we check the matrix of prices:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(head(l.wide$price.adjusted))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     ref.date     ABBV   ABMD      ABT      ACN      MMM
## 1 2017-01-03 52.55166 112.36 36.55642 109.8161 162.4736
## 2 2017-01-04 53.29267 115.74 36.84662 110.0802 162.7200
## 3 2017-01-05 53.69685 114.81 37.16491 108.4300 162.1634
## 4 2017-01-06 53.71369 115.42 38.17595 109.6653 162.6379
## 5 2017-01-09 54.06735 117.11 38.13851 108.4394 161.7619
## 6 2017-01-10 53.94946 112.24 38.65339 108.4960 161.1322&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and matrix of returns:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(head(l.wide$ret.adjusted.prices))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     ref.date          ABBV         ABMD           ABT           ACN
## 1 2017-01-03            NA           NA            NA            NA
## 2 2017-01-04  0.0141005055  0.030081853  0.0079383861  0.0024043005
## 3 2017-01-05  0.0075841391 -0.008035252  0.0086381596 -0.0149906200
## 4 2017-01-06  0.0003136497  0.005313126  0.0272041565  0.0113923084
## 5 2017-01-09  0.0065841132  0.014642203 -0.0009806436 -0.0111779967
## 6 2017-01-10 -0.0021804289 -0.041584860  0.0135001858  0.0005216922
##            MMM
## 1           NA
## 2  0.001516547
## 3 -0.003420851
## 4  0.002926172
## 5 -0.005386333
## 6 -0.003892474&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Looking back in 2017 and plans for 2018</title>
      <link>https://www.msperlin.com/post/2017-12-30-looking-back-2017/</link>
      <pubDate>Sat, 30 Dec 2017 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2017-12-30-looking-back-2017/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;my-blog-in-2017&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;My blog in 2017&lt;/h1&gt;
&lt;p&gt;As we come close to the end of 2017, its time to look back. This has been a great year for me in many ways. This blog started as a way to write short pieces about using R for finance and promote my &lt;a href=&#34;https://sites.google.com/view/pafdR/home&#34;&gt;book&lt;/a&gt; in an organic way. Today, I’m very happy with my decision. Discovering and trying new writing styles keeps my interest very much alive. Academic research is very strict on what you can write and publish. It is satisfying to see that I can promote my work and have an impact in different ways, not only through the publication of academic papers.&lt;/p&gt;
&lt;p&gt;My blog is build using a &lt;a href=&#34;https://deanattali.com/beautiful-jekyll/&#34;&gt;Jekyll template&lt;/a&gt;, meaning the whole site, including individual posts, is built and controlled with editable text files and Github. All files related to posts follow the same structure, meaning I can easily gather the textual data and organize it in a nice &lt;code&gt;tibble&lt;/code&gt;. Let’s first have a look in all post files:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post.folder &amp;lt;- &amp;#39;~/GitRepo/msperlin.github.io/_posts/&amp;#39;

my.f.posts &amp;lt;- list.files(post.folder, full.names = TRUE)
my.f.posts&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## character(0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I posted 0 posts during 2017. Notice how all dates are in the beginning of the file name. I can easily convert that to a &lt;code&gt;Date&lt;/code&gt; object using &lt;code&gt;as.Date&lt;/code&gt;. Let’s organize it all in a nice &lt;code&gt;tibble&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✔ ggplot2 3.3.3     ✔ purrr   0.3.4
## ✔ tibble  3.1.0     ✔ dplyr   1.0.4
## ✔ tidyr   1.1.2     ✔ stringr 1.4.0
## ✔ readr   1.4.0     ✔ forcats 0.5.1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df.posts &amp;lt;- tibble(ref.date = as.Date(basename(my.f.posts)),
                   ref.month = format(ref.date, &amp;#39;%m&amp;#39;), 
                   content = sapply(my.f.posts, function(x) paste0(readLines(x), collapse = &amp;#39;\n&amp;#39;) ),
                   char.length = nchar(content)) %&amp;gt;%  # includes output code in length calculation..
  filter(ref.date &amp;gt; as.Date(&amp;#39;2017-01-01&amp;#39;) | ref.date &amp;lt; as.Date(&amp;#39;2018-01-01&amp;#39;) ) # not really necessary but keep it for future

glimpse(df.posts)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 0
## Columns: 4
## $ ref.date    &amp;lt;date&amp;gt; 
## $ ref.month   &amp;lt;chr&amp;gt; 
## $ content     &amp;lt;named list&amp;gt; []
## $ char.length &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Fist, let’s look at the frequency of posts by month:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print( ggplot(df.posts, aes(x = ref.month)) + geom_histogram(stat=&amp;#39;count&amp;#39;)) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Ignoring unknown parameters: binwidth, bins, pad&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2017-12-30-Looking-Back-2017_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It is not accidental that january was the month with the highest number of posts. This is when I had material reserved for the book. June and July (0!) were the worst months as I traveled a lot. In June I attended R and Finance in Chicago, SER in Rio de Janeiro and in July I was visiting Goethe University in Germany for the whole month. On average, I created 0 posts per month overall, which fells quite alright. I hope I can keep that pace for the upcoming years.&lt;/p&gt;
&lt;p&gt;As for the length of posts, below we can see a nice pattern for its distribution conditional on the months of the year.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(ggplot(df.posts, aes(x=ref.month, y = char.length)) + geom_boxplot())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2017-12-30-Looking-Back-2017_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I was not very productive from may to august, writing a few and short posts, when comparing to other months. This was probably due to my travels.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;plans-for-2018&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Plans for 2018&lt;/h1&gt;
&lt;p&gt;Despite the usual effort in research and teaching, my plans for 2018 are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Work on the second edition of the &lt;a href=&#34;https://sites.google.com/view/r-financas/&#34;&gt;portuguese book&lt;/a&gt;&lt;/strong&gt;. It significantly lags the english version in content and this need to be fixed. I already have some ideas laid out for new chapters and new packages to cover. I’ll write more about this update as soon as I have it figured out.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Start a portal for financial data in Brazil&lt;/strong&gt;. I want to make it easy for people to visualize and download organized financial data, specially those without programming experience. It will include the usual datasets such as prices in equity/bond/derivative markets for various frequencies, historical yield curves, financial statements of companies, and so on. The idea is to offer the datasets in various file formats, facilitating its use in research.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That’s it. If you got this far, happy new year! Enjoy your family and the holidays!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Serving shiny apps in the internet with your own server</title>
      <link>https://www.msperlin.com/post/2017-12-13-serving-shiny-apps-internet/</link>
      <pubDate>Wed, 13 Dec 2017 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2017-12-13-serving-shiny-apps-internet/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;In this post I’ll share my experience in setting up my own virtual server for hosting shiny applications in &lt;a href=&#34;https://www.digitalocean.com/&#34;&gt;Digital Ocean&lt;/a&gt;. First, context. I’m working in a academic project where we build a package for accessing financial data and corporate events directly from B3, the Brazilian financial exchange. The objective is to set a reproducible standard and facilite data acquisition of a large, and very interesting, dataset. The result is GetDFPData. Since many researchers and students in Brazil are not knowledgeable in R, we needed to make it easier for people to use the software. A shiny app hosted in the internet is perfect for that. The app is available at &lt;a href=&#34;http://www.msperlin.com/shiny/GetDFPData/&#34;&gt;http://www.msperlin.com/shiny/GetDFPData/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can host your own shiny app for free in &lt;a href=&#34;https://www.shinyapps.io/&#34;&gt;www.shiny.io&lt;/a&gt;, but that comes with some &lt;a href=&#34;https://www.shinyapps.io/#pricing&#34;&gt;usage limitations&lt;/a&gt;. While searching for alternatives, I’ve found this &lt;a href=&#34;https://deanattali.com/2015/05/09/setup-rstudio-shiny-server-digital-ocean/&#34;&gt;great post&lt;/a&gt; by &lt;a href=&#34;https://deanattali.com/&#34;&gt;Dean Attali&lt;/a&gt; that clearly explains the steps for setting up a web server in a virtual machine from Digital Ocean. Despite being a 2015 post, it works perfectly. The best thing is that a server only costs $5 per month, with the first two months for free.&lt;/p&gt;
&lt;p&gt;Once the server is up and running, I can control it using ssh (terminal), send/retrieve files with github/dropbox or rsync, and run code with Rstudio server, which is basically a Rstudio session in a browser. Now I have my own corner in the internet, where I can host all my shiny apps with full control. I’m not only using the server for hosting web applications, but also running CRON jobs for periodically gather data for another project, which has to run a R script every day. No longer I have to worry or remember to turn on my computer every day. I’m sure I’ll find many more uses to it in the future.&lt;/p&gt;
&lt;p&gt;I’m very happy in choosing the longer, more difficult path in publishing a shiny app in the internet. I learned a lot along the way. At first it felt overwhelming to configure every aspect of the server. But, if you know a bit of Linux, setting up your own webserver is not that difficult. I recommend everyone to give it a try.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Package GetDFPData</title>
      <link>https://www.msperlin.com/post/2017-12-06-package-getdfpdata/</link>
      <pubDate>Wed, 06 Dec 2017 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2017-12-06-package-getdfpdata/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div class=&#34;alert alert-warning&#34;&gt;
&lt;p&gt;
Package &lt;code&gt;GetDFPData&lt;/code&gt; is being substituted by &lt;code&gt;GetDFPData2&lt;/code&gt;. See this &lt;a href=&#34;https://www.msperlin.com/post/2020-07-18-new_packages-getfredata-getdfpdata2/&#34;&gt;blog post&lt;/a&gt; for details.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Financial statements of companies traded at B3 (formerly Bovespa), the Brazilian stock exchange, are available in its &lt;a href=&#34;http://www.bmfbovespa.com.br/&#34;&gt;website&lt;/a&gt;. Accessing the data for a single company is straightforward. In the website one can find a simple interface for accessing this dataset. An example is given &lt;a href=&#34;https://www.rad.cvm.gov.br/ENETCONSULTA/frmGerenciaPaginaFRE.aspx?NumeroSequencialDocumento=67775&amp;amp;CodigoTipoInstituicao=2&#34;&gt;here&lt;/a&gt;. However, gathering and organizing the data for a large scale research, with many companies and many dates, is painful. Financial reports must be downloaded or copied individually and later aggregated. Changes in the accounting format thoughout time can make this process slow, unreliable and irreproducible.&lt;/p&gt;
&lt;p&gt;Package &lt;code&gt;GetDFPData&lt;/code&gt; provides a R interface to all annual financial statements available in the website and more. It not only downloads the data but also organizes it in a tabular format and allows the use of inflation indexes. Users can select companies and a time period to download all available data. Several information about current companies, such as sector and available quarters are also at reach. The main purpose of the package is to make it easy to access financial statements in large scale research, facilitating the reproducibility of corporate finance studies with B3 data.&lt;/p&gt;
&lt;p&gt;The positive aspects of &lt;code&gt;GetDFDData&lt;/code&gt; are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Easy and simple R and web interface&lt;/li&gt;
&lt;li&gt;Changes in accounting format are internally handled by the software&lt;/li&gt;
&lt;li&gt;Access to corporate events in the FRE system such as dividend payments, changes in stock holder composition, changes in governance listings, board composition and compensation, debt composition, and a lot more!&lt;/li&gt;
&lt;li&gt;The output data is automatically organized using tidy data principles (long format)&lt;/li&gt;
&lt;li&gt;A cache system is employed for fast data acquisition&lt;/li&gt;
&lt;li&gt;Completely free and open source!&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;installation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Installation&lt;/h1&gt;
&lt;p&gt;The package is available in CRAN (release version) and in Github (development version). You can install any of those with the following code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Release version in CRAN
install.packages(&amp;#39;GetDFPData&amp;#39;) # not in CRAN yet

# Development version in Github
devtools::install_github(&amp;#39;msperlin/GetDFPData&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;shinny-interface&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Shinny interface&lt;/h1&gt;
&lt;p&gt;The web interface of &lt;code&gt;GetDFPData&lt;/code&gt; is available at &lt;a href=&#34;http://www.msperlin.com/shiny/GetDFPData/&#34;&gt;http://www.msperlin.com/shiny/GetDFPData/&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-use-getdfpdata&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How to use &lt;code&gt;GetDFPData&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;The starting point of &lt;code&gt;GetDFPData&lt;/code&gt; is to find the official names of companies in B3. Function &lt;code&gt;gdfpd.search.company&lt;/code&gt; serves this purpose. Given a string (text), it will search for a partial matches in companies names. As an example, let’s find the &lt;em&gt;official&lt;/em&gt; name of Petrobras, one of the largest companies in Brazil:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(GetDFPData)
library(tibble)

gdfpd.search.company(&amp;#39;petrobras&amp;#39;,cache.folder = tempdir())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Its official name in Bovespa records is &lt;code&gt;PETRÓLEO BRASILEIRO  S.A.  - PETROBRAS&lt;/code&gt;. Data for quarterly and annual statements are available from 1998 to 2017. The situation of the company, active or canceled, is also given. This helps verifying the availability of data.&lt;/p&gt;
&lt;p&gt;The content of all available financial statements can be accessed with function &lt;code&gt;gdfpd.get.info.companies&lt;/code&gt;. It will read and parse a .csv file from my &lt;a href=&#34;https://github.com/msperlin/GetDFPData_auxiliary&#34;&gt;github repository&lt;/a&gt;. This will be periodically updated for new information. Let’s try it out:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df.info &amp;lt;- gdfpd.get.info.companies(type.data = &amp;#39;companies&amp;#39;, cache.folder = tempdir())

glimpse(df.info)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This file includes several information that are gathered from Bovespa: names of companies, official numeric ids, listing segment, sectors, traded tickers and, most importantly, the available dates. The resulting dataframe can be used to filter and gather information for large scale research such as downloading financial data for a specific sector.&lt;/p&gt;
&lt;div id=&#34;downloading-financial-information-for-one-company&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Downloading financial information for ONE company&lt;/h2&gt;
&lt;p&gt;All you need to download financial data with &lt;code&gt;GetDFPData&lt;/code&gt; are the official names of companies, which can be found with &lt;code&gt;gdfpd.search.company&lt;/code&gt;, the desired starting and ending dates and the type of financial information (individual or consolidated). Let’s try it for PETROBRAS:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;name.companies &amp;lt;- &amp;#39;PETRÓLEO BRASILEIRO  S.A.  - PETROBRAS&amp;#39;
first.date &amp;lt;- &amp;#39;2015-01-01&amp;#39;
last.date  &amp;lt;- &amp;#39;2016-01-01&amp;#39;

df.reports &amp;lt;- gdfpd.GetDFPData(name.companies = name.companies, 
                               first.date = first.date,
                               last.date = last.date,
                               cache.folder = tempdir())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The resulting object is a &lt;code&gt;tibble&lt;/code&gt;, a data.frame type of object that allows for list columns. Let’s have a look in its content:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(df.reports)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Object &lt;code&gt;df.reports&lt;/code&gt; only has one row since we only asked for data of one company. The number of rows increases with the number of companies, as we will soon learn with the next example. All financial statements for the different years are available within &lt;code&gt;df.reports&lt;/code&gt;. For example, the assets statements for all desired years of PETROBRAS are:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df.income.long &amp;lt;- df.reports$fr.income[[1]]

glimpse(df.income.long)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The resulting dataframe is in the long format, ready for processing. In the long format, financial statements of different years are stacked. In the wide format, we have the year as columns of the table.&lt;/p&gt;
&lt;p&gt;If you want the wide format, which is the most common way that financial reports are presented, you can use function &lt;code&gt;gdfpd.convert.to.wide&lt;/code&gt;. See an example next:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df.income.wide &amp;lt;- gdfpd.convert.to.wide(df.income.long)

knitr::kable(df.income.wide )&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;downloading-financial-information-for-several-companies&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Downloading financial information for SEVERAL companies&lt;/h2&gt;
&lt;p&gt;If you are doing serious research, it is likely that you need financial statements for more than one company. Package &lt;code&gt;GetDFPData&lt;/code&gt; is specially designed for handling large scale download of data. Let’s build a case with two selected companies:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my.companies &amp;lt;- c(&amp;#39;PETRÓLEO BRASILEIRO  S.A.  - PETROBRAS&amp;#39;,
                  &amp;#39;BANCO DO ESTADO DO RIO GRANDE DO SUL SA&amp;#39;)

first.date &amp;lt;- &amp;#39;2016-01-01&amp;#39;
last.date  &amp;lt;- &amp;#39;2017-01-01&amp;#39;
type.statements &amp;lt;- &amp;#39;individual&amp;#39;

df.reports &amp;lt;- gdfpd.GetDFPData(name.companies = my.companies, 
                               first.date = first.date,
                               last.date = last.date,
                               cache.folder = tempdir())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now we can check the resulting &lt;code&gt;tibble&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(df.reports)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Every row of &lt;code&gt;df.reports&lt;/code&gt; will provide information for one company. Metadata about the corresponding dataframes such as min/max dates is available in the first columns. Keeping a tabular structure facilitates the organization and future processing of all financial data. We can use tibble &lt;code&gt;df.reports&lt;/code&gt; for creating other dataframes in the long format containing data for all companies. See next, where we create dataframes with the assets and liabilities of all companies:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df.assets &amp;lt;- do.call(what = rbind, args = df.reports$fr.assets)
df.liabilities &amp;lt;- do.call(what = rbind, args = df.reports$fr.liabilities)

df.assets.liabilities &amp;lt;- rbind(df.assets, df.liabilities)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As an example, let’s use the resulting dataframe for calculating and analyzing a simple liquidity index of a company, the total of current (liquid) assets (&lt;em&gt;Ativo circulante&lt;/em&gt;) divided by the total of current short term liabilities (&lt;em&gt;Passivo Circulante&lt;/em&gt;), over time.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)

my.tab &amp;lt;- df.assets.liabilities %&amp;gt;%
  group_by(name.company, ref.date) %&amp;gt;%
  summarise(Liq.Index = acc.value[acc.number == &amp;#39;1.01&amp;#39;]/ acc.value[acc.number == &amp;#39;2.01&amp;#39;])

my.tab&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can visualize the information using &lt;code&gt;ggplot2&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

p &amp;lt;- ggplot(my.tab, aes(x = ref.date, y = Liq.Index, fill = name.company)) +
  geom_col(position = &amp;#39;dodge&amp;#39; )
print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;exporting-financial-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exporting financial data&lt;/h2&gt;
&lt;p&gt;The package includes function &lt;code&gt;gdfpd.export.DFP.data&lt;/code&gt; for exporting the financial data to an Excel or zipped csv files. See next:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my.basename &amp;lt;- &amp;#39;MyExcelData&amp;#39;
my.format &amp;lt;- &amp;#39;csv&amp;#39; # only supported so far
gdfpd.export.DFP.data(df.reports = df.reports, 
                      base.file.name = my.basename,
                      type.export = my.format)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The resulting Excel file contains all data available in &lt;code&gt;df.reports&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The Brazilian Yield Curve</title>
      <link>https://www.msperlin.com/post/2017-09-14-brazilian-yield-curve/</link>
      <pubDate>Thu, 14 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2017-09-14-brazilian-yield-curve/</guid>
      <description>


&lt;p&gt;The latest version of &lt;code&gt;GetTDData&lt;/code&gt; offers function &lt;code&gt;get.yield.curve&lt;/code&gt; to download the current Brazilian yield curve directly from &lt;a href=&#34;http://www.anbima.com.br/est_termo/CZ.asp&#34;&gt;Anbima&lt;/a&gt;. The yield curve is a financial tool that, based on current prices of fixed income instruments, shows how the market perceives the future real, nominal and inflation returns. You can find more details regarding the use and definition of a yield curve in &lt;a href=&#34;http://www.investopedia.com/terms/y/yieldcurve.asp&#34;&gt;Investopedia&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Unfortunately, function &lt;code&gt;get.yield.curve&lt;/code&gt; only downloads the &lt;strong&gt;current&lt;/strong&gt; yield curve from the website. Data for historical curves over five business days are not available in Anbima website.&lt;/p&gt;
&lt;p&gt;The new version of &lt;code&gt;GetTDData&lt;/code&gt; is available in github and CRAN:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#from CRAN
install.packages(&amp;#39;GetTDData&amp;#39;)

# From github
devtools::install_github(&amp;#39;msperlin/GetTDData&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;the-current-brazilian-yield-curve&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The current Brazilian yield curve&lt;/h1&gt;
&lt;p&gt;Downloading the yield curve is easy, all you need is to di us call function &lt;code&gt;get.yield.curve&lt;/code&gt; without any argument:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(GetTDData)

df.yield &amp;lt;- get.yield.curve()  
str(df.yield)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    111 obs. of  5 variables:
##  $ n.biz.days  : num  126 252 378 504 630 ...
##  $ type        : chr  &amp;quot;real_return&amp;quot; &amp;quot;real_return&amp;quot; &amp;quot;real_return&amp;quot; &amp;quot;real_return&amp;quot; ...
##  $ value       : num  3.89 2.05 1.98 2.28 2.6 ...
##  $ ref.date    : Date, format: &amp;quot;2020-08-31&amp;quot; &amp;quot;2021-01-04&amp;quot; ...
##  $ current.date: Date, format: &amp;quot;2020-04-27&amp;quot; &amp;quot;2020-04-27&amp;quot; ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result is a dataframe in the long format containing data for the yield curve of real, nominal and inflation returns. Let’s plot it!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

p &amp;lt;- ggplot(df.yield, aes(x=ref.date, y = value) ) +
  geom_line(size=1) + geom_point() + facet_grid(~type, scales = &amp;#39;free&amp;#39;) + 
  labs(title = paste0(&amp;#39;The current Brazilian Yield Curve &amp;#39;),
       subtitle = paste0(&amp;#39;Date: &amp;#39;, df.yield$current.date[1]))     

print(p)  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2017-09-14-Brazilian-Yield-Curve_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The expected inflation in Brazil seems to be stable. Market expectation is for an inflation around 5% a year in 2024. This level is quite low when compared to our &lt;a href=&#34;https://tradingeconomics.com/brazil/inflation-cpi&#34;&gt;history&lt;/a&gt;. As for future nominal interest rate, market expects another drop in the interest rate level in 2019. This is in line with the latest report from &lt;a href=&#34;http://www.bcb.gov.br/?ATACOPOM&#34;&gt;COPOM&lt;/a&gt;, the Brazilian comittee of monetary policy. Real returns also seems to be stable and low, around 5%. Again, this is one of the lowest levels of real returns in our economy.&lt;/p&gt;
&lt;p&gt;I’m very optimistic (and very biased as I love my country!) regarding the future of the Brazilian economy. I hope we can keep these low levels of interest rate and inflation in order to foment comsumption, jobs and overall economic well-being.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Studying CRAN package names</title>
      <link>https://www.msperlin.com/post/2017-05-09-studying-pkg-names/</link>
      <pubDate>Tue, 09 May 2017 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2017-05-09-studying-pkg-names/</guid>
      <description>


&lt;p&gt;Setting a name for a CRAN package is an intimate process. Out of an infinite range of possibilities, an idea comes for a package and you spend at least a couple of days writing up and testing your code before submitting to CRAN. Once you set the name of the package, you cannot change it. Your choice index your effort and, it shouldn’t be a surprise that the name of the package can improve its impact.&lt;/p&gt;
&lt;p&gt;Looking at &lt;a href=&#34;https://cran.r-project.org/web/packages/available_packages_by_date.html&#34;&gt;package names&lt;/a&gt;, one strategy that I commonly observe is to use small words, a verb or noun, and add the letter R to it. A good example is &lt;code&gt;dplyr&lt;/code&gt;. Letter &lt;code&gt;d&lt;/code&gt; stands for dataframe, ply is just a tool, and R is, well, you know. In a conventional sense, the name of this popular tool is informative and easy to remember. As always, the extremes are never good. A couple of bad examples of package naming are &lt;code&gt;A3&lt;/code&gt;, &lt;code&gt;AF&lt;/code&gt;, &lt;code&gt;BB&lt;/code&gt; and so on. Googling the package name is definitely not helpful. On the other end, package &lt;code&gt;samplesizelogisticcasecontrol&lt;/code&gt; provides a lot of information but it is plain unattractive!&lt;/p&gt;
&lt;p&gt;Another strategy that I also find interesting is developers using names that, on first sight, are completely unrelated to the purpose of the package. But, there is a not so obvious link. One example is package &lt;code&gt;sandwich&lt;/code&gt;. At first sight, I challenge anyone to figure out what it does. This is an econometric package that computes robust standard errors in a regression model. These robust estimates are also called &lt;em&gt;sandwich&lt;/em&gt; estimators because the formula &lt;a href=&#34;http://gosset.wharton.upenn.edu/teaching/541/sandwich_estimator.html&#34;&gt;looks like a sandwich&lt;/a&gt;. But, you only know that if you studied a bit of econometric theory. This strategy works because it is easier to remember things that surprise us. Another great example is package &lt;code&gt;janitor&lt;/code&gt;. I’m sure the you already suspects that it has something do to with data cleaning. And you are right! The message of the name is effortless and it works! The author even got the privilege of using letter R in the name.&lt;/p&gt;
&lt;p&gt;While I can always hand pick good and bad examples, let’s dig deeper. In this post, we will study the names of packages available in CRAN by comparing them to the whole English vocabulary. We are going use the following datasets:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;List of CRAN package, available with function &lt;code&gt;available.packages()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;List of English words, available at &lt;a href=&#34;http://wordnet.princeton.edu/wordnet/download/standoff/&#34;&gt;WordNet database&lt;/a&gt;. This is a comprehensive database of English words that I once used in a &lt;a href=&#34;http://onlinelibrary.wiley.com/doi/10.1002/for.2446/full&#34;&gt;paper&lt;/a&gt;. It contains several tables, including all possible words from the English language.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;First, let’s have a look at the distribution of size (number of characters) for all packages available in CRAN:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(ggplot2)

# get data
df.pkgs &amp;lt;- as.data.frame(available.packages(repos = &amp;#39;https://cloud.r-project.org/&amp;#39;)) %&amp;gt;%
  mutate(Package = as.character(Package),
         n.char = nchar(Package)) %&amp;gt;% 
  rename(pkg = Package) %&amp;gt;%
  select(pkg, n.char)

# plot it!
p &amp;lt;- ggplot(df.pkgs, aes(x=n.char)) +
  geom_histogram(binwidth = 1)
print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2017-05-09-Studying-Pkg-Names_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As I suspected, the names of CRAN packages are usually small, with an average of 5-6 characters. We have a couple of packages with more than 25 characters. Let’s see their names:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df.pkgs$pkg[df.pkgs$n.char&amp;gt;25]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;AnglerCreelSurveySimulation&amp;quot;      &amp;quot;BipartiteModularityMaximization&amp;quot; 
##  [3] &amp;quot;BoutrosLab.plotting.general&amp;quot;      &amp;quot;easyDifferentialGeneCoexpression&amp;quot;
##  [5] &amp;quot;factset.analyticsapi.engines&amp;quot;     &amp;quot;factset.protobuf.stachextensions&amp;quot;
##  [7] &amp;quot;FractalParameterEstimation&amp;quot;       &amp;quot;GeneralisedCovarianceMeasure&amp;quot;    
##  [9] &amp;quot;GreedyExperimentalDesignJARs&amp;quot;     &amp;quot;ig.vancouver.2014.topcolour&amp;quot;     
## [11] &amp;quot;image.CornerDetectionHarris&amp;quot;      &amp;quot;MulvariateRandomForestVarImp&amp;quot;    
## [13] &amp;quot;NegativeControlOutcomeAdjustment&amp;quot; &amp;quot;particle.swarm.optimisation&amp;quot;     
## [15] &amp;quot;paws.application.integration&amp;quot;     &amp;quot;RcmdrPlugin.sutteForecastR&amp;quot;      
## [17] &amp;quot;ResidentialEnergyConsumption&amp;quot;     &amp;quot;RoughSetKnowledgeReduction&amp;quot;      
## [19] &amp;quot;samplesizelogisticcasecontrol&amp;quot;    &amp;quot;sarp.snowprofile.alignment&amp;quot;      
## [21] &amp;quot;SuperpixelImageSegmentation&amp;quot;      &amp;quot;wyz.code.offensiveProgramming&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I am sorry for the authors, but, in my opinion, I’m sure we could find better names. I am also sorry for those who are using these packages but do not use the &lt;a href=&#34;https://msperlin.github.io/pafdR/basicoperations.html#using-code-completion-with-tab&#34;&gt;autocomplete tool&lt;/a&gt; of RStudio and need to type the loooooooooong names.&lt;/p&gt;
&lt;p&gt;As for my hypothesis that CRAN package have short names, let’s compare the distribution of package names against all words in the English language. For that, let’s load the &lt;a href=&#34;http://sourceforge.net/projects/wnsql/files/wnsql3/sqlite/3.1_snapshot/sqlite-31_snapshot.db.zip/download&#34;&gt;WordNet database&lt;/a&gt; and do some calculations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(RSQLite)
library(stringr)

# get data
conn &amp;lt;- dbConnect(drv = SQLite(), &amp;#39;wordnet/sqlite-31_snapshot.db&amp;#39;)
words &amp;lt;- dbReadTable(conn, &amp;#39;wordsXsensesXsynsets&amp;#39;) %&amp;gt;%
  select(lemma)

# some are duplicate (same word, different types)
words &amp;lt;- unique(words)
words$nchar &amp;lt;- nchar(words$lemma)

# set df to plot
df.to.plot &amp;lt;- data.frame(n.char = c(df.pkgs$n.char, words$nchar), 
                         source.char = c(rep(&amp;#39;CRAN pkgs&amp;#39;, nrow(df.pkgs)),
                                         rep(&amp;#39;English Vocabulary&amp;#39;, nrow(words))))


p &amp;lt;- ggplot(df.to.plot, aes(x=n.char, color=source.char )) +
  geom_density(size=1) + coord_cartesian(xlim=c(0, 40))

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2017-05-09-Studying-Pkg-Names_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As I suspected, the distributions are very different. There is no need to apply a formal test as the visual evidence is clear: CRAN package have a tendency for shorter names.&lt;/p&gt;
&lt;p&gt;Now, let’s look at the distribution of used letters in relative terms:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(scales)

temp &amp;lt;- str_split(str_to_upper(df.pkgs$pkg), &amp;#39;&amp;#39;)
all.chars &amp;lt;- do.call(what = c,args = temp)
char.counts.pkg &amp;lt;- table(all.chars)

temp &amp;lt;- str_split(str_to_upper(words$lemma), &amp;#39;&amp;#39;)
all.chars &amp;lt;- do.call(what = c,args = temp)
char.counts.words &amp;lt;- table(all.chars)

df.to.plot &amp;lt;- data.frame(perc.count = c(char.counts.pkg/sum(char.counts.pkg), 
                                   char.counts.words/sum(char.counts.words)),
                         char = c(names(char.counts.pkg),
                                  names(char.counts.words)),
                         source.char = c(rep(&amp;#39;CRAN pkgs&amp;#39;, length(char.counts.pkg)),
                                         rep(&amp;#39;WordNet&amp;#39;, length(char.counts.words))))

# only keep LETTERS
idx &amp;lt;- df.to.plot$char %in% LETTERS
df.to.plot &amp;lt;- df.to.plot[idx, ]

p &amp;lt;- ggplot(df.to.plot, aes(x=char, y = perc.count, fill=source.char,width=.5)) +
  geom_col(position = &amp;#39;dodge&amp;#39;) + scale_y_continuous(labels = percent_format())  

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2017-05-09-Studying-Pkg-Names_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The result is really interesting! I was expecting far more differences in the relative use of characters. Not surprisingly, letter R is more used in package naming than in the English vocabulary. Still, the difference is not that large. Given that R is the name of the programming language, I was expecting a much greater proportion of R characters. My intuition was clearly wrong! In comparison, letters P and M have more difference in relative terms than letter R. I’m really not sure why that is. Overall, it is pretty clear the use of characters in the names of packages follow the distribution of words in the English language.&lt;/p&gt;
&lt;p&gt;While the distribution of letter is similar, we find just a few package with names exactly as in the English language. For all 18699 packages found in CRAN, only 1260 are an exact match of all 146625 unique words in the English vocabulary.&lt;/p&gt;
&lt;p&gt;Summing up, our data analysis shows that the names of packages are usually shorter than the words in the English language. However, when looking at distribution of used characters and editing distances, it is pretty clear that the names are based on the English language, usually with a few modifications of a base word.&lt;/p&gt;
&lt;p&gt;I hope you enjoyed this post.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>My Book about using R in Finance</title>
      <link>https://www.msperlin.com/post/2017-05-04-pafdr-is-out/</link>
      <pubDate>Thu, 04 May 2017 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2017-05-04-pafdr-is-out/</guid>
      <description>


&lt;p&gt;I am very please to announce that my book,&lt;strong&gt;Processing and Analyzing Financial Data with R&lt;/strong&gt;, is finally out! This book is an english version of my previous title in portuguese. This is a long term project that I plan to keep on working over the years.&lt;/p&gt;
&lt;p&gt;You can find it in &lt;a href=&#34;https://www.amazon.com/gp/product/8592243556&#34;&gt;Amazon&lt;/a&gt;. Following great titles about R, I decided to also publish an online version with full content &lt;a href=&#34;http://www.msperlin.com/pafdR/&#34;&gt;here&lt;/a&gt;. More details about the book, including table of contents, is availabe in its &lt;a href=&#34;http://www.msperlin.com/books/&#34;&gt;webpage&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Can we predict stock prices with Prophet?</title>
      <link>https://www.msperlin.com/post/2017-03-05-prophet-and_stock-market/</link>
      <pubDate>Sun, 05 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2017-03-05-prophet-and_stock-market/</guid>
      <description>


&lt;p&gt;Facebook recently released a API package allowing access to its forecasting model called &lt;a href=&#34;http://blog.revolutionanalytics.com/2017/02/facebook-prophet.html&#34;&gt;prophet&lt;/a&gt;. According to the underling post:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;It&amp;#39;s not your traditional ARIMA-style time series model. It&amp;#39;s closer in spirit to a  Bayesian-influenced generalized additive model, a regression of smooth terms. The model is resistant   to the effects of outliers, and supports data collected over an irregular time scale (ingliding presence of missing data) without the need for interpolation. The underlying calculation engine is Stan; the R and Python packages simply provide a convenient interface.  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After reading it, I got really curious about the predictive performance of this method for stock prices. That is, &lt;strong&gt;can we predict stock price movements based on prophet?&lt;/strong&gt; In this post I will investigate this research question using a database of prices for the SP500 components.&lt;/p&gt;
&lt;p&gt;Before describing the code and results, it is noteworthy to point out that forecasting stock returns is really hard! There is a significant body of literature trying to forecast prices and to prove (or not) that financial markets are efficient in pricing publicly available information, including historical prices. This is the so called efficient market hypothesis. I have studied it, tried to trade for myself for a while when I was a Msc student, advised several graduate students on it, and the results are mostly the same: it is very difficult to find a trade signal that works well and is sustainable in real life.&lt;/p&gt;
&lt;p&gt;This means that most of the variation in prices is due to random factors that cannot be anticipated. The explanation is simple, prices move according to investor’s expectation from available information. Every time that new (random) information, true or not, reaches the market, investor’s update their beliefs and trade accordingly. So, unless, new information or market expectation have a particular pattern, price changes will be mostly random.&lt;/p&gt;
&lt;p&gt;Even with a body of evidence against our research, it is still interesting to see how we could apply &lt;code&gt;prophet&lt;/code&gt; in a trading setup.&lt;/p&gt;
&lt;div id=&#34;the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The data&lt;/h2&gt;
&lt;p&gt;First, let’s download stock prices for some components of the SP500 index since 2010.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(BatchGetSymbols)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: rvest&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: xml2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: dplyr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;dplyr&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:stats&amp;#39;:
## 
##     filter, lag&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:base&amp;#39;:
## 
##     intersect, setdiff, setequal, union&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(100)

all.stocks &amp;lt;- GetSP500Stocks()$Ticker
my.stocks &amp;lt;- sample(all.stocks, 20)

first.date &amp;lt;- as.Date(&amp;#39;2015-01-01&amp;#39;)
last.date &amp;lt;- as.Date(&amp;#39;2019-01-01&amp;#39;)
df.stocks &amp;lt;- BatchGetSymbols(my.stocks, 
                             first.date = first.date, 
                             last.date = last.date)[[2]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Running BatchGetSymbols for:&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##    tickers =FTV, ZBH, OXY, C, XLNX, VZ, BEN, WY, ROL, VTR, TSN, ABMD, MKC, MDLZ, CNP, PVH, ADBE, EXPD, L, UNM
##    Downloading data for benchmark ticker
## ^GSPC | yahoo (1|1) | Found cache file
## FTV | yahoo (1|20) | Found cache file - Got 62% of valid prices | OUT: not enough data (thresh.bad.data = 75%)
## ZBH | yahoo (2|20) | Found cache file - Got 100% of valid prices | OK!
## OXY | yahoo (3|20) | Found cache file - Got 100% of valid prices | Got it!
## C | yahoo (4|20) | Found cache file - Got 100% of valid prices | You got it!
## XLNX | yahoo (5|20) | Found cache file - Got 100% of valid prices | OK!
## VZ | yahoo (6|20) | Found cache file - Got 100% of valid prices | Got it!
## BEN | yahoo (7|20) | Found cache file - Got 100% of valid prices | Feels good!
## WY | yahoo (8|20) | Found cache file - Got 100% of valid prices | Looking good!
## ROL | yahoo (9|20) | Found cache file - Got 100% of valid prices | Got it!
## VTR | yahoo (10|20) | Found cache file - Got 100% of valid prices | OK!
## TSN | yahoo (11|20) | Found cache file - Got 100% of valid prices | Feels good!
## ABMD | yahoo (12|20) | Found cache file - Got 100% of valid prices | Feels good!
## MKC | yahoo (13|20) | Found cache file - Got 100% of valid prices | Got it!
## MDLZ | yahoo (14|20) | Found cache file - Got 100% of valid prices | Feels good!
## CNP | yahoo (15|20) | Found cache file - Got 100% of valid prices | Got it!
## PVH | yahoo (16|20) | Found cache file - Got 100% of valid prices | Looking good!
## ADBE | yahoo (17|20) | Found cache file - Got 100% of valid prices | OK!
## EXPD | yahoo (18|20) | Found cache file - Got 100% of valid prices | You got it!
## L | yahoo (19|20) | Found cache file - Got 100% of valid prices | Good job!
## UNM | yahoo (20|20) | Found cache file - Got 100% of valid prices | Looking good!&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s understand how prophet works. I was happy to see that the interface is quite simple, you offer a time series with input &lt;code&gt;y&lt;/code&gt; and a date vector with &lt;code&gt;ds&lt;/code&gt;. If no further custom option is set, you are good to go. My only complain with &lt;code&gt;prophet&lt;/code&gt; is that that the function outputs lots of messages. They really should add a &lt;code&gt;quiet&lt;/code&gt; option, so that the user doesn’t have to use &lt;code&gt;capture.output&lt;/code&gt; to silent it. Have a look in the next example with a dummy series:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(prophet)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: Rcpp&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: rlang&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;rlang&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &amp;#39;package:xml2&amp;#39;:
## 
##     as_list&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df.est &amp;lt;- data.frame(y = rnorm(100), ds = Sys.Date() + 1:100)

m &amp;lt;- prophet(df = df.est)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Disabling yearly seasonality. Run prophet with yearly.seasonality=TRUE to override this.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The next step is to think about how to structure a function for our research problem. Our study has two steps, first we will set a &lt;em&gt;training&lt;/em&gt; (in-sample) period, estimate the model and make forecasts. After that, we use the &lt;em&gt;out-of-sample&lt;/em&gt; data to test the accuracy of the model.&lt;/p&gt;
&lt;p&gt;The whole procedure of estimating and forecasting will be encapsulated in a single R function. This is not the best way of doing it but, for our simple example, it will suffice. My function will take as input a dataframe and the number of out-of-sample forecasts. Based on the adjusted closing prices, we calculate returns and feed &lt;code&gt;1:(nrow(df)-nfor)&lt;/code&gt; rows for the estimation. The last &lt;code&gt;nfor&lt;/code&gt; rows are used for testing the accuracy of the model. For example, if I have a vector with 1000 returns and &lt;code&gt;nfor=5&lt;/code&gt;, I use observations from &lt;code&gt;1:995&lt;/code&gt; for estimating the model and &lt;code&gt;996:1000&lt;/code&gt; for testing the forecasts. The function returns a dataframe with the predictions for each horizon, its error, among other things. Here’s the function definition:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;est.model.and.forecast &amp;lt;- function(df.in, nfor=5){
  # Estimated model using prophet and forecast it
  #
  # Args:
  #   df.in - A dataframe with columns price.adjusted and ref.date
  #   nfor - Number of out-of-sample forecasts
  #
  # Returns:
  #   A dataframe with forecasts and errors for each horizon.
  
  require(prophet)
  require(dplyr)
  
  my.ticker &amp;lt;- df.in$ticker[1]
  
  #cat(&amp;#39;\nProcessing &amp;#39;, my.ticker)
  
  df.in &amp;lt;- df.in %&amp;gt;%
    select(ref.date, ret.adjusted.prices)
  
  names(df.in) &amp;lt;- c(&amp;#39;ds&amp;#39;, &amp;#39;y&amp;#39;)
  
  idx &amp;lt;- nrow(df.in) - nfor
  
  df.est &amp;lt;- df.in[1:idx, ]
  df.for &amp;lt;- df.in[(idx + 1):nrow(df.in), ]
  
  capture.output(
    m &amp;lt;- prophet(df = df.est)
  )
  
  # forecast 50 days ahead (it also includes non trading days)
  df.pred &amp;lt;- predict(m,
                     make_future_dataframe(m,
                                           periods = nfor + 50))
  
  df.pred$ds &amp;lt;- as.Date(df.pred$ds)
  df.for &amp;lt;- merge(df.for, df.pred, by = &amp;#39;ds&amp;#39;)
  df.for &amp;lt;- select(df.for, ds, y, yhat)
  
  # forecast statistics
  df.for$eps &amp;lt;- with(df.for,y - yhat)
  df.for$abs.eps &amp;lt;- with(df.for,abs(y - yhat))
  df.for$perc.eps &amp;lt;- with(df.for,(y - yhat)/y)
  df.for$nfor &amp;lt;- 1:nrow(df.for)
  df.for$ticker &amp;lt;- my.ticker
  
  return(df.for)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s try it out using the &lt;code&gt;by&lt;/code&gt; function to apply it for each stock in our sample. All results are later combined in a single dataframe with function &lt;code&gt;do.call&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;out.l &amp;lt;- by(data = df.stocks,
            INDICES = df.stocks$ticker, 
            FUN = est.model.and.forecast, nfor = 5)

my.result &amp;lt;- do.call(rbind, out.l)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Lets have a look in the resulting dataframe:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(my.result)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                ds            y         yhat         eps    abs.eps  perc.eps
## ABMD.1 2018-12-24 -0.031726969 -0.005299687 -0.02642728 0.02642728 0.8329596
## ABMD.2 2018-12-26  0.093781188 -0.002497698  0.09627889 0.09627889 1.0266333
## ABMD.3 2018-12-27  0.026769487 -0.005186820  0.03195631 0.03195631 1.1937587
## ABMD.4 2018-12-28  0.007919663 -0.001131558  0.00905122 0.00905122 1.1428795
## ABMD.5 2018-12-31  0.021592217 -0.003278144  0.02487036 0.02487036 1.1518206
## ADBE.1 2018-12-24 -0.017432945 -0.005505203 -0.01192774 0.01192774 0.6842070
##        nfor ticker
## ABMD.1    1   ABMD
## ABMD.2    2   ABMD
## ABMD.3    3   ABMD
## ABMD.4    4   ABMD
## ABMD.5    5   ABMD
## ADBE.1    1   ADBE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this object you’ll find the forecasts (yhat), the actual values (y), the absolute and normalized error (abs.eps, perc.eps).&lt;/p&gt;
&lt;p&gt;For ou first analysis, let’s have a look on the effect of the forecasting horizon over the absolute error distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

p &amp;lt;- ggplot(my.result, aes(x=factor(nfor), 
                           y=abs.eps))
p &amp;lt;- p + geom_boxplot()

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2017-03-05-Prophet-and_stock-market_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We do find some positive dependency. As the horizon increases, the forecasting algorithm makes more mistakes. Surprisingly, this pattern is not found for &lt;code&gt;nfor=5&lt;/code&gt; and &lt;code&gt;nfor=4&lt;/code&gt;. It might be interesting to add more data and check if this effect is robust.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;encopassing-test&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Encopassing test&lt;/h2&gt;
&lt;p&gt;A simple and powerful test for verifying the accuracy of a prediction algorithm is the encompassing test. The idea is to estimate the following linear model with the real returns (&lt;span class=&#34;math inline&#34;&gt;\(R_t\)&lt;/span&gt;) and its predictions (&lt;span class=&#34;math inline&#34;&gt;\(\hat{R} _t\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_t = \alpha + \beta\hat{y_t} + \epsilon _t\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;If the model provides good forecasts, we can expect that &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; is equal to zero (no bias) and &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; is equal to 1. If both conditions are true, we have that &lt;span class=&#34;math inline&#34;&gt;\(R_t = \hat{R} _t + \epsilon _t\)&lt;/span&gt;$, meaning that our forecasting model provides an unbiased estimator of the predicted variable. In a formal research, we could use a Wald test to verify this hypothesis jointly.&lt;/p&gt;
&lt;p&gt;First, lets find the result of the encompassing test for all forecasts.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm.model &amp;lt;- lm(formula = y ~yhat, data = my.result)
summary(lm.model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = y ~ yhat, data = my.result)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.055237 -0.012307 -0.000287  0.008360  0.086257 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)  
## (Intercept) 0.007954   0.004063   1.957   0.0533 .
## yhat        0.171995   1.132177   0.152   0.8796  
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.02675 on 93 degrees of freedom
## Multiple R-squared:  0.0002481,  Adjusted R-squared:  -0.0105 
## F-statistic: 0.02308 on 1 and 93 DF,  p-value: 0.8796&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, it didn’t work very well. The constant is significant, which indicates a bias. The value of 0.1719945 is not very close to 1. But, it could be the case that the different horizon have different results. A longer horizon, with bad forecasts, will be affecting short horizons with good forecasts. Lets use &lt;code&gt;dplyr&lt;/code&gt; to separate our model according to &lt;code&gt;nfor&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;models &amp;lt;- my.result %&amp;gt;%
  group_by(nfor) %&amp;gt;%
  do(ols.model = lm(data = ., formula = y ~ yhat ))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We report the results with &lt;code&gt;texreg::screenreg&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;texreg::screenreg(models$ols.model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ==============================================================
##              Model 1    Model 2    Model 3  Model 4  Model 5  
## --------------------------------------------------------------
## (Intercept)  -0.04 ***   0.05 ***   0.01    -0.00     0.01 ***
##              (0.00)     (0.01)     (0.00)   (0.00)   (0.00)   
## yhat         -2.32 **   -0.14      -1.01    -0.19    -0.22    
##              (0.77)     (2.82)     (0.87)   (0.51)   (0.72)   
## --------------------------------------------------------------
## R^2           0.35       0.00       0.07     0.01     0.01    
## Adj. R^2      0.31      -0.06       0.02    -0.05    -0.05    
## Num. obs.    19         19         19       19       19       
## RMSE          0.01       0.02       0.01     0.01     0.01    
## ==============================================================
## *** p &amp;lt; 0.001, ** p &amp;lt; 0.01, * p &amp;lt; 0.05&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Well, the R2 shows some evidence that shorter horizons have better results in the encompassing test. But, we got some negative betas! This means that, for some horizons, it might be better to take the opposite suggestion of the forecast!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;trading-based-on-forecasts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Trading based on forecasts&lt;/h2&gt;
&lt;p&gt;In a practical trading applications, it might not be of interest to forecast actual returns. If you are trading according to these forecasts, you are probably more worried about the direction of the forecasts and not its nominal error. A model can have bad nominal forecasts, but be good in predicting the sign of the next price movement. If this is the case, you can still make money even though your model fails in the encompassing test.&lt;/p&gt;
&lt;p&gt;Let’s try it out with a simple trading strategy for all different horizons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;buy in end of day &lt;em&gt;t&lt;/em&gt; if forecast in &lt;em&gt;t+1&lt;/em&gt; is positive and sell at the end of &lt;em&gt;t+1&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;short-sell in the end of day &lt;em&gt;t&lt;/em&gt; when forecast for &lt;em&gt;t+1&lt;/em&gt; is negative and buy it back in the end of &lt;em&gt;t+1&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The total profit will be given by:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my.profit &amp;lt;- sum(with(my.result, (yhat&amp;gt;0)*y + (yhat&amp;lt;0)*-y))
print(my.profit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.7584576&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Not bad! Doesn’t look like much, but remember that we have a few trading days and this return might be due to a sistematic effect in the market. Let’s see how this result compares to random trading signals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n.sim &amp;lt;- 10000

monkey.ret &amp;lt;- numeric(length = n.sim)
for (i in seq(n.sim)) {
  rnd.vec &amp;lt;- rnorm(length(my.result$y))
  
  monkey.ret[i] &amp;lt;- sum( (rnd.vec&amp;gt;0)*my.result$y + (rnd.vec&amp;lt;0)*-my.result$y )
  
} 

temp.df &amp;lt;- data.frame(monkey.ret, my.profit)
p &amp;lt;- ggplot(temp.df, aes(monkey.ret)) 
p &amp;lt;- p + geom_histogram()
p &amp;lt;- p + geom_vline(aes(xintercept =  my.profit),size=2)
p &amp;lt;- p + labs(x=&amp;#39;Returns from random trading signals&amp;#39;)
print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2017-03-05-Prophet-and_stock-market_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The previous histogram shows the total return from randomnly generated signals in 10^{4} simulations. The vertical line is the result from using &lt;code&gt;prophet&lt;/code&gt;. As you can see, it is a bit higher than the average of the distribution. The total return from &lt;code&gt;prophet&lt;/code&gt; is lower than the return of the naive strategy in 99.72 percent of the simulations. This is not a bad result. But, notice that we didnt add trading or liquidity costs to the analysis, which will make the total returns worse.&lt;/p&gt;
&lt;p&gt;The main results of this simple study are clear: &lt;strong&gt;&lt;code&gt;prophet&lt;/code&gt; is bad at point forecasts for returns, specially for longer horizons, but does quite better in directional predictions&lt;/strong&gt;. It might be interesting to test it further, with more data, adding trading costs, other forecasting setups, and see if the results hold.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Writing a R book and self-publishing it in Amazon</title>
      <link>https://www.msperlin.com/post/2017-02-16-writing-a-book/</link>
      <pubDate>Thu, 16 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2017-02-16-writing-a-book/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Many people, including my university colleagues and friends, have asked me about the process of writing a book and self publishing it in Amazon. You can find the details about the english version of the book &lt;a href=&#34;https://www.amazon.com/dp/B084LSNXMN&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;http://www.msperlin.com/books/&#34;&gt;here&lt;/a&gt;. Given so much interest, I’m going to report the whole process in this post.&lt;/p&gt;
&lt;p&gt;First, motivation. &lt;strong&gt;Why did I write a book?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I am a university professor. Writing is a major part of my work and I really enjoy it. Think about it, it is a magical process. I press a specific and long combination of strokes in my keyboard and that translates into information distributed all over the world. This information helps people in a particular problem, just as I have been helped in the past by reading the work of other people.&lt;/p&gt;
&lt;p&gt;A longer answer, I wrote the book because I simply felt like studying and learning more about R. Writing a book is an excellent opportunity for doing so as it forces you to think about a topic and communicate it clearly and objectively. After reading the &lt;a href=&#34;https://www.amazon.com/Reproducible-Research-Studio-Second-Chapman/dp/1498715370&#34;&gt;book from Grangrud&lt;/a&gt;, I got some inspiration for writing my own book about R, reproducible research and Finance. My experience in the academia tells me that people often learn programming by themselves, without any consideration for the structure and re-usability of the code. You can see examples of it when you download code from other researchers. In most cases, it is a big mess and I often found it easier (and less risky) to rewrite it all from scratch. So, writing a book is a way to show to people how to use R for data analysis in finance and how to organize code that can be used later, saving lots of time of development. As I mentioned in a &lt;a href=&#34;http://www.msperlin.com/post/2017-05-04-pafdr-is-out/&#34;&gt;previous post&lt;/a&gt;, another argument for writing the book is that, even if I didn’t publish it, I would still have very good class notes for my graduate students or perhaps a pdf to host in my website.&lt;/p&gt;
&lt;p&gt;Off course you may wonder about the financial side. After all, I am a finance professor and finance is the science of money. While you can make money selling books, the financial incentives for writing a new technical book are quite low. In financial terms, writing a technical book is a project with negative expected Net Present Value (NPV). This means that, from the &lt;em&gt;ex ante&lt;/em&gt; point of view of a potential writer, working in a technical book simply does not create financial value. There is a high production cost in terms of how much time you spend writing and formatting the book and a high uncertainty about the future royalties. If you look at it from the financial side, it is just a bad gamble. This is why you should only write a book about something you love and want to learn more about. Otherwise, it can become a big frustration.&lt;/p&gt;
&lt;div id=&#34;the-writing-process&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The writing process&lt;/h2&gt;
&lt;p&gt;The first step in writing my book was to set out a summary, that is, the names of the chapters. The first part of it was pretty obvious, it covered the basics of using R: packages, objects, functions, loops and so on. The rest of the topics were all based on my experience. I asked the question &lt;strong&gt;What are the most important data tasks that a finance student should learn?&lt;/strong&gt;. Once you have a TOC (table of contents) ready, it is all about filling up the book with content.&lt;/p&gt;
&lt;p&gt;I really enjoyed the process of writing the book. Taking a long term project such as a book requires discipline. One strategy that really helped me was to work very early in the morning. As soon as the sun rised at 0630, I’m up and in my way to the university. From 07:00 am to 0900 am, nothing really happens at the university, giving me plenty of time to write peacefully. Some days I could write all morning, if I felt like it and had a free schedule. One tip for anyone that is thinking about writing a book (or article), only write when you fell like writing. It is really difficult to write well if your mind is not into it. Not having a deadline for this project meant that I could take my time in developing it.&lt;/p&gt;
&lt;p&gt;As for software, the first version of the book was written in &lt;a href=&#34;http://www.texstudio.org/&#34;&gt;TexStudio&lt;/a&gt; with the content in &lt;code&gt;Sweave&lt;/code&gt; files (.Rnw), and a &lt;a href=&#34;https://www.r-bloggers.com/use-sweave-with-texmaker-and-make-synctex-work-properly-with-it/&#34;&gt;simple hack&lt;/a&gt; to call Sweave from R and compile the resulting tex file. I’m used to work with latex, so the choice for textudio was obvious. I like this latex editor as it integrates nicely with grammar checking tools and latex compilation. Why not &lt;code&gt;knitr&lt;/code&gt;? Well, at the time I was very comfortable with &lt;code&gt;Sweave&lt;/code&gt;. It offered everything I needed. I didn’t see a reason for change. Clearly, I was wrong. Once I started to investigate how to format better the code in the book, it became clear that I should be using &lt;code&gt;knitr&lt;/code&gt;, which has all these extra options that are not available in &lt;code&gt;Sweave&lt;/code&gt;. I switched it as soon as I realized how much I would gain there was.&lt;/p&gt;
&lt;p&gt;After 6 months of work, I had a first readable version of the book. This is when I started to investigate how to turn a latex file into an ebook file. To my surprise, this is not easy! It could be the case that I had lots of code and figures from the compilation. I tried all the existing software and, to my frustration, it just didn’t work. When I didn’t got an error message that stopped the conversion, the resulting &lt;em&gt;epub&lt;/em&gt; file look awful in the kindle reader. The warning and error messages from the latex2ebook compiler also didn’t help a lot.&lt;/p&gt;
&lt;p&gt;By looking for solutions in the internet and with a bit of luck, I’ve found that Yihui Xie had just published his &lt;a href=&#34;https://bookdown.org/&#34;&gt;bookdown package&lt;/a&gt;. I tried out the first chapters and it worked perfectly! The great thing about &lt;code&gt;bookdown&lt;/code&gt; is that you can output to pdf, html or epub with the same files. I was very happy that, finally, I would be able to get all formats that I needed in a single platform. I’m not going to go into the details about how to use &lt;code&gt;bookdown&lt;/code&gt;. You can find the official tutorial &lt;a href=&#34;https://bookdown.org/yihui/bookdown/&#34;&gt;here&lt;/a&gt;. It is worth to point out that the written content is just RMarkdown so, if you know latex, you’ll fell right at home. So, here I go again, switching a whole book from latex to Rmarkdown.&lt;/p&gt;
&lt;p&gt;The only feature in &lt;code&gt;bookdown&lt;/code&gt; that didn’t work out of the box was the equation in the kindle format. The formulas just didn’t print well. The weird part is that they looked fine in any other ebook reader, but not in Kindle. Apparently, there is no solution for this problem besides using figure files for the equations. What I did to solve it was to use R switches within the book so that the epub compilation used a figure file created in &lt;a href=&#34;https://www.codecogs.com/latex/eqneditor.php&#34;&gt;codecogs&lt;/a&gt; and the latex/html compilation used the normal code for equations. See here an example of code for the first equation in chapter 9.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2017-02-16-Writing-a-book_files/screenshot-ebook-figures.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As you can see, I used a switch in the &lt;code&gt;knitr&lt;/code&gt; command as in &lt;code&gt;include=identical(knitr:::pandoc_to(), &#39;epub3&#39;)&lt;/code&gt; to run each code conditional to the type of output. As for inline equations, I just used straight text to indicate coefficients such as &lt;em&gt;beta&lt;/em&gt;, &lt;em&gt;alpha&lt;/em&gt;. I know I could have used the same strategy, but I didn’t fell the need since there were so few inline equations in the text.&lt;/p&gt;
&lt;p&gt;After switching to bookdown, I added a couple more chapters in the following months. A comment here is that I tried writing in RStudio but it didn’t worked out for me. Perhaps it was due to the large files I was handling, but it felt really clunky, slow and not reactive. Also, the grammar check system in Rstudio needs a lot of work. I tried going back to Texstudio but it didn’t had support for markdown highlighting. I then switched software by doing the writing in &lt;a href=&#34;https://notepad-plus-plus.org/&#34;&gt;notepad++&lt;/a&gt; + &lt;a href=&#34;https://github.com/Edditoria/markdown_npp&#34;&gt;markdown extension&lt;/a&gt; and only used RStudio to compile the book. If you haven’t tried notepad++, give it a go. I really like it and I find myself using it more and more.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;publishing-in-amazon&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Publishing in Amazon&lt;/h2&gt;
&lt;p&gt;Around october of 2016, the content of the book started to take a good shape and it was time to investigate where and how to publish it. I got in touch with a major local publisher here in Brazil and, after one month, they informed me that they were not interested in the book. While I could try other publishers, I really didn’t felt like going through another month of evaluation. I studied for while and decided to &lt;strong&gt;self-publish the book&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;One positive aspect of self publishing is that big publishers downsized over the years and good professionals are now in the market for hire. This means that a large range of good editors and designers are available to the independent author. In my case, I fought the urge to do the cover myself and searched for a cover designer. After a lot of search, I hired &lt;a href=&#34;http://capista.com.br/capas-de-livros/&#34;&gt;Capista&lt;/a&gt; to do the book cover. I really liked his portfolio and, he offers a discount for self-publish authors, which is very nice of him.&lt;/p&gt;
&lt;p&gt;I also hired professionals to check the text for mistakes and grammar. This is particular important as grammar mistakes are normal and expected in large documents. But, selecting a reviewer was an interactive process. I searched the web and hired tree different reviewers and offered them three different chapters of the book. Once I had all revisions, I selected the reviewer the offered the best result and sent him the rest of the chapters. You can find his site &lt;a href=&#34;http://revisaotextual.com.br/&#34;&gt;here&lt;/a&gt;. I’m glad I did this way, It would be a nightmare if I hired the wrong person to do this job.&lt;/p&gt;
&lt;p&gt;The main advantage of self publication is that the royalties for the author are higher and the cost to publish are lower. This setup translates into a lower price of the book and more sells. Specific to Brazil, where the exchange rate of dollar to Real (the Brazilian currency) is very unfavourable, it makes sense to offer a lower priced book. This way, it is easier for students and instructor to acquire and use the book.&lt;/p&gt;
&lt;p&gt;Since ebooks is a growing market, you can find lots of tutorials about this topic in the internet, &lt;a href=&#34;https://www.cnet.com/how-to/how-to-self-publish-an-ebook/&#34;&gt;like this one&lt;/a&gt; and &lt;a href=&#34;http://www.thecreativepenn.com/how-to-self-publish-an-ebook/&#34;&gt;this one&lt;/a&gt;. The problem here is that they are mostly about self-publishing &lt;em&gt;text&lt;/em&gt; ebooks, as in fiction stories. The only article I’ve found about self-publishing technical books is &lt;a href=&#34;http://cacm.acm.org/magazines/2015/2/182651-do-it-yourself-textbook-publishing/abstract#&#34;&gt;this one&lt;/a&gt;, where the author describe their rather good experience in publishing a software-engineering textbook.&lt;/p&gt;
&lt;p&gt;I checked &lt;a href=&#34;https://www.lulu.com/&#34;&gt;Lulu&lt;/a&gt;, &lt;a href=&#34;https://www.smashwords.com/&#34;&gt;Smashwords&lt;/a&gt; and &lt;a href=&#34;https://kdp.amazon.com/&#34;&gt;Amazon KDP&lt;/a&gt;. What made my choice towards Amazon was that it was a established platform, where almost everyone is registered. Buying an Ebook in Amazon is just one click away. Also, I’ve found that the KDP (self publish) program of Amazon is quite good. If the ebook sells for less than 9 dollars and is enrolled in the &lt;a href=&#34;https://www.amazon.com/Browse-Kindle-Unlimited-Books/b?ie=UTF8&amp;amp;node=9069934011&#34;&gt;Amazon unlimited program&lt;/a&gt;, the author gets 70 percent of the sticker price in royalties, which is a nice percentage! A bit of information, the normal royalty rate for an author of a publishing company is around 5-10 percent of the book price. Just a quick comparison, for each ebook sold at 9 USD, the author gets 6.3 USD (0.70 times 9). In other scenario, assuming an author has a publisher that offered 10 percent royalty, you would get the same royalty for a a book priced at 63 USD (6.3/0.1). The big difference here is that a 9 USD ebook sells a lot more than a 63 USD ebook, resulting in higher royalties and higher impact. More people read your book and you make more money. My only disappointment with Amazon is that the printed books are shipped from the USA. A buyer of the printed book in Brazil will need to wait at least 10-15 days to get the book. But, overall, I find this to be a small cost to bear.&lt;/p&gt;
&lt;p&gt;When the final version of the content of the book was ready, I started to organize everything I needed in order to publish the book. This is the list:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;A ISBN number - A unique id that indexes your book, one for the ebook and another for the print version. In order to get an ISBN, you need to find the &lt;a href=&#34;https://www.isbn-international.org/&#34;&gt;representation of ISBN in your country&lt;/a&gt;. Amazon also offers their own ISBN, but I don’t advise to use it. Having your own ISBN gives you more control. Just get one yourself. It is easy and cheap. In my case, I sent the request from the &lt;a href=&#34;http://www.isbn.bn.br/website/&#34;&gt;website&lt;/a&gt; by filling up forms in less than 10 minutes and got the number in five days.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Cover - The cover is processed as a figure file (.jpg). An important information here is that you need to define the size of you book and the number of pages at this stage. In my case, I used a 7x11 inches configuration for 200+ pages. It looks quite nice. Have a look:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://www.msperlin.com/post/2017-02-16-Writing-a-book_files/MyBook_printed.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;My Book and my spanish Iguana!&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Beautiful cover! Isn’t it? Once you have the figure file, you just add it to the &lt;em&gt;book creator&lt;/em&gt; system in amazon. At this stage, you will also need a summary about the book and its author and a picture for the back cover of the printed version.&lt;/p&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Registration in Amazon. The site asks you a lot of information. It took me at least half an hour to fill up the forms, which also includes tax details for us and non-us residents.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Description of the book. This is the text that goes in the webpage of the book in Amazon. In my case, I just used the same text as the back cover.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://sites.google.com/view/r-financas/p%C3%A1gina-inicial&#34;&gt;A book site&lt;/a&gt;. I wanted to distribute the code from the book and also exercises over the web. I used &lt;a href=&#34;https://sites.google.com/&#34;&gt;Google Sites&lt;/a&gt;, but I’m sure you have plenty of options here. On a side note, I’m also considering writing a CRAN package for distributing this content.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For the ebook, the next step is easy. Just upload the cover, the &lt;code&gt;.epub&lt;/code&gt; file from &lt;code&gt;bookdown&lt;/code&gt;, write the description and other details and you are good to go. With everything ready to go, you can check the ebook page by page with the online viewer. I didn’t have any problems at this stage. As for the print version, it is far more complicated. In my case, I used the pdf file to build the printed version. Once you upload the pdf, you can check the result in a online viewer. This is the final proof of the book and shows how it would look like when printed. There are lots of error checking from the system and, if you got an error, you cannot publish the book. I’ve spent a lot of time formatting everything so that the book comes out perfectly. The problem is that, each attempt to solve errors demanded processing time. At least 10 minutes to reach the whole cycle of compiling the pdf, uploading and checking the result. So, every time I tried to solve an error, I got the result 10 minutes later. I repeated this process over and over until I had a perfect book.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-publication&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The publication&lt;/h2&gt;
&lt;p&gt;The book was launched in the sixth of February 2017. I advertised it in here, my blog, Facebook and email. I was very surprised with the strong reception. In the first and second day, it became the &lt;em&gt;best seller&lt;/em&gt; book in the section of finance in the Brazilian Amazon. I am really happy for the success of the book. Right now, the sales have gone down, which is normal and expected, but I’m getting all sorts of good responses. What surprised me is that, even though the book was published primarily for Brazil, I’m receiving lots of replies (and sales) of people from other Portuguese speaking countries such as Cabo Verde and Portugal!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;some-advices&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Some advices&lt;/h2&gt;
&lt;p&gt;If I could go back in time and advice myself about the book, this is what I would have said. I hope these advices are helpful for others as well.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;From the first version, make up your mind about book size and letter size. This decision will impact everything else. Problems are easier to detect and solve if you stick to a single format.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;RStudio and &lt;code&gt;bookdown&lt;/code&gt; are your friends. I’m not aware of any other free platform that offers anything like it for developing a technical book.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;When possible, use &lt;code&gt;tidy=TRUE&lt;/code&gt; in the chunks of code. This simple command forces the code within the boundaries of the pdf. Sometimes it doesn’t look good so you always need to mannualy check the chunks with lots of code.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Avoid using function &lt;code&gt;str&lt;/code&gt; in the content. For some reason, it does not respect the boundaries of the page. There is a solution but it would not look good in the book.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use a dark theme for writing. Your eyes will hurt less and you will be able to write more.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Talk to people that understands the material you are writing about. Listen to their advices and make changes when necessary. Don’t over commit to sections that you are not sure will be included.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For all figure files in your book, always get the highest possible resolution (at least 300 dpi). Amazon will not let you publish figures with low resolution.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Don’t even try to do yourself the book cover or grammar check. Hire someone to do it for you. Your future self will thank you later!&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;whats-next&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Whats next?&lt;/h2&gt;
&lt;p&gt;I really enjoyed the experience of self-publishing a book and I strongly advise for anyone to give it a try. A cautionary note, &lt;strong&gt;I never worked with a established publisher and, therefore, I cannot talk about how it is or compare it to self-publish&lt;/strong&gt;. If someone has had that experience, fell free to use the comments to discuss it.&lt;/p&gt;
&lt;p&gt;The impact of a technical book is uncertain. Only time will tell if the book is successful or not. I have high hopes though. The feedback from the community has been strongly positive. I also have been working on extra material such as exercises and slides that are going to be distributed for free. This should motivate professors to use the book in class and increase distribution.&lt;/p&gt;
&lt;p&gt;I hope this post was helpful and enlightening for potential authors. Comments or suggestions, please use the comment section or drop me an email at &lt;a href=&#34;marceloperlin@gmail.com&#34;&gt;marceloperlin@gmail.com&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Best,
Marcelo.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Using R to study tennis players</title>
      <link>https://www.msperlin.com/post/2017-02-13-r-and-tennis-players/</link>
      <pubDate>Mon, 13 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2017-02-13-r-and-tennis-players/</guid>
      <description>


&lt;p&gt;In the previous post about tennis, we studied how changes in ball’s composition in hard and grass courts affected the game back in 2000. In this post, we will analyse a different dataset from the same repository and look at the players winning records in ATP matches.&lt;/p&gt;
&lt;div id=&#34;the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The data&lt;/h2&gt;
&lt;p&gt;I’m again using the great repository of tennis data of &lt;a href=&#34;https://github.com/JeffSackmann/&#34;&gt;Jeff Sackmann&lt;/a&gt;. In this case, however, I’m using the &lt;a href=&#34;https://github.com/JeffSackmann/tennis_atp&#34;&gt;ATP repository&lt;/a&gt; that contains ATP match data since 1968 until today. Again, I thank Jeff Sackmann for making this dataset publicly available.&lt;/p&gt;
&lt;p&gt;First, let’s download and unzip the dataset. This is a large file with 35MB and it takes some time.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;zip.file &amp;lt;- &amp;#39;TennisData_ATP.zip&amp;#39;

# download file
if (!file.exists(zip.file)){
  download.file(&amp;#39;https://github.com/JeffSackmann/tennis_atp/archive/master.zip&amp;#39;, destfile = zip.file)
  
}

# unzip it
dir.out &amp;lt;- &amp;#39;tennis_atp-master/&amp;#39;
if (!dir.exists(dir.out)) unzip(zip.file)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Lets have a look at the contents of the zip file.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my.f &amp;lt;- list.files(dir.out, pattern = &amp;#39;*.csv&amp;#39;, full.names = T)
print(my.f)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   [1] &amp;quot;tennis_atp-master//atp_matches_1968.csv&amp;quot;           
##   [2] &amp;quot;tennis_atp-master//atp_matches_1969.csv&amp;quot;           
##   [3] &amp;quot;tennis_atp-master//atp_matches_1970.csv&amp;quot;           
##   [4] &amp;quot;tennis_atp-master//atp_matches_1971.csv&amp;quot;           
##   [5] &amp;quot;tennis_atp-master//atp_matches_1972.csv&amp;quot;           
##   [6] &amp;quot;tennis_atp-master//atp_matches_1973.csv&amp;quot;           
##   [7] &amp;quot;tennis_atp-master//atp_matches_1974.csv&amp;quot;           
##   [8] &amp;quot;tennis_atp-master//atp_matches_1975.csv&amp;quot;           
##   [9] &amp;quot;tennis_atp-master//atp_matches_1976.csv&amp;quot;           
##  [10] &amp;quot;tennis_atp-master//atp_matches_1977.csv&amp;quot;           
##  [11] &amp;quot;tennis_atp-master//atp_matches_1978.csv&amp;quot;           
##  [12] &amp;quot;tennis_atp-master//atp_matches_1979.csv&amp;quot;           
##  [13] &amp;quot;tennis_atp-master//atp_matches_1980.csv&amp;quot;           
##  [14] &amp;quot;tennis_atp-master//atp_matches_1981.csv&amp;quot;           
##  [15] &amp;quot;tennis_atp-master//atp_matches_1982.csv&amp;quot;           
##  [16] &amp;quot;tennis_atp-master//atp_matches_1983.csv&amp;quot;           
##  [17] &amp;quot;tennis_atp-master//atp_matches_1984.csv&amp;quot;           
##  [18] &amp;quot;tennis_atp-master//atp_matches_1985.csv&amp;quot;           
##  [19] &amp;quot;tennis_atp-master//atp_matches_1986.csv&amp;quot;           
##  [20] &amp;quot;tennis_atp-master//atp_matches_1987.csv&amp;quot;           
##  [21] &amp;quot;tennis_atp-master//atp_matches_1988.csv&amp;quot;           
##  [22] &amp;quot;tennis_atp-master//atp_matches_1989.csv&amp;quot;           
##  [23] &amp;quot;tennis_atp-master//atp_matches_1990.csv&amp;quot;           
##  [24] &amp;quot;tennis_atp-master//atp_matches_1991.csv&amp;quot;           
##  [25] &amp;quot;tennis_atp-master//atp_matches_1992.csv&amp;quot;           
##  [26] &amp;quot;tennis_atp-master//atp_matches_1993.csv&amp;quot;           
##  [27] &amp;quot;tennis_atp-master//atp_matches_1994.csv&amp;quot;           
##  [28] &amp;quot;tennis_atp-master//atp_matches_1995.csv&amp;quot;           
##  [29] &amp;quot;tennis_atp-master//atp_matches_1996.csv&amp;quot;           
##  [30] &amp;quot;tennis_atp-master//atp_matches_1997.csv&amp;quot;           
##  [31] &amp;quot;tennis_atp-master//atp_matches_1998.csv&amp;quot;           
##  [32] &amp;quot;tennis_atp-master//atp_matches_1999.csv&amp;quot;           
##  [33] &amp;quot;tennis_atp-master//atp_matches_2000.csv&amp;quot;           
##  [34] &amp;quot;tennis_atp-master//atp_matches_2001.csv&amp;quot;           
##  [35] &amp;quot;tennis_atp-master//atp_matches_2002.csv&amp;quot;           
##  [36] &amp;quot;tennis_atp-master//atp_matches_2003.csv&amp;quot;           
##  [37] &amp;quot;tennis_atp-master//atp_matches_2004.csv&amp;quot;           
##  [38] &amp;quot;tennis_atp-master//atp_matches_2005.csv&amp;quot;           
##  [39] &amp;quot;tennis_atp-master//atp_matches_2006.csv&amp;quot;           
##  [40] &amp;quot;tennis_atp-master//atp_matches_2007.csv&amp;quot;           
##  [41] &amp;quot;tennis_atp-master//atp_matches_2008.csv&amp;quot;           
##  [42] &amp;quot;tennis_atp-master//atp_matches_2009.csv&amp;quot;           
##  [43] &amp;quot;tennis_atp-master//atp_matches_2010.csv&amp;quot;           
##  [44] &amp;quot;tennis_atp-master//atp_matches_2011.csv&amp;quot;           
##  [45] &amp;quot;tennis_atp-master//atp_matches_2012.csv&amp;quot;           
##  [46] &amp;quot;tennis_atp-master//atp_matches_2013.csv&amp;quot;           
##  [47] &amp;quot;tennis_atp-master//atp_matches_2014.csv&amp;quot;           
##  [48] &amp;quot;tennis_atp-master//atp_matches_2015.csv&amp;quot;           
##  [49] &amp;quot;tennis_atp-master//atp_matches_2016.csv&amp;quot;           
##  [50] &amp;quot;tennis_atp-master//atp_matches_2017.csv&amp;quot;           
##  [51] &amp;quot;tennis_atp-master//atp_matches_2018.csv&amp;quot;           
##  [52] &amp;quot;tennis_atp-master//atp_matches_2019.csv&amp;quot;           
##  [53] &amp;quot;tennis_atp-master//atp_matches_futures_1991.csv&amp;quot;   
##  [54] &amp;quot;tennis_atp-master//atp_matches_futures_1992.csv&amp;quot;   
##  [55] &amp;quot;tennis_atp-master//atp_matches_futures_1993.csv&amp;quot;   
##  [56] &amp;quot;tennis_atp-master//atp_matches_futures_1994.csv&amp;quot;   
##  [57] &amp;quot;tennis_atp-master//atp_matches_futures_1995.csv&amp;quot;   
##  [58] &amp;quot;tennis_atp-master//atp_matches_futures_1996.csv&amp;quot;   
##  [59] &amp;quot;tennis_atp-master//atp_matches_futures_1997.csv&amp;quot;   
##  [60] &amp;quot;tennis_atp-master//atp_matches_futures_1998.csv&amp;quot;   
##  [61] &amp;quot;tennis_atp-master//atp_matches_futures_1999.csv&amp;quot;   
##  [62] &amp;quot;tennis_atp-master//atp_matches_futures_2000.csv&amp;quot;   
##  [63] &amp;quot;tennis_atp-master//atp_matches_futures_2001.csv&amp;quot;   
##  [64] &amp;quot;tennis_atp-master//atp_matches_futures_2002.csv&amp;quot;   
##  [65] &amp;quot;tennis_atp-master//atp_matches_futures_2003.csv&amp;quot;   
##  [66] &amp;quot;tennis_atp-master//atp_matches_futures_2004.csv&amp;quot;   
##  [67] &amp;quot;tennis_atp-master//atp_matches_futures_2005.csv&amp;quot;   
##  [68] &amp;quot;tennis_atp-master//atp_matches_futures_2006.csv&amp;quot;   
##  [69] &amp;quot;tennis_atp-master//atp_matches_futures_2007.csv&amp;quot;   
##  [70] &amp;quot;tennis_atp-master//atp_matches_futures_2008.csv&amp;quot;   
##  [71] &amp;quot;tennis_atp-master//atp_matches_futures_2009.csv&amp;quot;   
##  [72] &amp;quot;tennis_atp-master//atp_matches_futures_2010.csv&amp;quot;   
##  [73] &amp;quot;tennis_atp-master//atp_matches_futures_2011.csv&amp;quot;   
##  [74] &amp;quot;tennis_atp-master//atp_matches_futures_2012.csv&amp;quot;   
##  [75] &amp;quot;tennis_atp-master//atp_matches_futures_2013.csv&amp;quot;   
##  [76] &amp;quot;tennis_atp-master//atp_matches_futures_2014.csv&amp;quot;   
##  [77] &amp;quot;tennis_atp-master//atp_matches_futures_2015.csv&amp;quot;   
##  [78] &amp;quot;tennis_atp-master//atp_matches_futures_2016.csv&amp;quot;   
##  [79] &amp;quot;tennis_atp-master//atp_matches_futures_2017.csv&amp;quot;   
##  [80] &amp;quot;tennis_atp-master//atp_matches_futures_2018.csv&amp;quot;   
##  [81] &amp;quot;tennis_atp-master//atp_matches_futures_2019.csv&amp;quot;   
##  [82] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1978.csv&amp;quot;
##  [83] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1979.csv&amp;quot;
##  [84] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1980.csv&amp;quot;
##  [85] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1981.csv&amp;quot;
##  [86] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1982.csv&amp;quot;
##  [87] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1983.csv&amp;quot;
##  [88] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1984.csv&amp;quot;
##  [89] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1985.csv&amp;quot;
##  [90] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1986.csv&amp;quot;
##  [91] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1987.csv&amp;quot;
##  [92] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1988.csv&amp;quot;
##  [93] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1989.csv&amp;quot;
##  [94] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1990.csv&amp;quot;
##  [95] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1991.csv&amp;quot;
##  [96] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1992.csv&amp;quot;
##  [97] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1993.csv&amp;quot;
##  [98] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1994.csv&amp;quot;
##  [99] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1995.csv&amp;quot;
## [100] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1996.csv&amp;quot;
## [101] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1997.csv&amp;quot;
## [102] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1998.csv&amp;quot;
## [103] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1999.csv&amp;quot;
## [104] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2000.csv&amp;quot;
## [105] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2001.csv&amp;quot;
## [106] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2002.csv&amp;quot;
## [107] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2003.csv&amp;quot;
## [108] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2004.csv&amp;quot;
## [109] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2005.csv&amp;quot;
## [110] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2006.csv&amp;quot;
## [111] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2007.csv&amp;quot;
## [112] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2008.csv&amp;quot;
## [113] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2009.csv&amp;quot;
## [114] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2010.csv&amp;quot;
## [115] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2011.csv&amp;quot;
## [116] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2012.csv&amp;quot;
## [117] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2013.csv&amp;quot;
## [118] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2014.csv&amp;quot;
## [119] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2015.csv&amp;quot;
## [120] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2016.csv&amp;quot;
## [121] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2017.csv&amp;quot;
## [122] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2018.csv&amp;quot;
## [123] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2019.csv&amp;quot;
## [124] &amp;quot;tennis_atp-master//atp_players.csv&amp;quot;                
## [125] &amp;quot;tennis_atp-master//atp_rankings_00s.csv&amp;quot;           
## [126] &amp;quot;tennis_atp-master//atp_rankings_10s.csv&amp;quot;           
## [127] &amp;quot;tennis_atp-master//atp_rankings_70s.csv&amp;quot;           
## [128] &amp;quot;tennis_atp-master//atp_rankings_80s.csv&amp;quot;           
## [129] &amp;quot;tennis_atp-master//atp_rankings_90s.csv&amp;quot;           
## [130] &amp;quot;tennis_atp-master//atp_rankings_current.csv&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, same as with the other post, we see a lot of files. The names are quite suggesting and it is clear that not all files contains matches data. Let’s restrict the analysis just for the files with the string &lt;code&gt;atp_matches&lt;/code&gt;. This includes main matches, qualifications and futures games.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(stringr)

# restrict just for main atp matches
my.f &amp;lt;- my.f[str_detect(my.f, &amp;#39;matches&amp;#39;)]
my.f&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   [1] &amp;quot;tennis_atp-master//atp_matches_1968.csv&amp;quot;           
##   [2] &amp;quot;tennis_atp-master//atp_matches_1969.csv&amp;quot;           
##   [3] &amp;quot;tennis_atp-master//atp_matches_1970.csv&amp;quot;           
##   [4] &amp;quot;tennis_atp-master//atp_matches_1971.csv&amp;quot;           
##   [5] &amp;quot;tennis_atp-master//atp_matches_1972.csv&amp;quot;           
##   [6] &amp;quot;tennis_atp-master//atp_matches_1973.csv&amp;quot;           
##   [7] &amp;quot;tennis_atp-master//atp_matches_1974.csv&amp;quot;           
##   [8] &amp;quot;tennis_atp-master//atp_matches_1975.csv&amp;quot;           
##   [9] &amp;quot;tennis_atp-master//atp_matches_1976.csv&amp;quot;           
##  [10] &amp;quot;tennis_atp-master//atp_matches_1977.csv&amp;quot;           
##  [11] &amp;quot;tennis_atp-master//atp_matches_1978.csv&amp;quot;           
##  [12] &amp;quot;tennis_atp-master//atp_matches_1979.csv&amp;quot;           
##  [13] &amp;quot;tennis_atp-master//atp_matches_1980.csv&amp;quot;           
##  [14] &amp;quot;tennis_atp-master//atp_matches_1981.csv&amp;quot;           
##  [15] &amp;quot;tennis_atp-master//atp_matches_1982.csv&amp;quot;           
##  [16] &amp;quot;tennis_atp-master//atp_matches_1983.csv&amp;quot;           
##  [17] &amp;quot;tennis_atp-master//atp_matches_1984.csv&amp;quot;           
##  [18] &amp;quot;tennis_atp-master//atp_matches_1985.csv&amp;quot;           
##  [19] &amp;quot;tennis_atp-master//atp_matches_1986.csv&amp;quot;           
##  [20] &amp;quot;tennis_atp-master//atp_matches_1987.csv&amp;quot;           
##  [21] &amp;quot;tennis_atp-master//atp_matches_1988.csv&amp;quot;           
##  [22] &amp;quot;tennis_atp-master//atp_matches_1989.csv&amp;quot;           
##  [23] &amp;quot;tennis_atp-master//atp_matches_1990.csv&amp;quot;           
##  [24] &amp;quot;tennis_atp-master//atp_matches_1991.csv&amp;quot;           
##  [25] &amp;quot;tennis_atp-master//atp_matches_1992.csv&amp;quot;           
##  [26] &amp;quot;tennis_atp-master//atp_matches_1993.csv&amp;quot;           
##  [27] &amp;quot;tennis_atp-master//atp_matches_1994.csv&amp;quot;           
##  [28] &amp;quot;tennis_atp-master//atp_matches_1995.csv&amp;quot;           
##  [29] &amp;quot;tennis_atp-master//atp_matches_1996.csv&amp;quot;           
##  [30] &amp;quot;tennis_atp-master//atp_matches_1997.csv&amp;quot;           
##  [31] &amp;quot;tennis_atp-master//atp_matches_1998.csv&amp;quot;           
##  [32] &amp;quot;tennis_atp-master//atp_matches_1999.csv&amp;quot;           
##  [33] &amp;quot;tennis_atp-master//atp_matches_2000.csv&amp;quot;           
##  [34] &amp;quot;tennis_atp-master//atp_matches_2001.csv&amp;quot;           
##  [35] &amp;quot;tennis_atp-master//atp_matches_2002.csv&amp;quot;           
##  [36] &amp;quot;tennis_atp-master//atp_matches_2003.csv&amp;quot;           
##  [37] &amp;quot;tennis_atp-master//atp_matches_2004.csv&amp;quot;           
##  [38] &amp;quot;tennis_atp-master//atp_matches_2005.csv&amp;quot;           
##  [39] &amp;quot;tennis_atp-master//atp_matches_2006.csv&amp;quot;           
##  [40] &amp;quot;tennis_atp-master//atp_matches_2007.csv&amp;quot;           
##  [41] &amp;quot;tennis_atp-master//atp_matches_2008.csv&amp;quot;           
##  [42] &amp;quot;tennis_atp-master//atp_matches_2009.csv&amp;quot;           
##  [43] &amp;quot;tennis_atp-master//atp_matches_2010.csv&amp;quot;           
##  [44] &amp;quot;tennis_atp-master//atp_matches_2011.csv&amp;quot;           
##  [45] &amp;quot;tennis_atp-master//atp_matches_2012.csv&amp;quot;           
##  [46] &amp;quot;tennis_atp-master//atp_matches_2013.csv&amp;quot;           
##  [47] &amp;quot;tennis_atp-master//atp_matches_2014.csv&amp;quot;           
##  [48] &amp;quot;tennis_atp-master//atp_matches_2015.csv&amp;quot;           
##  [49] &amp;quot;tennis_atp-master//atp_matches_2016.csv&amp;quot;           
##  [50] &amp;quot;tennis_atp-master//atp_matches_2017.csv&amp;quot;           
##  [51] &amp;quot;tennis_atp-master//atp_matches_2018.csv&amp;quot;           
##  [52] &amp;quot;tennis_atp-master//atp_matches_2019.csv&amp;quot;           
##  [53] &amp;quot;tennis_atp-master//atp_matches_futures_1991.csv&amp;quot;   
##  [54] &amp;quot;tennis_atp-master//atp_matches_futures_1992.csv&amp;quot;   
##  [55] &amp;quot;tennis_atp-master//atp_matches_futures_1993.csv&amp;quot;   
##  [56] &amp;quot;tennis_atp-master//atp_matches_futures_1994.csv&amp;quot;   
##  [57] &amp;quot;tennis_atp-master//atp_matches_futures_1995.csv&amp;quot;   
##  [58] &amp;quot;tennis_atp-master//atp_matches_futures_1996.csv&amp;quot;   
##  [59] &amp;quot;tennis_atp-master//atp_matches_futures_1997.csv&amp;quot;   
##  [60] &amp;quot;tennis_atp-master//atp_matches_futures_1998.csv&amp;quot;   
##  [61] &amp;quot;tennis_atp-master//atp_matches_futures_1999.csv&amp;quot;   
##  [62] &amp;quot;tennis_atp-master//atp_matches_futures_2000.csv&amp;quot;   
##  [63] &amp;quot;tennis_atp-master//atp_matches_futures_2001.csv&amp;quot;   
##  [64] &amp;quot;tennis_atp-master//atp_matches_futures_2002.csv&amp;quot;   
##  [65] &amp;quot;tennis_atp-master//atp_matches_futures_2003.csv&amp;quot;   
##  [66] &amp;quot;tennis_atp-master//atp_matches_futures_2004.csv&amp;quot;   
##  [67] &amp;quot;tennis_atp-master//atp_matches_futures_2005.csv&amp;quot;   
##  [68] &amp;quot;tennis_atp-master//atp_matches_futures_2006.csv&amp;quot;   
##  [69] &amp;quot;tennis_atp-master//atp_matches_futures_2007.csv&amp;quot;   
##  [70] &amp;quot;tennis_atp-master//atp_matches_futures_2008.csv&amp;quot;   
##  [71] &amp;quot;tennis_atp-master//atp_matches_futures_2009.csv&amp;quot;   
##  [72] &amp;quot;tennis_atp-master//atp_matches_futures_2010.csv&amp;quot;   
##  [73] &amp;quot;tennis_atp-master//atp_matches_futures_2011.csv&amp;quot;   
##  [74] &amp;quot;tennis_atp-master//atp_matches_futures_2012.csv&amp;quot;   
##  [75] &amp;quot;tennis_atp-master//atp_matches_futures_2013.csv&amp;quot;   
##  [76] &amp;quot;tennis_atp-master//atp_matches_futures_2014.csv&amp;quot;   
##  [77] &amp;quot;tennis_atp-master//atp_matches_futures_2015.csv&amp;quot;   
##  [78] &amp;quot;tennis_atp-master//atp_matches_futures_2016.csv&amp;quot;   
##  [79] &amp;quot;tennis_atp-master//atp_matches_futures_2017.csv&amp;quot;   
##  [80] &amp;quot;tennis_atp-master//atp_matches_futures_2018.csv&amp;quot;   
##  [81] &amp;quot;tennis_atp-master//atp_matches_futures_2019.csv&amp;quot;   
##  [82] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1978.csv&amp;quot;
##  [83] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1979.csv&amp;quot;
##  [84] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1980.csv&amp;quot;
##  [85] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1981.csv&amp;quot;
##  [86] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1982.csv&amp;quot;
##  [87] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1983.csv&amp;quot;
##  [88] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1984.csv&amp;quot;
##  [89] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1985.csv&amp;quot;
##  [90] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1986.csv&amp;quot;
##  [91] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1987.csv&amp;quot;
##  [92] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1988.csv&amp;quot;
##  [93] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1989.csv&amp;quot;
##  [94] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1990.csv&amp;quot;
##  [95] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1991.csv&amp;quot;
##  [96] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1992.csv&amp;quot;
##  [97] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1993.csv&amp;quot;
##  [98] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1994.csv&amp;quot;
##  [99] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1995.csv&amp;quot;
## [100] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1996.csv&amp;quot;
## [101] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1997.csv&amp;quot;
## [102] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1998.csv&amp;quot;
## [103] &amp;quot;tennis_atp-master//atp_matches_qual_chall_1999.csv&amp;quot;
## [104] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2000.csv&amp;quot;
## [105] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2001.csv&amp;quot;
## [106] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2002.csv&amp;quot;
## [107] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2003.csv&amp;quot;
## [108] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2004.csv&amp;quot;
## [109] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2005.csv&amp;quot;
## [110] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2006.csv&amp;quot;
## [111] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2007.csv&amp;quot;
## [112] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2008.csv&amp;quot;
## [113] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2009.csv&amp;quot;
## [114] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2010.csv&amp;quot;
## [115] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2011.csv&amp;quot;
## [116] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2012.csv&amp;quot;
## [117] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2013.csv&amp;quot;
## [118] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2014.csv&amp;quot;
## [119] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2015.csv&amp;quot;
## [120] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2016.csv&amp;quot;
## [121] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2017.csv&amp;quot;
## [122] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2018.csv&amp;quot;
## [123] &amp;quot;tennis_atp-master//atp_matches_qual_chall_2019.csv&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, I used string matching function &lt;code&gt;str_detect&lt;/code&gt; from &lt;code&gt;stringr&lt;/code&gt; to find and keep just the csv files with the string &lt;em&gt;matches&lt;/em&gt; in its name. Now, let’s load all files into a single dataframe.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(readr)
library(dplyr)

# set cols (missing some)
my.cols &amp;lt;- cols(
  .default = col_integer(),
  tourney_id = col_character(),
  tourney_name = col_character(),
  surface = col_character(),
  tourney_level = col_character(),
  winner_entry = col_character(),
  winner_name = col_character(),
  winner_hand = col_character(),
  winner_ioc = col_character(),
  winner_age = col_double(),
  loser_entry = col_character(),
  loser_name = col_character(),
  loser_hand = col_character(),
  loser_ioc = col_character(),
  loser_age = col_double(),
  score = col_character(),
  round = col_character()
)

# load all files with lapply and do.call (some cols don&amp;#39;t match in all files)
df.matches &amp;lt;- do.call(bind_rows,lapply(my.f, read_csv, col_types = my.cols))

# create year column
df.matches$Date &amp;lt;- as.Date(as.character(df.matches$tourney_date),&amp;#39;%Y%m%d&amp;#39;)
df.matches$Year &amp;lt;- format(df.matches$Date,&amp;#39;%Y&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s see what the data offers.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(df.matches)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## tibble [752,552 × 51] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
##  $ tourney_id        : chr [1:752552] &amp;quot;1968-580&amp;quot; &amp;quot;1968-580&amp;quot; &amp;quot;1968-580&amp;quot; &amp;quot;1968-580&amp;quot; ...
##  $ tourney_name      : chr [1:752552] &amp;quot;Australian Chps.&amp;quot; &amp;quot;Australian Chps.&amp;quot; &amp;quot;Australian Chps.&amp;quot; &amp;quot;Australian Chps.&amp;quot; ...
##  $ surface           : chr [1:752552] &amp;quot;Grass&amp;quot; &amp;quot;Grass&amp;quot; &amp;quot;Grass&amp;quot; &amp;quot;Grass&amp;quot; ...
##  $ draw_size         : int [1:752552] 64 64 64 64 64 64 64 64 64 64 ...
##  $ tourney_level     : chr [1:752552] &amp;quot;G&amp;quot; &amp;quot;G&amp;quot; &amp;quot;G&amp;quot; &amp;quot;G&amp;quot; ...
##  $ tourney_date      : int [1:752552] 19680119 19680119 19680119 19680119 19680119 19680119 19680119 19680119 19680119 19680119 ...
##  $ match_num         : int [1:752552] 1 2 3 4 5 6 7 8 9 10 ...
##  $ winner_id         : int [1:752552] 110023 109803 100257 100105 109966 107759 100101 100025 108519 109799 ...
##  $ winner_seed       : int [1:752552] NA NA NA 5 NA NA 12 3 NA NA ...
##  $ winner_entry      : chr [1:752552] NA NA NA NA ...
##  $ winner_name       : chr [1:752552] &amp;quot;Richard Coulthard&amp;quot; &amp;quot;John Brown&amp;quot; &amp;quot;Ross Case&amp;quot; &amp;quot;Allan Stone&amp;quot; ...
##  $ winner_hand       : chr [1:752552] &amp;quot;R&amp;quot; &amp;quot;R&amp;quot; &amp;quot;R&amp;quot; &amp;quot;R&amp;quot; ...
##  $ winner_ht         : int [1:752552] NA NA NA NA NA NA NA 173 NA NA ...
##  $ winner_ioc        : chr [1:752552] &amp;quot;AUS&amp;quot; &amp;quot;AUS&amp;quot; &amp;quot;AUS&amp;quot; &amp;quot;AUS&amp;quot; ...
##  $ winner_age        : num [1:752552] NA 27.5 16.2 22.3 29.9 ...
##  $ winner_rank       : int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ winner_rank_points: int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ loser_id          : int [1:752552] 107760 106964 110024 110025 110026 110027 110028 108430 110029 110030 ...
##  $ loser_seed        : int [1:752552] NA NA 15 NA NA NA NA NA NA NA ...
##  $ loser_entry       : chr [1:752552] NA NA NA NA ...
##  $ loser_name        : chr [1:752552] &amp;quot;Max Senior&amp;quot; &amp;quot;Ernie Mccabe&amp;quot; &amp;quot;Gondo Widjojo&amp;quot; &amp;quot;Robert Layton&amp;quot; ...
##  $ loser_hand        : chr [1:752552] &amp;quot;R&amp;quot; &amp;quot;R&amp;quot; &amp;quot;R&amp;quot; &amp;quot;R&amp;quot; ...
##  $ loser_ht          : int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ loser_ioc         : chr [1:752552] &amp;quot;AUS&amp;quot; &amp;quot;AUS&amp;quot; &amp;quot;INA&amp;quot; &amp;quot;AUS&amp;quot; ...
##  $ loser_age         : num [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ loser_rank        : int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ loser_rank_points : int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ score             : chr [1:752552] &amp;quot;12-10 7-5 4-6 7-5&amp;quot; &amp;quot;6-3 6-2 6-4&amp;quot; &amp;quot;6-4 3-6 6-3 7-5&amp;quot; &amp;quot;6-4 6-2 6-1&amp;quot; ...
##  $ best_of           : int [1:752552] 5 5 5 5 5 5 5 5 5 5 ...
##  $ round             : chr [1:752552] &amp;quot;R64&amp;quot; &amp;quot;R64&amp;quot; &amp;quot;R64&amp;quot; &amp;quot;R64&amp;quot; ...
##  $ minutes           : int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ w_ace             : int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ w_df              : int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ w_svpt            : int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ w_1stIn           : int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ w_1stWon          : int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ w_2ndWon          : int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ w_SvGms           : int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ w_bpSaved         : int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ w_bpFaced         : int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ l_ace             : int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ l_df              : int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ l_svpt            : int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ l_1stIn           : int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ l_1stWon          : int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ l_2ndWon          : int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ l_SvGms           : int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ l_bpSaved         : int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ l_bpFaced         : int [1:752552] NA NA NA NA NA NA NA NA NA NA ...
##  $ Date              : Date[1:752552], format: &amp;quot;1968-01-19&amp;quot; &amp;quot;1968-01-19&amp;quot; ...
##  $ Year              : chr [1:752552] &amp;quot;1968&amp;quot; &amp;quot;1968&amp;quot; &amp;quot;1968&amp;quot; &amp;quot;1968&amp;quot; ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, lots of information. Looks like the games are separated by rows, where the columns have a lot of information about the matches. This dataset is not as detailed as the last one with point by point data, but still quite impressive.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;looking-at-top-players-winning-percentages&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Looking at top players winning percentages&lt;/h1&gt;
&lt;p&gt;For our first analysis, lets look at the winning percentages of the top 10 players from the ATP rankings. For that, I will use package &lt;code&gt;rvest&lt;/code&gt; to scrape the information about the top ATP players from the &lt;a href=&#34;http://www.atpworldtour.com/en/rankings/singles&#34;&gt;ATP website&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rvest)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: xml2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;rvest&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &amp;#39;package:readr&amp;#39;:
## 
##     guess_encoding&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(stringr)

n.players &amp;lt;- 10

my.url &amp;lt;- &amp;#39;http://www.atpworldtour.com/en/rankings/singles&amp;#39;

atp.players &amp;lt;- read_html(my.url) %&amp;gt;%
  html_nodes(&amp;quot;.player-cell&amp;quot;) %&amp;gt;%
  html_text() %&amp;gt;%
  str_replace_all(&amp;#39;\\n&amp;#39;,&amp;#39;&amp;#39;) %&amp;gt;%
  str_trim()

name.player &amp;lt;- atp.players[1:n.players]
print(name.player)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Novak Djokovic&amp;quot;     &amp;quot;Rafael Nadal&amp;quot;       &amp;quot;Dominic Thiem&amp;quot;     
##  [4] &amp;quot;Roger Federer&amp;quot;      &amp;quot;Daniil Medvedev&amp;quot;    &amp;quot;Stefanos Tsitsipas&amp;quot;
##  [7] &amp;quot;Alexander Zverev&amp;quot;   &amp;quot;Matteo Berrettini&amp;quot;  &amp;quot;Gael Monfils&amp;quot;      
## [10] &amp;quot;David Goffin&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, we have to usual suspects. Novak Djokovic is now leading in the first position, which was held previously by Djokovic for a long period of time. I really like to see Dominic Thiem in the top ten as he is the youngest with 23 year, a solid game, and lots of potential. Federer is the oldest of the list, with 35 years old, but the most talented. It is amazing how he can still stay competitive given the age difference.&lt;/p&gt;
&lt;p&gt;Back to the R analysis, a problem with this approach of scraping the names from the ATP website is that they don’t necessarily match the names in the ATP files. As an example, the swiss player &lt;em&gt;Stan Wawrinka&lt;/em&gt; is named &lt;em&gt;Stanislas Wawrinka&lt;/em&gt; in the csv files, while in the ATP website is &lt;em&gt;Stan Wawrinka&lt;/em&gt;. This means that directly trying to match the names in &lt;code&gt;name.player&lt;/code&gt; with the names in &lt;code&gt;df.matches&lt;/code&gt; may not work. This is classic case of data from difference sources that don’t share the same unique identifiers.&lt;/p&gt;
&lt;p&gt;I usually solve this problem using a lookup table built manually in a csv file, where I store the matching identifiers in the different datasets. If the number of unique cases is small, it is quite doable. For this analysis, however, we have 13491 players, which is definitely too much. Manually creating a lookup table would be very demanding.&lt;/p&gt;
&lt;p&gt;The solution I often in this case is to make the computer look for the best &lt;em&gt;imperfect match&lt;/em&gt; among the different identifiers (names). This is also known as calculating &lt;strong&gt;string distances&lt;/strong&gt; - the number of require edits so that a string matches other, and can be accomplished in many different ways. In this example I’ll use function &lt;code&gt;amatch&lt;/code&gt; from package &lt;code&gt;stringdist&lt;/code&gt;, with the basic options.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(stringdist)

# get unique names from losers and winners
unique.players &amp;lt;- unique(c(df.matches$winner_name, 
                           df.matches$loser_name ))

# find the index of the closest string for each name in name.player
idx &amp;lt;- amatch(name.player, unique.players, maxDist = 5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Lets look at the result:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(data.frame(name.from.web = name.player,
                 name.from.atp = unique.players[idx] ))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         name.from.web      name.from.atp
## 1      Novak Djokovic     Novak Djokovic
## 2        Rafael Nadal       Rafael Nadal
## 3       Dominic Thiem      Dominic Thiem
## 4       Roger Federer      Roger Federer
## 5     Daniil Medvedev    Daniil Medvedev
## 6  Stefanos Tsitsipas Stefanos Tsitsipas
## 7    Alexander Zverev   Alexander Zverev
## 8   Matteo Berrettini  Matteo Berrettini
## 9        Gael Monfils       Gael Monfils
## 10       David Goffin       David Goffin&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Beautiful! For our case of just 10 players, it worked perfectly. The name of Stan Wawrinka_ was matched correctly. Be aware, however, that this procedure of string matching is not guaranteed to work 100% of the cases. You could also set NA values using the options in &lt;code&gt;amatch&lt;/code&gt; but it is still not guaranteed to work well. You should always manually check the result.&lt;/p&gt;
&lt;p&gt;Going forward, let’s copy the players name from one to the other and use a loop and &lt;code&gt;dplyr&lt;/code&gt; to calculate yearly winning percentages of each player, also separating by the type of surface. Using a loop here might look odd, but this was the simplest solution I’ve found as you cannot use &lt;code&gt;dplyr&lt;/code&gt; directly. The dataframe &lt;code&gt;df.matches&lt;/code&gt; is unique in the sense that it has two informations in each row, you have a win for someone and a loss to another player (see columns &lt;code&gt;winner_name&lt;/code&gt; and &lt;code&gt;loser_name&lt;/code&gt;). If I use &lt;code&gt;dplyr&lt;/code&gt; directly, I would miss the games where two players in the list played each other. There is probably a way to adjust the dataframe, but I just find it easier to loop over the players.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# copy players name
name.player &amp;lt;- unique.players[idx]

# create table with players
my.tab &amp;lt;- tibble()
for (i.player in name.player) {
  
  temp &amp;lt;- filter(df.matches, (winner_name==i.player)|(loser_name==i.player))
  temp$Name &amp;lt;- i.player
  temp.tab &amp;lt;- temp %&amp;gt;% 
    group_by(Name, Year,surface) %&amp;gt;%
    summarise(`Percentage of wins` = sum(winner_name == Name)/n(),
              `Number of matches` = n()) %&amp;gt;%
    filter(`Number of matches` &amp;gt; 0 ) %&amp;gt;%
    filter(surface %in% c(&amp;#39;Hard&amp;#39;,&amp;#39;Clay&amp;#39;))
  
  my.tab &amp;lt;- bind_rows(my.tab,
                      temp.tab)
    
}

# use atp ranking in names e.g. Andy Murray (1)
my.tab$Name &amp;lt;- paste0(my.tab$Name, 
                      &amp;#39; (&amp;#39;, 
                      match(my.tab$Name, name.player),
                      &amp;#39;)&amp;#39; )

my.tab &amp;lt;- my.tab[complete.cases(my.tab), ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Lets plot it!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

p &amp;lt;- ggplot(my.tab, aes(x = as.numeric(Year), y = `Percentage of wins`, color=surface))
p &amp;lt;- p + geom_point() + geom_smooth()
p &amp;lt;- p + facet_grid(surface~Name)
p &amp;lt;- p + ylim(c(0.25,1)) + xlim(c(2005,2016))
print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2017-02-13-R-and-Tennis-Players_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can see a few patterns. First, the winning consistency of top ten player is higher in hard courts. For example, look at Murray and Djokovic. It is easier for them to keep the same proportion of wins in hard courts than it is in clay. My best guess is that hard courts are more predictable and the ball is faster and bounces lower, making it easier for top players to hit winners and other point-finishing strokes such as drop shots. Be aware that this could also be due to the different number of matches in each court. We could test the difference of volatility statistically but I rather keep the analysis simple and visual.&lt;/p&gt;
&lt;p&gt;Also, not surprisingly, Nadal, &lt;a href=&#34;https://www.youtube.com/watch?v=7mknZrjakM8&#34;&gt;the king of clay&lt;/a&gt;, presents the highest winning percentage in clay, before 2012. His game strategy uses strength and heavy top spin balls that are difficult to counter. See &lt;a href=&#34;https://www.quora.com/Why-is-Nadal-so-dominant-on-clay&#34;&gt;here&lt;/a&gt; for a more detailed analysis on why he is so dominant on clay. The bad side of his strategy and type of play is that it is based heavily on his muscular strength. As his age increases, it is difficult to maintain the same level. This explains the increased proportion of defeats after 2012.&lt;/p&gt;
&lt;p&gt;The effect of age is also perceived for Roger Federer. But, given that his style of play is not based just on strength, I think that he can still beat a lot of players. Just look at the his recent title win at the 2017 Australian open.&lt;/p&gt;
&lt;p&gt;Now, look how Dojokovic is consistent in clay and hard courts. He is definitely the player with the best stats. I predict that, if he works for it, he will have no problem in taking the #1 spot once again from Murray.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;looking-at-brazilian-tennis-players&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Looking at Brazilian tennis players&lt;/h1&gt;
&lt;p&gt;In this section we will analyse the stats of Brazilian tennis players in ATP rankings. The following code can be easily executed for any country as the data is scraped from the ATP website. Just change the object &lt;code&gt;my.country&lt;/code&gt; for your case.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my.country &amp;lt;- &amp;#39;BRA&amp;#39;
n.players &amp;lt;- 5
my.url &amp;lt;- paste0(&amp;#39;http://www.atpworldtour.com/en/rankings/singles?rankDate=2017-02-06&amp;amp;rankRange=0-500&amp;amp;countryCode=&amp;#39;,my.country)

atp.players &amp;lt;- read_html(my.url) %&amp;gt;%
  html_nodes(&amp;quot;.player-cell&amp;quot;) %&amp;gt;%
  html_text() %&amp;gt;%
  str_replace_all(&amp;#39;\\n&amp;#39;,&amp;#39;&amp;#39;) %&amp;gt;%
  str_trim()

name.player &amp;lt;- atp.players[1:n.players]
name.player&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Thiago Monteiro&amp;quot;     &amp;quot;Rogerio Dutra Silva&amp;quot; &amp;quot;Thomaz Bellucci&amp;quot;    
## [4] &amp;quot;Joao Souza&amp;quot;          &amp;quot;Andre Ghem&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The top five Brazilian players in ATP are Thiago Monteiro, Rogerio Dutra Silva, Thomas Belluci, João Souza and Andre Ghem, in that order. We should be proud of all of them. I can only imagine the dedication and effort necessary to be a professional tennis player. You can see more details about each &lt;a href=&#34;http://www.atpworldtour.com/en/rankings/singles?rankDate=2017-02-06&amp;amp;rankRange=1-5000&amp;amp;countryCode=BRA&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;At this point, it makes sense to create a function to analyse the dataframe, as we will use it again later.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot.winning.perc &amp;lt;- function(name.player, 
                              df.matches, 
                              min.games.per.year = 0,
                              min.year = 2005,
                              max.year = 2016){
  require(stringdist)
  require(stringr)
  require(dplyr)
  require(ggplot2)
  
  # create year column
  df.matches$Date &amp;lt;- as.Date(as.character(df.matches$tourney_date),&amp;#39;%Y%m%d&amp;#39;)
  df.matches$Year &amp;lt;- format(df.matches$Date,&amp;#39;%Y&amp;#39;)
  
  # get unique names from losers and winners
  unique.players &amp;lt;- unique(c(df.matches$winner_name, 
                             df.matches$loser_name ))
  
  # find the index of the closest string for each name in name.player
  idx &amp;lt;- amatch(name.player, unique.players, maxDist = 5)
  #print(data.frame(name.from.web = name.player,
   #                name.from.atp = unique.players[idx] ))
  
  my.tab &amp;lt;- tibble()
  for (i.player in name.player) {
    
    temp &amp;lt;- filter(df.matches, (winner_name==i.player)|(loser_name==i.player))
    temp$Name &amp;lt;- i.player
    temp.tab &amp;lt;- temp %&amp;gt;% 
      group_by(Name, Year,surface) %&amp;gt;%
      summarise(`Percentage of wins` = sum(winner_name == Name)/n(),
                `Number of matches` = n()) %&amp;gt;%
      filter(`Number of matches` &amp;gt; min.games.per.year ) %&amp;gt;%
      filter(surface %in% c(&amp;#39;Hard&amp;#39;,&amp;#39;Clay&amp;#39;))
    
    my.tab &amp;lt;- bind_rows(my.tab,
                        temp.tab)
    
  }
  
  p &amp;lt;- ggplot(my.tab, aes(x = as.numeric(Year), y = `Percentage of wins`, color=surface))
  p &amp;lt;- p + geom_point() + geom_smooth()
  p &amp;lt;- p + facet_grid(surface~Name)
  p &amp;lt;- p + ylim(c(0.25,1)) + xlim(c(min.year,max.year))
  
  return(p)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we use the previous function for the new names of players.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# plot winnign percentages
p &amp;lt;- plot.winning.perc(name.player, df.matches)
print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2017-02-13-R-and-Tennis-Players_files/figure-html/brplayers-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;From this list, the youngest Brazilian player, and with most potential in my opinion, is Thiago Monteiro. He is 22 and has lots of time to improve his game. In 2016 he beated Tsonga in a great match &lt;a href=&#34;http://www.atpworldtour.com/en/news/monteiro-upsets-tsonga-in-rio-de-janeiro&#34;&gt;here in Brazil&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;the-records-of-guga-gustavo-kurten&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The records of Guga (Gustavo Kurten)&lt;/h2&gt;
&lt;p&gt;For last, lets look at stats of the the best and most cherished singles player from Brazil, &lt;a href=&#34;https://en.wikipedia.org/wiki/Gustavo_Kuerten&#34;&gt;Gustavo Kuerten - Guga&lt;/a&gt;. Guga is internationally famous and reached #1 in the ATP ranking in 2000. A very charismatic player, with a fantastic backhand. It is not far fetched to say that Guga brought Tennis to Brazil, making it a more popular sport.&lt;/p&gt;
&lt;p&gt;Guga had a hip injury back in 2001. He tried surgery, but it didn’t worked out and he wasn’t able to maintain the higher level of tennis that is necessary in the professional circuit. He retired in february of 2008. His story is very inspiring, growing up in the state of Santa Catarina, in a time where tennis was not a popular sport in Brazil and funding opportunities were scarce. His &lt;a href=&#34;https://www.amazon.com/Gustavo-Kuerten/e/B00VOUXHS2&#34;&gt;biography (in portuguese)&lt;/a&gt; is an excellent read.&lt;/p&gt;
&lt;p&gt;Let’s have a look in the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;name.player &amp;lt;- &amp;#39;Gustavo Kuerten&amp;#39;

p &amp;lt;- plot.winning.perc(name.player, df.matches, min.year = 1990)
print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2017-02-13-R-and-Tennis-Players_files/figure-html/guga-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As expected, a winning journey until 2001, when losses start to accumulate.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conlusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conlusion&lt;/h2&gt;
&lt;p&gt;The data repository of Jeff Sackmann is great. I really only scratched the surface with some simple graphical analysis. I think there is a lot of space for modeling as well, that is, creating a model that can predict the winning records of a player. I’m thinking about an econometric model using historical statistics of players such as past winning records, forehand/backhand winners, and so on. But I’m sure you can use other approaches as well.&lt;/p&gt;
&lt;p&gt;From the computational side, it would be interesting to create a CRAN package to analyse this dataset. Just like in this post, all data could be fetched from the ATP website and the repository of Jeff. One could check the winning records of players with just a simple function call. I just checked and there is nothing like it in CRAN. A shiny app would also be interesting. I’ll keep it in mind for the future.&lt;/p&gt;
&lt;p&gt;I hope you liked this post. Any comments or suggestions, please share in the comments section.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Building and maintaining exams with dynamic content</title>
      <link>https://www.msperlin.com/post/2017-01-30-exams-with-dynamic-content/</link>
      <pubDate>Mon, 30 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2017-01-30-exams-with-dynamic-content/</guid>
      <description>


&lt;p&gt;Part of my job as a researcher and teacher is to periodically apply and grade exams in my classroom. Being constantly in the shoes of an examiner, you soon quickly realize that students are clever in finding ways to do well in an exam without effort. These days, photos and pdf versions of past exams and exercises are shared online in facebook, whatsapp groups, instagram and what not. As weird as it may sound, the distribution of information in the digital era creates a problem for examiners. If you use the same exam from past year, it is likely that students will simply memorize the answers from a digital record. Moreover, some students will also cheat by looking for answers during the test. Either way, keeping the same exam over time and across students, is not advisable.&lt;/p&gt;
&lt;p&gt;This issue really bothered me. For large classes, there isn’t a way to evaluate the work of students as cost effective as online or printed exams. I’m strongly in favor of meritocracy in academia and I think that a grade in an exam should, on average, be good indicator of the knowledge that the students retained during coursework. Otherwise, what’s the point of doing all of it?&lt;/p&gt;
&lt;p&gt;In the past, I manually created different versions of questions and wrote new ones in order to avoid cheating and memorization of questions. But, year after year, it became clear to me that this was a time consuming task that took more energy than what I would like to invest. Besides teaching, I also do research and work on administrative issues within my department. Sometimes, specially around deadlines, you simply don’t have the time and mental energy to come up with different versions of an existing exam.&lt;/p&gt;
&lt;p&gt;Back in 2016 I decided to invest some to time to automatize this process and try to come up with an elegant solution. Since I had all my exams in a latex template called &lt;code&gt;examdesign&lt;/code&gt;, I wrote package &lt;a href=&#34;https://CRAN.R-project.org/package=RndTexExams&#34;&gt;RndTexExams&lt;/a&gt; that took as input a .tex file and created &lt;code&gt;n&lt;/code&gt; versions of exams by randomly defining the order of questions, the answer list and textual content based on a simple markup language. If you know latex, it is basically a problem of finding regex patterns and restructuring a character object that is later saved in a new and compilable latex file.&lt;/p&gt;
&lt;p&gt;The package I wrote worked pretty well for me but, as with any first version of a software, it had missing features. The output was only a pdf file based on a template, it did not work with standard academic platforms such as Blackboard and Moodle and, the most problematic in my opinion, it was not designed to run embedded R code that could be parsed by &lt;code&gt;knitr&lt;/code&gt;, like in a Rmarkdown file.&lt;/p&gt;
&lt;p&gt;This is when I tried out the package &lt;a href=&#34;https://CRAN.R-project.org/package=exams&#34;&gt;exams&lt;/a&gt;. While my solution with &lt;code&gt;RndTexExams&lt;/code&gt; was alright for a latex user, package exams is much better at solving the problem of dynamic content in exams. Using the &lt;code&gt;knitr&lt;/code&gt; and &lt;code&gt;sweave&lt;/code&gt; engines, the level of randomization and creation of dynamic content is really amazing. By combining R code (and all the capabilities of CRAN packages), you can do do anything your want in an exam. You can get information on the web, use completely different datasets for each exam and so on. The limit is set by your imagination.&lt;/p&gt;
&lt;div id=&#34;an-example-of-exam-with-dynamic-content&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;An example of exam with dynamic content&lt;/h2&gt;
&lt;p&gt;As a quick example, I am going to show one question from the exercise chapter of my book. When it is ready, I will be serving the exercises with a web based shiny app, meaning that the reader will download a pdf file with unique questions that is processed in a shiny server.&lt;/p&gt;
&lt;p&gt;In this example questions, I’m asking the reader to use R to solve the following problem:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;How many packages you can find today (2020-04-28) in CRAN?
Use repository https://cloud.r-project.org/ for the solution.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The solution is pretty simple, all you need to do is to ask for the number of rows for the object output from a call to &lt;code&gt;available.packages()&lt;/code&gt;. The reader can find the solution with the command &lt;code&gt;nrow(available.packages(repos=&#39;https://cloud.r-project.org/&#39;))&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now, lets build the content of this simple question in a separate file. You can either use .Rnw or .Rmd files with exam. I will choose the later just to keep it simple. Here are the contents of a file called &lt;strong&gt;Question.Rmd&lt;/strong&gt;, available &lt;a href=&#34;https://www.msperlin.com/files/Question.Rmd&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my.q.file &amp;lt;- &amp;#39;~/Dropbox/11-My Website/www.msperlin.com-static/files/Question.Rmd&amp;#39;
cat(paste0(readLines(my.q.file), collapse = &amp;#39;\n&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ```{r data generation, echo = FALSE, results = &amp;quot;hide&amp;quot;}
## #possible.repo &amp;lt;- getCRANmirrors()$URL  # doenst work well for all repos
## 
## possible.repo &amp;lt;- c(&amp;#39;https://cloud.r-project.org/&amp;#39;,
##                   &amp;#39;http://mirror.fcaglp.unlp.edu.ar/CRAN/&amp;#39;,
##                   &amp;#39;http://cran-r.c3sl.ufpr.br/&amp;#39;,
##                   &amp;#39;http://cran.stat.sfu.ca/&amp;#39;,
##                   &amp;#39;https://mirrors.dotsrc.org/cran/&amp;#39;,
##                   &amp;#39;https://mirrors.cicku.me/CRAN/&amp;#39;,
##                   &amp;#39;https://cran.ism.ac.jp/&amp;#39;)
## 
## my.repo &amp;lt;- sample(possible.repo,1)
## 
## n.pkgs &amp;lt;- nrow(available.packages(repos = my.repo))
## 
## sol.q &amp;lt;- n.pkgs
## rnd.vec &amp;lt;- c(0, sample(-5000:-1,4))
## 
## my.answers &amp;lt;- paste0(sol.q+rnd.vec, &amp;#39; packages&amp;#39;)
## ```
## 
## Question
## ========
## 
## How many packages you can find today (`r Sys.Date()`) in CRAN? 
## 
## Use repository `r my.repo` for the solution.
## 
## ```{r questionlist, echo = FALSE, results = &amp;quot;asis&amp;quot;}
## exams::answerlist(my.answers, markup = &amp;quot;markdown&amp;quot;)
## ```
## 
## Meta-information
## ================
## extype: schoice
## exsolution: 10000
## exname: numbero of cran pkgs
## exshuffle: TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the last piece of code, notice that I’ve set the solution of the question in object &lt;code&gt;sol.q&lt;/code&gt;. Later, in object &lt;code&gt;my.answers&lt;/code&gt;, I use it together with a random vector of integers to create five alternative answers to the questions, where the first one is the correct. This operation results in the following objects:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my.repo &amp;lt;- &amp;#39;https://cloud.r-project.org/&amp;#39;
n.pkgs &amp;lt;- nrow(available.packages(repos = my.repo))
  
sol.q &amp;lt;- n.pkgs
rnd.vec &amp;lt;- c(0, sample(-5000:-1,4))
  
my.answers &amp;lt;- paste0(sol.q+rnd.vec, &amp;#39; packages&amp;#39;)
print(my.answers)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;15557 packages&amp;quot; &amp;quot;12845 packages&amp;quot; &amp;quot;13153 packages&amp;quot; &amp;quot;13913 packages&amp;quot;
## [5] &amp;quot;13148 packages&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To conclude the question, I simply use &lt;code&gt;Sys.Date()&lt;/code&gt; to get the system’s date and later set the correct answers using function &lt;code&gt;answerlist&lt;/code&gt;. Some metadata is also inserted at the last section of &lt;code&gt;Question.Rmd&lt;/code&gt;. The line &lt;code&gt;exshuffle: TRUE&lt;/code&gt; sets a random order of possible answers in each exam for this questions. Do notice that the solution is registered in line &lt;code&gt;exsolution: 10000&lt;/code&gt;, where the 1 in 10000 means correct answer in the first element of &lt;code&gt;my.answers&lt;/code&gt; and the 0s represent incorrect answers.&lt;/p&gt;
&lt;p&gt;Now that the file with content of the question is finished, let’s set some options and build the exam with &lt;code&gt;exams&lt;/code&gt;. For simplicity, we will repeate the same question five times.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(exams)

my.f &amp;lt;- my.q.file
n.ver &amp;lt;- 1
name.exam &amp;lt;- &amp;#39;exam_sample&amp;#39;
my.dir &amp;lt;- paste0(&amp;#39;exam-out/&amp;#39;)

my.exam &amp;lt;- exams2pdf(file = rep(my.f,5),
                     n = n.ver, 
                     dir = my.dir,
                     name = name.exam, 
                     verbose = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Exams generation initialized.
## 
## Output directory: /home/msperlin/Desktop/testing/content/post/exam-out
## Exercise directory: /home/msperlin/Desktop/testing/content/post
## Supplement directory: /tmp/RtmpJtbGrM/file9e855ddbb636
## Temporary directory: /tmp/RtmpJtbGrM/file9e85555c5ce9
## Exercises: ~/Dropbox/11-My Website/www.msperlin.com-static/files/Question, ~/Dropbox/11-My Website/www.msperlin.com-static/files/Question, ~/Dropbox/11-My Website/www.msperlin.com-static/files/Question, ~/Dropbox/11-My Website/www.msperlin.com-static/files/Question, ~/Dropbox/11-My Website/www.msperlin.com-static/files/Question
## 
## Generation of individual exams.
## Exam 1: _Dropbox_11-My Website_www.msperlin.com-blog_static_files_Question (srt) _Dropbox_11-My Website_www.msperlin.com-blog_static_files_Question_1 (srt) _Dropbox_11-My Website_www.msperlin.com-blog_static_files_Question_2 (srt) _Dropbox_11-My Website_www.msperlin.com-blog_static_files_Question_3 (srt) _Dropbox_11-My Website_www.msperlin.com-blog_static_files_Question_4 (srt) ... w&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required namespace: tinytex&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  ... done.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f.out &amp;lt;- paste0(my.dir,name.exam,&amp;#39;1&amp;#39;,&amp;#39;.pdf&amp;#39;)
file.exists(f.out)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result of the previous code is a pdf file &lt;a href=&#34;https://www.msperlin.com/files/exam_sample1.pdf&#34;&gt;pdf file&lt;/a&gt; with the exam content.&lt;/p&gt;
&lt;p&gt;One interesting information from this post is that you can find a small difference in the number of packages in between the CRAN mirrors. My best guess is that they synchronize with the master server in different times of the day/week.&lt;/p&gt;
&lt;p&gt;Looking at the contents of the pdf file, clearly some things are missing from the exam, such as the title page and the instructions. You can add all the bells and whistles with the inputs of function &lt;code&gt;exams2pdf&lt;/code&gt; or change it directly in the different file templates. One quick tip for new users is that the answer sheet can be found by looping over the values of the output from &lt;code&gt;exams2pdf&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df.answer.key &amp;lt;- data.frame()
n.q &amp;lt;- 5 # number of questions
for (i.ver in seq(n.ver)){
  
  exam.now &amp;lt;- my.exam[[i.ver]] 
  
  for (i.q in seq(n.q)){
    
    sol.now &amp;lt;- letters[which(exam.now[[i.q]]$metainfo$solution)]
    
    temp &amp;lt;- data.frame(i.ver = i.ver, i.q = i.q, solution = sol.now)
    df.answer.key &amp;lt;- rbind(df.answer.key, temp)  
  }
  
}

df.answer.key.wide &amp;lt;- tidyr::spread(df.answer.key, key = i.q, value = solution)
df.answer.key.wide&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   i.ver 1 2 3 4 5
## 1     1 a a a a a&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By using package &lt;code&gt;exams2pdf&lt;/code&gt;, I can code different questions in the &lt;code&gt;exams&lt;/code&gt; format and not worry whether someone is going to copy it over and distribute it in the internet. Students may know the content of each question, but they will have to learn how to get to the correct answer in order to solve it for their exam. Cheating is also impossible since each student will have different versions and different answer sheets. If I have a class of 100 students, I will build 100 different exams, each one with unique answers.&lt;/p&gt;
&lt;p&gt;As for maintainability, the time value of my exam questions increases significantly. I can use them over and over, now that I can effortlessly create as many versions of it as I need. Since it is all based in R code, I can use the code from the class material in my exams. Going further, I can also automatically grade the exams using the internet (see the &lt;a href=&#34;https://cran.r-project.org/web/packages/RndTexExams/vignettes/rte-vignette_creating_exams.html&#34;&gt;vignette of &lt;code&gt;RndTexExams&lt;/code&gt;&lt;/a&gt; for information on how to do that with Google spreadsheets.)&lt;/p&gt;
&lt;p&gt;In this post I only scratched the surface of &lt;code&gt;exams&lt;/code&gt;. Adding to the description of its capabilities, you can &lt;strong&gt;export&lt;/strong&gt; exams to standard academic systems such as Moodle, Blackboard and others. You can also print the exam in pdf, nops (a pdf that allows easy scanning), or html. If you know a bit of latex or html, it is easy to customize the templates to the needs of your particular exam.&lt;/p&gt;
&lt;p&gt;As with all technical things, not everything is perfect. In my oppinio, the main issue with the &lt;code&gt;exams&lt;/code&gt; template is that requires some knowledge of R and Knitr. While this is Ok for most people reading this blog, it is not the case for the &lt;em&gt;average&lt;/em&gt; professor. It may sound surprising to the quantitative inclined people, but the great majority of professors still use .docx and .xlsx files to write academic work such as articles and exams. Why they don’t use or learn better tools? Well, this is a long answer, best suited for another post.&lt;/p&gt;
&lt;p&gt;Package &lt;code&gt;exams&lt;/code&gt; had a &lt;strong&gt;big and positive impact on how I do my work&lt;/strong&gt;. Based on a large database of questions that I’ve built, I can create a new exam in 5 minutes and grade it for a large class in less than 1 minute. I am very thankful to its authors and this is one of the reasons why I love posting packages in CRAN. It is my way of giving it back to the community.&lt;/p&gt;
&lt;p&gt;Concluding, package &lt;code&gt;exams&lt;/code&gt; is great and I believe that every examiner and professor should be using it. Thinking about the future, the template of questions in &lt;code&gt;exams&lt;/code&gt; has the potential of setting the &lt;strong&gt;language of exams&lt;/strong&gt;, a structure that could allow the user to output questions in any format he wants, just as you can use Markdown to output latex or word.&lt;/p&gt;
&lt;p&gt;Sharing questions in a collaborative platform, such as Quora, should be something for the developers (or R community) to think of. Questions could be ranked according to popular vote. Users could contribute by posting question files for other to use. Users would get a feedback on their work and, at the same time, be able to use other people questions. Students could also have access to it and independently study to a particular topic, by building custom made exams with randomized content.&lt;/p&gt;
&lt;p&gt;Summing up, if you are a teacher or examiner, I hope that this post convinces you to try out package &lt;code&gt;exams&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How to calculate betas (systematic risk) for a large number of stocks</title>
      <link>https://www.msperlin.com/post/2017-01-15-calculatingbetas/</link>
      <pubDate>Sun, 15 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2017-01-15-calculatingbetas/</guid>
      <description>


&lt;p&gt;One of the first examples about using linear regression models in finance is the calculation of betas, the so called market model. Coefficient beta is a measure of systematic risk and it is calculated by estimating a linear model where the dependent variable is the return vector of a stock and the explanatory variable is the return vector of a diversified local market index, such as SP500 (US), FTSE (UK), Ibovespa (Brazil), or any other.&lt;/p&gt;
&lt;p&gt;From the academic side, the calculation of beta is part of a famous asset pricing model, CAPM - Capital Asset Pricing Model, that relates expected return and systematic risk. One can reach the market model equation by assuming several conditions such as Normal distributed returns, rational investors and frictionless market. Summing up, the CAPM model predicts that betas have a linear relationship to expected returns, that is, stocks with higher betas should present, collectively, higher average of historical returns.&lt;/p&gt;
&lt;p&gt;In the quantitative side, we can formulate the market model as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(R_t = \alpha + \beta R_{M,t} + \epsilon _t\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(R_{t}\)&lt;/span&gt; is the return of the stock at time &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(R_{M,t}\)&lt;/span&gt; is the return of the market index, &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; is the constant (also called Jensen’s alphas) and, finally, &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; is the measure of systematic risk for the stock. The values of &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; are found by minimizing the sum of squared errors of the model. So, if you have a vector of prices for a stock and another vector of prices for the local market index, you can easily find the stock’s beta by calculating the daily returns and estimating the market model by OLS.&lt;/p&gt;
&lt;p&gt;The problem here is that, usually, you don’t want the beta of a single stock. You want to calculate the systematic risk for a large number of stocks. This is where students usually have problems, as they only learned in class how to estimate one model. In order to do the same procedure for more than one stock, some programming is needed. This is where R really shines in comparison to simpler programs such as Excel.&lt;/p&gt;
&lt;p&gt;In this post I will download some data from the US market, make some adjustments to the resulting dataframe and discuss three ways to calculate the betas of several stocks. These are:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Using a &lt;code&gt;loop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Using function &lt;code&gt;by&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Using package &lt;code&gt;dplyr&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;But first, lets load the data.&lt;/p&gt;
&lt;div id=&#34;loading-the-data-and-preparing-it&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Loading the data and preparing it&lt;/h1&gt;
&lt;p&gt;I’m a bit biased, but I really like using package &lt;code&gt;BatchGetSymbols&lt;/code&gt; to download financial data from yahoo finance. In this example we will download data for 10 stocks selected randomly from the SP500 index. I will also add the ticker &lt;code&gt;^GSPC&lt;/code&gt;, which belongs to the SP500 index. We will need it to calculate the betas. In order for the code to be reproducible, I will set &lt;code&gt;random.seed(100)&lt;/code&gt;. This means that anyone that runs the code available here will get the exact same results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(BatchGetSymbols)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: rvest&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: xml2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: dplyr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;dplyr&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:stats&amp;#39;:
## 
##     filter, lag&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:base&amp;#39;:
## 
##     intersect, setdiff, setequal, union&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(100)

ticker.MktIdx &amp;lt;- &amp;#39;^GSPC&amp;#39;
first.date &amp;lt;- as.Date(&amp;#39;2015-01-01&amp;#39;)
last.date &amp;lt;- as.Date(&amp;#39;2019-01-01&amp;#39;)

n.chosen.stocks &amp;lt;- 10 # can&amp;#39;t be higher than 505

# get random stocks
my.tickers &amp;lt;- c(sample(GetSP500Stocks()$Tickers,n.chosen.stocks),
                ticker.MktIdx)

l.out &amp;lt;- BatchGetSymbols(tickers = my.tickers, 
                             first.date = first.date,
                             last.date = last.date)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Running BatchGetSymbols for:&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##    tickers =FTV, ZBH, OXY, C, XLNX, VZ, BEN, WY, ROL, VTR, ^GSPC
##    Downloading data for benchmark ticker
## ^GSPC | yahoo (1|1) | Found cache file
## FTV | yahoo (1|11) | Found cache file - Got 62% of valid prices | OUT: not enough data (thresh.bad.data = 75%)
## ZBH | yahoo (2|11) | Found cache file - Got 100% of valid prices | Youre doing good!
## OXY | yahoo (3|11) | Found cache file - Got 100% of valid prices | Good stuff!
## C | yahoo (4|11) | Found cache file - Got 100% of valid prices | Looking good!
## XLNX | yahoo (5|11) | Found cache file - Got 100% of valid prices | Youre doing good!
## VZ | yahoo (6|11) | Found cache file - Got 100% of valid prices | Feels good!
## BEN | yahoo (7|11) | Found cache file - Got 100% of valid prices | Well done!
## WY | yahoo (8|11) | Found cache file - Got 100% of valid prices | Well done!
## ROL | yahoo (9|11) | Found cache file - Got 100% of valid prices | Looking good!
## VTR | yahoo (10|11) | Found cache file - Got 100% of valid prices | Nice!
## ^GSPC | yahoo (11|11) | Found cache file - Got 100% of valid prices | Got it!&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df.stocks &amp;lt;- l.out$df.tickers&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, lets check if everything went well with the import process.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(l.out$df.control)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 11 x 6
##    ticker src   download.status total.obs perc.benchmark.dates threshold.decisi…
##    &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;               &amp;lt;int&amp;gt;                &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;            
##  1 FTV    yahoo OK                    628                0.624 OUT              
##  2 ZBH    yahoo OK                   1006                1     KEEP             
##  3 OXY    yahoo OK                   1006                1     KEEP             
##  4 C      yahoo OK                   1006                1     KEEP             
##  5 XLNX   yahoo OK                   1006                1     KEEP             
##  6 VZ     yahoo OK                   1006                1     KEEP             
##  7 BEN    yahoo OK                   1006                1     KEEP             
##  8 WY     yahoo OK                   1006                1     KEEP             
##  9 ROL    yahoo OK                   1006                1     KEEP             
## 10 VTR    yahoo OK                   1006                1     KEEP             
## 11 ^GSPC  yahoo OK                   1006                1     KEEP&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It seems that everything is Ok. All stocks have column &lt;code&gt;perc.benchmark.dates&lt;/code&gt; equal to one (100%), meaning that they have the exact same dates as the benchmark ticker.&lt;/p&gt;
&lt;p&gt;Now, lets plot the time series of prices and look for any problem:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

p &amp;lt;- ggplot(df.stocks, aes(x=ref.date, y=price.adjusted)) + 
  geom_line() + facet_wrap(~ticker, scales = &amp;#39;free&amp;#39;)

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/post/2017-01-15-CalculatingBetas_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Again, we see that all prices seems to be Ok. This is one of the advantages of working with adjusted (and not closing) prices from yahoo finance. Artificial effects in the dataset such as ex-dividend prices, splits and inplits are already taken into account and the result is a smooth series without any breaks.&lt;/p&gt;
&lt;p&gt;The final step in preparing the data is to add a column with the returns of the market index. This is not strictly necessary but I really like to keep things organized in a tabular way. Since we will match each vector of returns of the stocks to a vector of returns of the market index, it makes sense to &lt;em&gt;synchronize&lt;/em&gt; the rows in the data.frame. First, we isolate the data for the market index in object &lt;code&gt;df.MktIdx&lt;/code&gt; and use function &lt;code&gt;match&lt;/code&gt; to make an index that matches the dates between the assets and the market index. We later use this index to build a new column in &lt;code&gt;df.stocks&lt;/code&gt;. See the next code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df.MktIdx &amp;lt;- df.stocks[df.stocks$ticker==ticker.MktIdx, ]

idx &amp;lt;- match(df.stocks$ref.date, df.MktIdx$ref.date)

df.stocks$ret.MktIdx &amp;lt;- df.MktIdx$ret.adjusted.prices[idx]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have the data in the correct format and structure, let’s start to calculate some betas. Here is where the different approaches will differ in syntax. Let’s start with the first case, using loops.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;estimating-betas&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Estimating betas&lt;/h1&gt;
&lt;div id=&#34;using-loops&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using loops&lt;/h2&gt;
&lt;p&gt;Loops are great and (almost) everyone loves then. While they can be a bit more verbose than fancy on-liners, the structure of a loop is very flexible and this can help solve complex problems. Let use it in our problem.&lt;/p&gt;
&lt;p&gt;The first step in using loops is the understand the vector that will be used as iterator in the loop. In our problem we are processing each stock, so the number of iterations in the loop is simply the number of stocks in the sample. We can find the unique stocks with the command &lt;code&gt;unique&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Check unique tickers
unique.tickers &amp;lt;- unique(df.stocks$ticker)

# create a empty vector to store betas
beta.vec &amp;lt;- c()

for (i.ticker in unique.tickers){
  
  # message to prompt
  cat(&amp;#39;\nRunning ols for&amp;#39;,i.ticker)
  
  # filter the data.frame for stock i.ticker
  df.temp &amp;lt;- df.stocks[df.stocks$ticker==i.ticker, ]
  
  # calculate beta with lm
  my.ols &amp;lt;- lm(data = df.temp, formula = ret.adjusted.prices ~ ret.MktIdx)
  
  # save beta
  my.beta &amp;lt;- coef(my.ols)[2]
  
  # store beta em beta.vec
  beta.vec &amp;lt;- c(beta.vec, my.beta)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Running ols for ZBH
## Running ols for OXY
## Running ols for C
## Running ols for XLNX
## Running ols for VZ
## Running ols for BEN
## Running ols for WY
## Running ols for ROL
## Running ols for VTR
## Running ols for ^GSPC&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# print result
print(data.frame(unique.tickers,beta.vec))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    unique.tickers  beta.vec
## 1             ZBH 0.9130036
## 2             OXY 1.0046153
## 3               C 1.3468402
## 4            XLNX 1.2272195
## 5              VZ 0.5864176
## 6             BEN 1.2555433
## 7              WY 0.9400250
## 8             ROL 0.8057286
## 9             VTR 0.4923402
## 10          ^GSPC 1.0000000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, the result is a lengthy code, but it works quite well. The final result is a dataframe with the tickers and their betas. Notice that, as expected, the betas are all positive and &lt;code&gt;^GSPC&lt;/code&gt; has a beta equal to 1.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-function-by&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using function &lt;code&gt;by&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Another way of solving the problem is to calculate the betas using one of the functions from the &lt;code&gt;apply&lt;/code&gt; family. In this case, we will use function &lt;code&gt;by&lt;/code&gt;. Be aware that you can also solve the problem using &lt;code&gt;tapply&lt;/code&gt; and &lt;code&gt;lapply&lt;/code&gt;. The code, however, will increase in complexity.&lt;/p&gt;
&lt;p&gt;The function &lt;code&gt;by&lt;/code&gt; works similarly to &lt;code&gt;tapply&lt;/code&gt;. The difference is that it is oriented to dataframes. That is, given a grouping variable, the original dataframe is broken into smaller dataframes and each piece is passed to a function. This helps a lot our problem since we need to work with two columns, the vector of returns of the asset and the vector of returns of the market index.&lt;/p&gt;
&lt;p&gt;Given the functional form of &lt;code&gt;by&lt;/code&gt;, will need to encapsulate a procedure that takes a dataframe as input and returns a coefficient beta, calculated from columns &lt;code&gt;ret&lt;/code&gt; and &lt;code&gt;ret.MktIdx&lt;/code&gt;. The next code does that.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get.beta &amp;lt;- function(df.temp){
  
  # estimate model
  my.ols &amp;lt;- lm(data=df.temp, formula = ret.adjusted.prices ~ ret.MktIdx)
  
  # isolate beta
  my.beta &amp;lt;- coef(my.ols)[2]
  
  # return beta
  return(my.beta)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The previous function accepts a single dataframe called &lt;code&gt;df.temp&lt;/code&gt;, uses it to calculate a linear model with function &lt;code&gt;lm&lt;/code&gt; and then returns the resulting beta, which is the second coefficient in &lt;code&gt;coef(my.ols)&lt;/code&gt;. Now, lets use it with function &lt;code&gt;by&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get betas with by
my.l &amp;lt;- by(data = df.stocks, 
           INDICES = df.stocks$ticker, 
           FUN = get.beta)

# my.l is an objetct of class by. To get only its elements, we can unclass it
betas &amp;lt;- unclass(my.l)

# print result
print(data.frame(betas))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           betas
## ^GSPC 1.0000000
## BEN   1.2555433
## C     1.3468402
## OXY   1.0046153
## ROL   0.8057286
## VTR   0.4923402
## VZ    0.5864176
## WY    0.9400250
## XLNX  1.2272195
## ZBH   0.9130036&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, it worked well. Needless to say that the results are identical to the previous case.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-dplyr&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using &lt;code&gt;dplyr&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Now, let’s solve our problem using package &lt;code&gt;dplyr&lt;/code&gt;. If you are not familiar with the &lt;em&gt;tidyverse&lt;/em&gt; and the work of Hadley Wickham, you will be a happier person after reading the rest of this post, trust me.&lt;/p&gt;
&lt;p&gt;Package &lt;code&gt;dplyr&lt;/code&gt; is one of my favorites and most used packages. It allows for the representation of data processing procedures in a simpler and more intuitive way. It really helps to tackle computational problems if you can fit it within a flexible structure. This is what, in my opinion, &lt;code&gt;dplyr&lt;/code&gt; does best. It combines clever functions with dataframes in the long (tidy) format.&lt;/p&gt;
&lt;p&gt;Have a look in the next set of code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)

beta.tab &amp;lt;- df.stocks %&amp;gt;% 
  group_by(ticker) %&amp;gt;% # group by column ticker
  do(ols.model = lm(data = ., formula = ret.adjusted.prices ~ret.MktIdx)) %&amp;gt;%   # estimate model
  mutate(beta = coef(ols.model)[2]) # get coefficients

print(beta.tab)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source: local data frame [10 x 3]
## Groups: &amp;lt;by row&amp;gt;
## 
## # A tibble: 10 x 3
##    ticker ols.model  beta
##    &amp;lt;chr&amp;gt;  &amp;lt;list&amp;gt;    &amp;lt;dbl&amp;gt;
##  1 ^GSPC  &amp;lt;lm&amp;gt;      1    
##  2 BEN    &amp;lt;lm&amp;gt;      1.26 
##  3 C      &amp;lt;lm&amp;gt;      1.35 
##  4 OXY    &amp;lt;lm&amp;gt;      1.00 
##  5 ROL    &amp;lt;lm&amp;gt;      0.806
##  6 VTR    &amp;lt;lm&amp;gt;      0.492
##  7 VZ     &amp;lt;lm&amp;gt;      0.586
##  8 WY     &amp;lt;lm&amp;gt;      0.940
##  9 XLNX   &amp;lt;lm&amp;gt;      1.23 
## 10 ZBH    &amp;lt;lm&amp;gt;      0.913&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After loading &lt;code&gt;dplyr&lt;/code&gt;, we use the pipeline operator %&amp;gt;% to streamline all calculations. This means that we don’t need to keep a copy of intermediate calculations. Also, It looks pretty, don’t you agree?&lt;/p&gt;
&lt;p&gt;The line &lt;code&gt;beta.tab &amp;lt;- df.stocks %&amp;gt;%&lt;/code&gt; passes the dataframe &lt;code&gt;df.stocks&lt;/code&gt; for the next line, &lt;code&gt;group_by(ticker) %&amp;gt;%&lt;/code&gt;, which will group the dataframe according the the values of column &lt;code&gt;ticker&lt;/code&gt; and pass the result for the next step. The line &lt;code&gt;do(ols.model = lm(data = ., formula = ret ~ret.MktIdx))&lt;/code&gt; estimates the model by passing a temporary dataframe and saves it in a column called &lt;code&gt;ols.model&lt;/code&gt;. Notice that the model is a &lt;code&gt;S3&lt;/code&gt; object and not a single value. The dataframe alternative &lt;code&gt;tibble&lt;/code&gt; is flexible with its content. The final line, &lt;code&gt;mutate(beta = coef(ols.model)[2])&lt;/code&gt; retrieves the beta from each element of the column &lt;code&gt;ols.model&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;What I really like about &lt;code&gt;dplyr&lt;/code&gt; is that it makes it easy to extend the original code. As an example, if I wanted to use a second grouping variable, I can just add it in the second line as &lt;code&gt;group_by(ticker, newgroupingvariable)&lt;/code&gt;. This becomes handy if you need, lets say, to estimated the model in different time periods.&lt;/p&gt;
&lt;p&gt;As an example, let’s assume that I want to split the sample for each stock in half and see if the betas change significantly from time period to the other. This robustness check is a very common procedure in scientific research. First, let’s build a new column in &lt;code&gt;df.stocks&lt;/code&gt; that sets the time periods as &lt;code&gt;Sample 1&lt;/code&gt; and &lt;code&gt;Sample 2&lt;/code&gt;. We can use &lt;code&gt;tapply&lt;/code&gt; for that;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.sample &amp;lt;- function(ref.dates){
  my.n &amp;lt;- length(ref.dates) # get number of dates
  my.n.half &amp;lt;- floor(my.n/2) # get aproximate half of observations
  
  # create grouping variable
  samples.vec &amp;lt;- c(rep(&amp;#39;Sample 1&amp;#39;, my.n.half ), rep(&amp;#39;Sample 2&amp;#39;, my.n-my.n.half))
  
  # return
  return(samples.vec)
}

# build group
my.l &amp;lt;- tapply(X = df.stocks$ref.date, 
               INDEX = df.stocks$ticker,
               FUN = set.sample )

# unsort it
my.l &amp;lt;- my.l[my.tickers]

# save it in dataframe
df.stocks$my.sample &amp;lt;- unlist(my.l)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We proceed by calling the same functions as before, but using an additional grouping variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;beta.tab &amp;lt;- df.stocks %&amp;gt;% 
  group_by(ticker,my.sample) %&amp;gt;% # group by column ticker
  do(ols.model = lm(data = ., formula = ret.adjusted.prices ~ret.MktIdx)) %&amp;gt;%   # estimate model
  mutate(beta = coef(ols.model)[2]) # get coefficients

print(beta.tab)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source: local data frame [20 x 4]
## Groups: &amp;lt;by row&amp;gt;
## 
## # A tibble: 20 x 4
##    ticker my.sample ols.model  beta
##    &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;     &amp;lt;list&amp;gt;    &amp;lt;dbl&amp;gt;
##  1 ^GSPC  Sample 1  &amp;lt;lm&amp;gt;      1.00 
##  2 ^GSPC  Sample 2  &amp;lt;lm&amp;gt;      1.   
##  3 BEN    Sample 1  &amp;lt;lm&amp;gt;      1.40 
##  4 BEN    Sample 2  &amp;lt;lm&amp;gt;      1.08 
##  5 C      Sample 1  &amp;lt;lm&amp;gt;      1.54 
##  6 C      Sample 2  &amp;lt;lm&amp;gt;      1.11 
##  7 OXY    Sample 1  &amp;lt;lm&amp;gt;      1.10 
##  8 OXY    Sample 2  &amp;lt;lm&amp;gt;      0.882
##  9 ROL    Sample 1  &amp;lt;lm&amp;gt;      0.781
## 10 ROL    Sample 2  &amp;lt;lm&amp;gt;      0.836
## 11 VTR    Sample 1  &amp;lt;lm&amp;gt;      0.653
## 12 VTR    Sample 2  &amp;lt;lm&amp;gt;      0.295
## 13 VZ     Sample 1  &amp;lt;lm&amp;gt;      0.669
## 14 VZ     Sample 2  &amp;lt;lm&amp;gt;      0.485
## 15 WY     Sample 1  &amp;lt;lm&amp;gt;      1.08 
## 16 WY     Sample 2  &amp;lt;lm&amp;gt;      0.772
## 17 XLNX   Sample 1  &amp;lt;lm&amp;gt;      1.07 
## 18 XLNX   Sample 2  &amp;lt;lm&amp;gt;      1.42 
## 19 ZBH    Sample 1  &amp;lt;lm&amp;gt;      0.888
## 20 ZBH    Sample 2  &amp;lt;lm&amp;gt;      0.944&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see, the output now shows the beta for all combinations between &lt;code&gt;ticker&lt;/code&gt; and &lt;code&gt;my.sample&lt;/code&gt;. It seems that the betas tend to be higher for &lt;em&gt;Sample 2&lt;/em&gt;, meaning that the overall systematic risk in the market has increased over time, at least for the majority of the ten chosen stocks. Given the small sample of stocks, It might be interesting to test for this property in a larger dataset.&lt;/p&gt;
&lt;p&gt;Back to the model, if you want more information about it, you can just write new lines in the last call to %&amp;gt;%. Let’s say, for example, that you want to get the value of alpha and the corresponding t-statistic of both coefficients. We can use the following code for that:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)

beta.tab &amp;lt;- df.stocks %&amp;gt;% 
  group_by(ticker) %&amp;gt;% # group by column ticker
  do(ols.model = lm(data = ., formula = ret.adjusted.prices ~ret.MktIdx)) %&amp;gt;%   # estimate model
  mutate(beta = coef(ols.model)[2],
         beta.tstat = summary(ols.model)[[4]][2,3],
         alpha = coef(ols.model)[1],
         alpha.tstat = summary(ols.model)[[4]][1,3]) # get coefficients&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in summary.lm(ols.model): essentially perfect fit: summary may be
## unreliable

## Warning in summary.lm(ols.model): essentially perfect fit: summary may be
## unreliable&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(beta.tab)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source: local data frame [10 x 6]
## Groups: &amp;lt;by row&amp;gt;
## 
## # A tibble: 10 x 6
##    ticker ols.model  beta beta.tstat     alpha alpha.tstat
##    &amp;lt;chr&amp;gt;  &amp;lt;list&amp;gt;    &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;
##  1 ^GSPC  &amp;lt;lm&amp;gt;      1        3.49e17  0              0    
##  2 BEN    &amp;lt;lm&amp;gt;      1.26     2.99e 1 -0.000708      -1.96 
##  3 C      &amp;lt;lm&amp;gt;      1.35     3.46e 1 -0.000184      -0.548
##  4 OXY    &amp;lt;lm&amp;gt;      1.00     2.19e 1 -0.000217      -0.551
##  5 ROL    &amp;lt;lm&amp;gt;      0.806    2.11e 1  0.000879       2.67 
##  6 VTR    &amp;lt;lm&amp;gt;      0.492    8.94e 0 -0.000144      -0.304
##  7 VZ     &amp;lt;lm&amp;gt;      0.586    1.65e 1  0.000287       0.935
##  8 WY     &amp;lt;lm&amp;gt;      0.940    2.24e 1 -0.000463      -1.28 
##  9 XLNX   &amp;lt;lm&amp;gt;      1.23     2.46e 1  0.000623       1.45 
## 10 ZBH    &amp;lt;lm&amp;gt;      0.913    2.17e 1 -0.000164      -0.451&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the previous code, I added line &lt;code&gt;beta.tstat = summary(ols.model)[[4]][2,3]&lt;/code&gt; that returns the t-statistic of the beta coefficient. The location of this parameter is found by investigating the elements of an object of type &lt;code&gt;lm&lt;/code&gt;. After calling &lt;code&gt;summary&lt;/code&gt;, the t-statistic is available in the fourth element of the &lt;code&gt;lm&lt;/code&gt; object, which is a matrix with several information from the estimation. The t-statistic for the alpha parameter is found in a similar way.&lt;/p&gt;
&lt;p&gt;As you can see, the syntax of &lt;code&gt;dplyr&lt;/code&gt; make it easy to extend the model and quickly try new things. It is possible to do the same using other R functions and a loop, but using &lt;code&gt;dplyr&lt;/code&gt; is really handy.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusions&lt;/h1&gt;
&lt;p&gt;As you can probably suspect from the text, I’m a big fan of &lt;code&gt;dplyr&lt;/code&gt; and I’m always teaching its use to my students. While loops are ok and I personally use then a lot in more complex problems, the functions in &lt;code&gt;dplyr&lt;/code&gt; allow for an intuitive syntax in data processing, making it easy to understand and extend code.&lt;/p&gt;
&lt;p&gt;Do notice that the code in this example is self contained and reproducible. If you want to try it for more stocks, just change input &lt;code&gt;n.chosen.stocks&lt;/code&gt; to a higher value.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Using R to download high frequency trade data diretcly from Bovespa</title>
      <link>https://www.msperlin.com/post/2017-01-02-gethfdata/</link>
      <pubDate>Mon, 02 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2017-01-02-gethfdata/</guid>
      <description>


&lt;p&gt;Recently, Bovespa, the Brazilian financial exchange company, allowed external access to its &lt;a href=&#34;ftp://ftp.bmf.com.br/&#34;&gt;ftp site&lt;/a&gt;. In this address one can find several information regarding the Brazilian financial system, including datasets with high frequency (tick by tick) trading data for three different markets: equity, options and BMF.&lt;/p&gt;
&lt;p&gt;Downloading and processing these files, however, can be exausting. The dataset is composed of zip files with the whole trading data, separated by day and market. These files are huge in size and processing or aggregating them in a usefull manner requires specific knowledge for the structure of the dataset.&lt;/p&gt;
&lt;p&gt;The package GetHFData make is easy to access this dataset directly by allowing the easy importation and aggregations of it. Based on this package the user can:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Access the contents of the Bovespa ftp using function function &lt;code&gt;ghfd_get_ftp_contents&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Get the list of available ticker in the trading data using &lt;code&gt;ghfd_get_available_tickers_from_ftp&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Download individual files using &lt;code&gt;ghfd_download_file&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Download and process a batch of dates and assets codes with &lt;code&gt;ghfd_get_HF_data&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More details can be found in my &lt;a href=&#34;https://ssrn.com/abstract=2824058&#34;&gt;SSRN paper&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>BatchGetSymbols | msperlin</title>
    <link>https://www.msperlin.com/tag/batchgetsymbols/</link>
      <atom:link href="https://www.msperlin.com/tag/batchgetsymbols/index.xml" rel="self" type="application/rss+xml" />
    <description>BatchGetSymbols</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Marcelo S. Perlin © 2022</copyright><lastBuildDate>Thu, 31 Mar 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://www.msperlin.com/img/portrait.jpg</url>
      <title>BatchGetSymbols</title>
      <link>https://www.msperlin.com/tag/batchgetsymbols/</link>
    </image>
    
    <item>
      <title>New R package yfR</title>
      <link>https://www.msperlin.com/post/2022-03-31-yfr/</link>
      <pubDate>Thu, 31 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2022-03-31-yfr/</guid>
      <description>


&lt;p&gt;Package &lt;a href=&#34;https://github.com/msperlin/BatchGetSymbols&#34;&gt;BatchGetSymbols&lt;/a&gt; facilitates importation of Yahoo Finance data directly into R and is one of my most popular R packages, with over 100k installations since conception (around 2500 downloads per month). However, I developed BatchGetSymbols back in 2016, with many bad structural choices from my part.&lt;/p&gt;
&lt;p&gt;For years I wanted to improved the code but always restrained myself because I did not want to mess up the execution of other people’s code that was based on BatchGetSymbols. In order to implement all the breaking changes and move forward with the package, I decided to develop a &lt;strong&gt;new&lt;/strong&gt; (and fresh) package called yfR.&lt;/p&gt;
&lt;p&gt;Today I’m releasing the first version of yfR (not yeat in CRAN). This in a major upgrade on BatchGetSymbols, with many backwards-incompatible changes.&lt;/p&gt;
&lt;div id=&#34;motivation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Motivation&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;yfR&lt;/code&gt; is the second and backwards-incompatible version of &lt;a href=&#34;https://CRAN.R-project.org/package=BatchGetSymbols&#34;&gt;BatchGetSymbols&lt;/a&gt;. In a nutshell, it provides access to daily stock prices from &lt;a href=&#34;https://finance.yahoo.com/&#34;&gt;Yahoo Finance&lt;/a&gt;, a vast repository with financial data around the globe. Yahoo Finance cover a large number of markets and assets, being used extensively for importing price datasets used in academic research and teaching.&lt;/p&gt;
&lt;p&gt;Package &lt;code&gt;yfR&lt;/code&gt; is based on &lt;a href=&#34;https://www.quantmod.com/&#34;&gt;quantmod&lt;/a&gt; and used its main function for fetching data from Yahoo Finance. The main innovation in &lt;code&gt;yfR&lt;/code&gt; is in the organization of the imported financial data and using local caching system and parallel computing for speeding up large scale download of datasets from Yahoo Finance.&lt;/p&gt;
&lt;p&gt;See full documentation &lt;a href=&#34;https://github.com/msperlin/yfR&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;features&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Fetchs daily/weekly/monthly/annual stock prices/returns from yahoo finance and outputs a dataframe (tibble) in the long format (stacked data);&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A new feature called “collections” facilitates download of multiple tickers from a particular market/index. You can, for example, download data for all stocks in the SP500 index with a simple call to &lt;code&gt;yf_collection_get()&lt;/code&gt;;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A session-persistent smart cache system is available by default. This means that the data is saved locally and only missing portions are downloaded, if needed.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;All dates are compared to a benchmark ticker such as SP500 and, whenever an individual asset does not have a sufficient number of dates, the software drops it from the output. This means you can choose to ignore tickers with high number of missing dates.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A customized function called &lt;code&gt;yf_convert_to_wide()&lt;/code&gt; can transform the long dataframe into a wide format (tickers as columns), much used in portfolio optimization. The output is a list where each element is a different target variable (prices, returns, volumes).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Parallel computing with package &lt;code&gt;furrr&lt;/code&gt; is available, speeding up the data importation process.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;differences-from-batchgetsymbols&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Differences from &lt;a href=&#34;https://github.com/msperlin/BatchGetSymbols&#34;&gt;BatchGetSymbols&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Package &lt;code&gt;BatchgetSymbols&lt;/code&gt; was developed back in 2016, with many bad structural choices from my part. Since then, I learned more about R and its ecosystem, resulting in better and more maintainable code. However, it is impossible to keep compatibility with the changes I wanted to make, which is why I decided to develop a new (and fresh) package.&lt;/p&gt;
&lt;p&gt;Here are the main differences between &lt;code&gt;yfR&lt;/code&gt; (new) and &lt;code&gt;BatchGetSymbols&lt;/code&gt; (old):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;All input arguments are now formatted as “snake_case” and not “dot.case”. For example, the argument for the first date of data importation in &lt;code&gt;yfR::yf_get()&lt;/code&gt; is &lt;code&gt;first_date&lt;/code&gt;, and not &lt;code&gt;first.date&lt;/code&gt; as used in &lt;code&gt;BatchGetSymbols::BatchGetSymbols&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;All function have been renamed for a common API notation. For example, &lt;code&gt;BatchGetSymbols::BatchGetSymbols&lt;/code&gt; is now &lt;code&gt;yfR::yf_get()&lt;/code&gt;. Likewise, the function for fetching collections is &lt;code&gt;yfR::yf_collection_get()&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The output of &lt;code&gt;yfR::yf_get()&lt;/code&gt; is always a tibble with the price data (and not a list as in &lt;code&gt;BatchGetSymbols::BatchGetSymbols&lt;/code&gt;). If one wants the tibble with a summary of the importing process, it is available as an attribute of the output (see function &lt;code&gt;base::attributes&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A new feature called “collection”, which allows for easy download of a collection of tickers. For example, you can download price data for all components of the SP500 by simply calling &lt;code&gt;yfR::yf_collection_get(&#34;SP500&#34;)&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;New and prettier status messages using package &lt;code&gt;cli&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can find more details at its github repo:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/msperlin/yfR&#34; class=&#34;uri&#34;&gt;https://github.com/msperlin/yfR&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;installation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;# CRAN (not yet available)
#install.packages(&amp;#39;yfR&amp;#39;)

# Github (dev version)
devtools::install_github(&amp;#39;msperlin/yfR&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;examples&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Examples&lt;/h2&gt;
&lt;div id=&#34;fetching-a-single-stock-price&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fetching a single stock price&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(yfR)

# set options for algorithm
my_ticker &amp;lt;- &amp;#39;FB&amp;#39;
first_date &amp;lt;- Sys.Date() - 30
last_date &amp;lt;- Sys.Date()

# fetch data
df_yf &amp;lt;- yf_get(tickers = my_ticker, 
                first_date = first_date,
                last_date = last_date)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Running yfR for 1 stocks | 2022-03-01 --&amp;gt; 2022-03-31 (30 days) ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Downloading data for benchmark ticker ^GSPC&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ (1/1) Fetching data for &amp;#39;,
## &amp;#39;FB&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## !    - not cached&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - cache saved successfully&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 22 valid rows (2022-03-01 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 100% of valid prices -- Well done msperlin!&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Binding price data&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# output is a tibble with data
head(df_yf)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 × 10
##   ticker ref_date   price_open price_high price_low price_close   volume
##   &amp;lt;chr&amp;gt;  &amp;lt;date&amp;gt;          &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 FB     2022-03-01       210.       212.      202.        203. 27094900
## 2 FB     2022-03-02       205.       209.      202.        208. 29452100
## 3 FB     2022-03-03       209.       209.      201.        203. 27263500
## 4 FB     2022-03-04       202.       206.      199.        200. 32130900
## 5 FB     2022-03-07       201.       201.      187.        187. 38560600
## 6 FB     2022-03-08       188.       197.      186.        190. 37508100
## # … with 3 more variables: price_adjusted &amp;lt;dbl&amp;gt;, ret_adjusted_prices &amp;lt;dbl&amp;gt;,
## #   ret_closing_prices &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;fetching-many-stock-prices&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fetching many stock prices&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(yfR)
library(ggplot2)

my_ticker &amp;lt;- c(&amp;#39;FB&amp;#39;, &amp;#39;GM&amp;#39;, &amp;#39;MMM&amp;#39;)
first_date &amp;lt;- Sys.Date() - 100
last_date &amp;lt;- Sys.Date()

df_yf_multiple &amp;lt;- yf_get(tickers = my_ticker, 
                         first_date = first_date,
                         last_date = last_date)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Running yfR for 3 stocks | 2021-12-21 --&amp;gt; 2022-03-31 (100 days) ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Downloading data for benchmark ticker ^GSPC&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ (1/3) Fetching data for &amp;#39;,
## &amp;#39;FB&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - found cache file (2022-03-01 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## !    - need new data (cache doesnt match query)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 69 valid rows (2021-12-21 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 100% of valid prices -- All OK!&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ (2/3) Fetching data for &amp;#39;,
## &amp;#39;GM&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## !    - not cached&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - cache saved successfully&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 69 valid rows (2021-12-21 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 100% of valid prices -- Well done msperlin!&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ (3/3) Fetching data for &amp;#39;,
## &amp;#39;MMM&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## !    - not cached&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - cache saved successfully&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 69 valid rows (2021-12-21 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 100% of valid prices -- Youre doing good!&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Binding price data&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- ggplot(df_yf_multiple, 
            aes(x = ref_date, y = price_adjusted,
                color = ticker)) + 
  geom_line()

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/blog/post/2022-03-31-yfR_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fetching-collections-of-prices&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fetching collections of prices&lt;/h3&gt;
&lt;p&gt;Collections are just a bundle of tickers pre-organized in the package. For example, collection &lt;code&gt;SP500&lt;/code&gt; represents the current composition of the SP500 index.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(yfR)

df_yf &amp;lt;- yf_collection_get(&amp;quot;SP500&amp;quot;, 
                           first_date = Sys.Date() - 30,
                           last_date = Sys.Date())

head(df_yf)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;fetching-dailyweeklymonthlyyearly-price-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fetching daily/weekly/monthly/yearly price data&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(yfR)
library(ggplot2)
library(dplyr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;dplyr&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:stats&amp;#39;:
## 
##     filter, lag&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:base&amp;#39;:
## 
##     intersect, setdiff, setequal, union&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_ticker &amp;lt;- &amp;#39;GE&amp;#39;
first_date &amp;lt;- &amp;#39;2010-01-01&amp;#39;
last_date &amp;lt;- Sys.Date()

df_dailly &amp;lt;- yf_get(tickers = my_ticker, 
                    first_date, last_date, 
                    freq_data = &amp;#39;daily&amp;#39;) |&amp;gt;
  mutate(freq = &amp;#39;daily&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Running yfR for 1 stocks | 2010-01-01 --&amp;gt; 2022-03-31 (4472 days) ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Downloading data for benchmark ticker ^GSPC&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ (1/1) Fetching data for &amp;#39;,
## &amp;#39;GE&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## !    - not cached&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - cache saved successfully&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 3082 valid rows (2010-01-04 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 100% of valid prices -- Time for some tea?&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Binding price data&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_weekly &amp;lt;- yf_get(tickers = my_ticker, 
                    first_date, last_date, 
                    freq_data = &amp;#39;weekly&amp;#39;) |&amp;gt;
  mutate(freq = &amp;#39;weekly&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Running yfR for 1 stocks | 2010-01-01 --&amp;gt; 2022-03-31 (4472 days) ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Downloading data for benchmark ticker ^GSPC&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ (1/1) Fetching data for &amp;#39;,
## &amp;#39;GE&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - found cache file (2010-01-04 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 3082 valid rows (2010-01-04 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 100% of valid prices -- You got it msperlin!&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Binding price data&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_monthly &amp;lt;- yf_get(tickers = my_ticker, 
                     first_date, last_date, 
                     freq_data = &amp;#39;monthly&amp;#39;) |&amp;gt;
  mutate(freq = &amp;#39;monthly&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Running yfR for 1 stocks | 2010-01-01 --&amp;gt; 2022-03-31 (4472 days) ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Downloading data for benchmark ticker ^GSPC&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ (1/1) Fetching data for &amp;#39;,
## &amp;#39;GE&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - found cache file (2010-01-04 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 3082 valid rows (2010-01-04 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 100% of valid prices -- Good stuff!&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Binding price data&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_yearly &amp;lt;- yf_get(tickers = my_ticker, 
                    first_date, last_date, 
                    freq_data = &amp;#39;yearly&amp;#39;) |&amp;gt;
  mutate(freq = &amp;#39;yearly&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Running yfR for 1 stocks | 2010-01-01 --&amp;gt; 2022-03-31 (4472 days) ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Downloading data for benchmark ticker ^GSPC&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ (1/1) Fetching data for &amp;#39;,
## &amp;#39;GE&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - found cache file (2010-01-04 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 3082 valid rows (2010-01-04 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 100% of valid prices -- Good job msperlin!&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Binding price data&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_allfreq &amp;lt;- bind_rows(
  list(df_dailly, df_weekly, df_monthly, df_yearly)
) |&amp;gt;
  mutate(freq = factor(freq, 
                       levels = c(&amp;#39;daily&amp;#39;, 
                                  &amp;#39;weekly&amp;#39;,
                                  &amp;#39;monthly&amp;#39;,
                                  &amp;#39;yearly&amp;#39;))) # make sure the order in plot is right

p &amp;lt;- ggplot(df_allfreq, aes(x=ref_date, y = price_adjusted)) + 
  geom_point() + geom_line() + facet_grid(freq ~ ticker) + 
  theme_minimal() + 
  labs(x = &amp;#39;&amp;#39;, y = &amp;#39;Adjusted Prices&amp;#39;)

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/blog/post/2022-03-31-yfR_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;changing-format-to-wide&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Changing format to wide&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(yfR)
library(ggplot2)

my_ticker &amp;lt;- c(&amp;#39;FB&amp;#39;, &amp;#39;GM&amp;#39;, &amp;#39;MMM&amp;#39;)
first_date &amp;lt;- Sys.Date() - 100
last_date &amp;lt;- Sys.Date()

df_yf_multiple &amp;lt;- yf_get(tickers = my_ticker, 
                         first_date = first_date,
                         last_date = last_date)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Running yfR for 3 stocks | 2021-12-21 --&amp;gt; 2022-03-31 (100 days) ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Downloading data for benchmark ticker ^GSPC&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ (1/3) Fetching data for &amp;#39;,
## &amp;#39;FB&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - found cache file (2021-12-21 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 69 valid rows (2021-12-21 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 100% of valid prices -- Good job msperlin!&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ (2/3) Fetching data for &amp;#39;,
## &amp;#39;GM&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - found cache file (2021-12-21 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 69 valid rows (2021-12-21 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 100% of valid prices -- All OK!&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ (3/3) Fetching data for &amp;#39;,
## &amp;#39;MMM&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - found cache file (2021-12-21 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 69 valid rows (2021-12-21 --&amp;gt; 2022-03-30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓    - got 100% of valid prices -- Well done msperlin!&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Binding price data&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;l_wide &amp;lt;- yf_convert_to_wide(df_yf_multiple)

prices_wide &amp;lt;- l_wide$price_adjusted

head(prices_wide)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 × 4
##   ref_date      FB    GM   MMM
##   &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 2021-12-21  334.  54.8  171.
## 2 2021-12-22  330.  56.1  171.
## 3 2021-12-23  335.  56.9  173.
## 4 2021-12-27  346.  57.4  175.
## 5 2021-12-28  346.  57.1  176.
## 6 2021-12-29  343.  57.2  177.&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A shiny interface to BatchGetSymbols</title>
      <link>https://www.msperlin.com/post/2021-05-26-bgs-shiny/</link>
      <pubDate>Wed, 26 May 2021 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2021-05-26-bgs-shiny/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/blog/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Hadley Wickham recently released an online version of &lt;a href=&#34;https://mastering-shiny.org/&#34;&gt;Mastering Shiny&lt;/a&gt;. The book is great! If you haven’t read it, do it fast! On a side note, it is really amazing how much of &lt;strong&gt;good and curated content&lt;/strong&gt; you can get for free in R. When I started programming back in 2007, the first step was buying a brand new – and sometimes expensive – book about the language. There were blogs and other sites, but most content was very basic and not curated, meaning that the posted code most of the time did not work. The new generation probably have no idea of how easy it is to start fresh on new code these days [I fell quite old writing this sentence :)].&lt;/p&gt;
&lt;p&gt;Well, this was a great opportunity for me to brush up my shiny skills. I learned shiny back in 2016 and can report on the development of the technology. I’m really impressed by the current state of shiny today. It is becoming very competitive against other data based dashboard technologies such as those using Python.&lt;/p&gt;
&lt;p&gt;The result of this learning sprint is &lt;a href=&#34;https://www.msperlin.com/shiny/bgs/&#34;&gt;bgs-shiny&lt;/a&gt;, a shiny interface to package BatchGetSymbols. Within this application you can visualize and download price data from Yahoo Finance. In the background, every data point is live feed, fetched from Yahoo Finance. As usual, all code is available in &lt;a href=&#34;https://github.com/msperlin/BatchGetSymbols-Shiny&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Risk and return for B3</title>
      <link>https://www.msperlin.com/post/2019-05-01-meanvariance/</link>
      <pubDate>Wed, 01 May 2019 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2019-05-01-meanvariance/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/blog/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;One of the subjects that I teach in my undergraduate finance class is the relationship between risk and expected returns. In short, the riskier the investment, more returns should be &lt;strong&gt;expected&lt;/strong&gt; by the investor. It is not a difficult argument to make. All that you need to understand is to remember that people are not naive in financial markets. Whenever they make a big gamble, the rewards should also be large. Rational investors, on theory, would not invest in risky stocks that are likelly to yield low returns.&lt;/p&gt;
&lt;p&gt;Going further, one the arguments I make to support this idea is looking at historical data. By assuming that expected returns is the average yearly return rate on a stock and the risk is the standard deviation of the same returns, we can check for a positive relationship by plotting the data in a scatter plot.&lt;/p&gt;
&lt;p&gt;In this post I’ll show how you can do it easily in R using &lt;code&gt;BatchGetSymbols&lt;/code&gt;, &lt;code&gt;GetBCBData&lt;/code&gt; and &lt;code&gt;tidyverse&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;First, we will gather and organize all data sets. Here I’m using the stock components of Ibovespa, the Brazilian market index, and also CDI, a common risk free rate in Brazil. The next code will:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Import the data&lt;/li&gt;
&lt;li&gt;organize it in the same structure (same columns)&lt;/li&gt;
&lt;li&gt;bind it all together&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get stock data
library(tidyverse)
library(BatchGetSymbols)
library(GetBCBData)

first.date &amp;lt;- &amp;#39;2008-01-01&amp;#39; # last date is Sys.Date by default

# get stock data
df.ibov &amp;lt;- GetIbovStocks()
mkt.idx &amp;lt;- c(&amp;#39;^BVSP&amp;#39;)
my.tickers &amp;lt;- c(mkt.idx, paste0(df.ibov$tickers, &amp;#39;.SA&amp;#39;) )

df.prices &amp;lt;- BatchGetSymbols(tickers = my.tickers, first.date = first.date,
                             freq.data = &amp;#39;yearly&amp;#39;, 
                             be.quiet = TRUE)[[2]]

tab.stocks &amp;lt;- df.prices %&amp;gt;%
  na.omit() %&amp;gt;%
  group_by(ticker) %&amp;gt;%
  summarise(mean.ret = mean(ret.adjusted.prices),
            sd.ret = sd(ret.adjusted.prices)) %&amp;gt;%
  mutate(ticker = str_replace_all(ticker, fixed(&amp;#39;.SA&amp;#39;), &amp;#39;&amp;#39;) )

tab.mkt.idx &amp;lt;- tab.stocks %&amp;gt;%
               filter(ticker %in% mkt.idx)

tab.stocks &amp;lt;- tab.stocks %&amp;gt;%
               filter(!(ticker %in% mkt.idx))

# get CDI (risk free rate) 
my.id &amp;lt;- c(CDI = 4389)

tab.CDI &amp;lt;- gbcbd_get_series(my.id, first.date = first.date) %&amp;gt;%
  rename(ticker = series.name ) %&amp;gt;%
  mutate(ref.date = format(ref.date, &amp;#39;%Y&amp;#39;),
         value = value/100) %&amp;gt;%
  group_by(ref.date, ticker) %&amp;gt;%
  summarise(ret = mean(value)) %&amp;gt;%
  group_by(ticker) %&amp;gt;%
  summarise(mean.ret = mean(ret),
            sd.ret = sd(ret))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have the data, lets use &lt;code&gt;ggplot&lt;/code&gt; to build our graph.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

p &amp;lt;- ggplot(tab.stocks, aes(x = sd.ret, y = mean.ret, group = ticker)) + 
  geom_point() + 
  geom_text(data = tab.stocks, aes(x = sd.ret, y = mean.ret, label = ticker), nudge_y = 0.03,
            check_overlap = TRUE, nudge_x = 0.05 ) + 
  geom_point(data = tab.CDI, aes(x = sd.ret, y = mean.ret, color = ticker), size =5) +
  geom_point(data = tab.mkt.idx, 
             aes(x = sd.ret, y = mean.ret, color = ticker), size =5) +
  labs(x = &amp;#39;Risk (standard deviation)&amp;#39;, y =&amp;#39;Expected Returns (average)&amp;#39;, 
       title = &amp;#39;Mean X Variance map for B3&amp;#39;,
       subtitle = paste0(nrow(tab.stocks), &amp;#39; stocks, &amp;#39;, lubridate::year(min(df.prices$ref.date)), 
                         &amp;#39; - &amp;#39;, lubridate::year(max(df.prices$ref.date)))) + 
  scale_x_continuous(labels = scales::percent) + 
  scale_y_continuous(labels = scales::percent)  

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/blog/post/2019-05-01-MeanVariance_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Looks pretty! What do we learn?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Overall, most of the stocks did better than the risk free rate (CDI);&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;There is a positive relationship between risk and return. The higher the standard deviation (x-axis), the higher the mean of returns (y-axis). However, notice that it is not a perfect relationship. If we followed the mean-variance gospel, there are lots of opportunities of arbitrage. We would mostly invest in those stocks in the upper-left part of the plot;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Surprisingly, the market index, Ibovespa (^BVSP), is not well positioned in the graph. Since it is a diversified portfolio, I expected it to be closer to the frontier, around stock EQTL3.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>BatchGetSymbols is now parallel!</title>
      <link>https://www.msperlin.com/post/2019-04-13-parallel-batchgetsymbols/</link>
      <pubDate>Sat, 13 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2019-04-13-parallel-batchgetsymbols/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/blog/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;&lt;a href=&#34;https://github.com/msperlin/BatchGetSymbols&#34;&gt;BatchGetSymbols&lt;/a&gt; is my most downloaded package by any count. Computation time, however, has always been an issue. While downloading data for 10 or less stocks is fine, doing it for a large ammount of tickers, say the SP500 composition, gets very boring.&lt;/p&gt;
&lt;p&gt;I’m glad to report that time is no longer an issue. Today I implemented a parallel option for BatchGetSymbols. If you have a high number of cores in your computer, you can seriously speep up the importation process. Importing SP500 compositition, over 500 stocks, is a breeze.&lt;/p&gt;
&lt;p&gt;Give a try. The new version is already available in Github:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;#39;msperlin/BatchGetSymbols&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It should be in CRAN soon.&lt;/p&gt;
&lt;div id=&#34;how-to-use-parallel&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How to use parallel&lt;/h2&gt;
&lt;p&gt;Very simple. Just set you parallel plan with &lt;code&gt;future::plan&lt;/code&gt; and use input &lt;code&gt;do.parallel = TRUE&lt;/code&gt; in &lt;code&gt;BatchGetSymbols&lt;/code&gt;. If you are not sure how many cores you have available, just run the following code to figure it out:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;future::availableCores()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## system 
##     16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#devtools::install_github(&amp;#39;msperlin/BatchGetSymbols&amp;#39;)
library(BatchGetSymbols)

# get tickers from SP500
df.sp500 &amp;lt;- GetSP500Stocks()
tickers &amp;lt;- df.sp500$Tickers
  
future::plan(future::multisession, 
             workers = 10) # use 10 cores (future::availableCores())

# dowload data for 50 stocks  
l.out &amp;lt;- BatchGetSymbols(tickers = tickers[1:50], 
                         first.date = &amp;#39;2010-01-01&amp;#39;, 
                         last.date = &amp;#39;2019-01-01&amp;#39;,
                         do.parallel = TRUE, 
                         do.cache = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
 Progress: ─────────────────────────────────────────           100%
 Progress: ───────────────────────────────────────────────     100%
 Progress: ─────────────────────────────────────────────────   100%
 Progress: ─────────────────────────────────────────────────── 100%&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(l.out)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 2
##  $ df.control: tibble [50 × 6] (S3: tbl_df/tbl/data.frame)
##   ..$ ticker              : chr [1:50] &amp;quot;MMM&amp;quot; &amp;quot;ABT&amp;quot; &amp;quot;ABBV&amp;quot; &amp;quot;ABMD&amp;quot; ...
##   ..$ src                 : chr [1:50] &amp;quot;yahoo&amp;quot; &amp;quot;yahoo&amp;quot; &amp;quot;yahoo&amp;quot; &amp;quot;yahoo&amp;quot; ...
##   ..$ download.status     : chr [1:50] &amp;quot;OK&amp;quot; &amp;quot;OK&amp;quot; &amp;quot;OK&amp;quot; &amp;quot;OK&amp;quot; ...
##   ..$ total.obs           : int [1:50] 2264 2264 1510 2264 2264 2264 2264 2264 2264 2264 ...
##   ..$ perc.benchmark.dates: num [1:50] 1 1 0.667 1 1 ...
##   ..$ threshold.decision  : chr [1:50] &amp;quot;KEEP&amp;quot; &amp;quot;KEEP&amp;quot; &amp;quot;OUT&amp;quot; &amp;quot;KEEP&amp;quot; ...
##  $ df.tickers:&amp;#39;data.frame&amp;#39;:  106408 obs. of  10 variables:
##   ..$ price.open         : num [1:106408] 83.1 82.8 83.9 83.3 83.7 ...
##   ..$ price.high         : num [1:106408] 83.4 83.2 84.6 83.8 84.3 ...
##   ..$ price.low          : num [1:106408] 82.7 81.7 83.5 82.1 83.3 ...
##   ..$ price.close        : num [1:106408] 83 82.5 83.7 83.7 84.3 ...
##   ..$ volume             : num [1:106408] 3043700 2847000 5268500 4470100 3405800 ...
##   ..$ price.adjusted     : num [1:106408] 63.5 63.1 64 64.1 64.5 ...
##   ..$ ref.date           : Date[1:106408], format: &amp;quot;2010-01-04&amp;quot; &amp;quot;2010-01-05&amp;quot; ...
##   ..$ ticker             : chr [1:106408] &amp;quot;MMM&amp;quot; &amp;quot;MMM&amp;quot; &amp;quot;MMM&amp;quot; &amp;quot;MMM&amp;quot; ...
##   ..$ ret.adjusted.prices: num [1:106408] NA -0.006263 0.014182 0.000717 0.007047 ...
##   ..$ ret.closing.prices : num [1:106408] NA -0.006264 0.014182 0.000717 0.007046 ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>BatchGetSymbols 2.2</title>
      <link>https://www.msperlin.com/post/2018-10-10-batchgetsymbols-newversion/</link>
      <pubDate>Wed, 10 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2018-10-10-batchgetsymbols-newversion/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/blog/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;One of the main requests I get for package &lt;code&gt;BatchGetSymbols&lt;/code&gt; is to add the choice of frequency of the financial dataset. Today I finally got some time to work on it. I just posted a new version of BatchGetSymbols in CRAN. The major change is that users can now set the time frequency of the financial data: dailly, weekly, monthly or yearly. Let’s check it out:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(BatchGetSymbols)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: rvest&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: xml2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: dplyr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;dplyr&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:stats&amp;#39;:
## 
##     filter, lag&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:base&amp;#39;:
## 
##     intersect, setdiff, setequal, union&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(purrr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;purrr&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &amp;#39;package:rvest&amp;#39;:
## 
##     pluck&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

my.fct &amp;lt;- function(my.freq) {
  
  df &amp;lt;- BatchGetSymbols(tickers = c(&amp;#39;GE&amp;#39;), 
                      first.date = &amp;#39;2010-01-01&amp;#39;,
                      last.date = Sys.Date(), do.cache = FALSE,
                      freq.data = my.freq)$df.tickers
  
  df$freq &amp;lt;- my.freq

  return(df)
}

my.possible.freq &amp;lt;-  c(&amp;#39;daily&amp;#39;, &amp;#39;weekly&amp;#39;, &amp;#39;monthly&amp;#39;, &amp;#39;yearly&amp;#39;)

df.allfreq &amp;lt;- bind_rows(map(.x = my.possible.freq, .f = my.fct))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Running BatchGetSymbols for:&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##    tickers =GE
##    Downloading data for benchmark ticker
## ^GSPC | yahoo (1|1)
## GE | yahoo (1|1) - Got 100% of valid prices | Good job!
## Running BatchGetSymbols for:
##    tickers =GE
##    Downloading data for benchmark ticker
## ^GSPC | yahoo (1|1)
## GE | yahoo (1|1) - Got 100% of valid prices | You got it!
## Running BatchGetSymbols for:
##    tickers =GE
##    Downloading data for benchmark ticker
## ^GSPC | yahoo (1|1)
## GE | yahoo (1|1) - Got 100% of valid prices | Feels good!
## Running BatchGetSymbols for:
##    tickers =GE
##    Downloading data for benchmark ticker
## ^GSPC | yahoo (1|1)
## GE | yahoo (1|1) - Got 100% of valid prices | You got it!&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- ggplot(df.allfreq, aes(x=ref.date, y = price.adjusted)) + 
  geom_point() + geom_line() + facet_grid(freq ~ ticker)

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/blog/post/2018-10-10-BatchGetSymbols-NewVersion_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Investing for the Long Run</title>
      <link>https://www.msperlin.com/post/2018-05-12-investing-long-run/</link>
      <pubDate>Sat, 12 May 2018 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2018-05-12-investing-long-run/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/blog/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I often get asked about how to invest in the stock market. Not surprisingly, this has been a common topic in my classes. Brazil is experiencing a big change in its financial scenario. Historically, fixed income instruments paid a large premium over the stock market and that is no longer the case. Interest rates are low, without the pressure from inflation. This means a more sustainable scenario for low-interest rates in the future. Without the premium in the fixed income market, people turn to the stock market.&lt;/p&gt;
&lt;p&gt;We can separate investors according to their horizon. Traders try to profit in the short term, usually within a day, and long-term investors buy a stock without the intent to sell it in the near future. This type of investment strategy is called BH (&lt;em&gt;buy and hold&lt;/em&gt;). At the extreme, you buy a stock and hold it forever. The most famous spokesperson of BH is Warren Buffet, among many others.&lt;/p&gt;
&lt;p&gt;Investing in the long run works for me because it doesn’t require much of my time. You just need to keep up with the quarterly and yearly financial reports of companies. You can easily do it as a side activity, parallel to your main job. You don’t need a lot of brain power to do it either, but it does require knowledge of accounting practices to understand all printed material released by companies.&lt;/p&gt;
&lt;p&gt;I read many books before starting to invest and one of the most interesting tables I’ve found portrays the relationship between investment horizon and profitability. The idea is that the more time you hold a stock or index, higher the chance of a profit. The table, originally from Taleb’s &lt;em&gt;Fooled by Randomness&lt;/em&gt;, is as follows.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://imgur.com/a/d5VnMaF&#34; /&gt;&lt;/p&gt;
&lt;p&gt;My problem with the table is that it seems pretty off. My experience tells me that a 67% chance of positive return every month seems exaggerated. If that was the case, making money in the stock market would be easy. Digging deeper, I found out that the data behind the table is simulated and, therefore, doesn’t really give good an estimate about the improvement in the probability of profits as a function of the investment horizon.&lt;/p&gt;
&lt;p&gt;As you probably suspect, I decided to tackle the problem using real data and R. I wrote a simple &lt;a href=&#34;https://www.msperlin.com/content/others/fct_invest_horizon.R&#34;&gt;function&lt;/a&gt; that will grab data, simulate investments of different horizons many times and plot the results. Let’s try it for the SP500 index:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;source(&amp;#39;fct_invest_horizon.R&amp;#39;)

my.ticker &amp;lt;- &amp;#39;^GSPC&amp;#39; # ticker from yahoo finance
max.horizon = 255*50 # 50 years
first.date &amp;lt;- &amp;#39;1950-01-01&amp;#39; 
last.date &amp;lt;- Sys.Date()
n.points &amp;lt;- 50 # number of points in figure 
rf.year &amp;lt;- 0 # risk free return (or inflation)

l.out &amp;lt;- get.figs.invest.horizon(ticker.in = my.ticker, 
                                 first.date = first.date, 
                                 last.date = last.date,
                                 max.horizon = max.horizon, 
                                 n.points = n.points, 
                                 rf.year = rf.year)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `data_frame()` is deprecated as of tibble 1.1.0.
## Please use `tibble()` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(l.out$p1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/blog/post/2018-05-12-Investing-Long-Run_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(l.out$p2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/blog/post/2018-05-12-Investing-Long-Run_files/figure-html/unnamed-chunk-3-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As the investment horizon increases, the chances of a positive return increases. This result suggests that, if you invest for more than 13 years, it is very unlikely that you’ll see a negative return. When looking at the distribution of total returns by the horizon, we find that it increases significantly with time. Someone that invested for 50 years is likely to receive a 2500% return on the investment.&lt;/p&gt;
&lt;p&gt;With input input &lt;code&gt;rf.year&lt;/code&gt; we can also set a desired rate of return. Let’s try it with 5% return per year, with is pretty standard for financial markets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my.ticker &amp;lt;- &amp;#39;^GSPC&amp;#39; # ticker from yahoo finance
max.horizon = 255*50 # 50 years
first.date &amp;lt;- &amp;#39;1950-01-01&amp;#39; 
last.date &amp;lt;- Sys.Date()
n.points &amp;lt;- 50 # number of points in figure 
rf.year &amp;lt;- 0.05 # risk free return (or inflation) - yearly

l.out &amp;lt;- get.figs.invest.horizon(ticker.in = my.ticker, 
                                 first.date = first.date, 
                                 last.date = last.date,
                                 max.horizon = max.horizon, 
                                 n.points = n.points, 
                                 rf.year = rf.year)

print(l.out$p1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/blog/post/2018-05-12-Investing-Long-Run_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As expected, the curve of probabilities has a lower slope, meaning that you need more time investing in the SP500 index to guarantee a return of more than 5% a year.&lt;/p&gt;
&lt;p&gt;Now, let’s try the same setup for Berkshire stock (BRK-A). This is Buffet’s company and looking at its share price we can have a good understanding of how successful Buffet has been as a BH (&lt;em&gt;buy and hold&lt;/em&gt;) investor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my.ticker &amp;lt;- &amp;#39;BRK-A&amp;#39; # ticker from yahoo finance
max.horizon = 255*25 # 50 years
first.date &amp;lt;- &amp;#39;1980-01-01&amp;#39; 
last.date &amp;lt;- Sys.Date()
n.points &amp;lt;- 50 # number of points in figure 
rf.year &amp;lt;- 0.05 # risk free return (or inflation) - yearly

l.out &amp;lt;- get.figs.invest.horizon(ticker.in = my.ticker, 
                                 first.date = first.date, 
                                 last.date = last.date,
                                 max.horizon = max.horizon, 
                                 n.points = n.points, 
                                 rf.year = rf.year)

print(l.out$p1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/blog/post/2018-05-12-Investing-Long-Run_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(l.out$p2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/blog/post/2018-05-12-Investing-Long-Run_files/figure-html/unnamed-chunk-5-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Well, needless to say that, historically, Buffet has done very well in his investments! If you bought the stock and kept it for more 1 year, there is a 70% chance that you got a profit.&lt;/p&gt;
&lt;p&gt;I hope this post convinced you to start investing. The results are clear, its better to start as early as possible.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Major update to BatchGetSymbols</title>
      <link>https://www.msperlin.com/post/2018-01-22-update-batchgetsymbols/</link>
      <pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2018-01-22-update-batchgetsymbols/</guid>
      <description>
&lt;script src=&#34;https://www.msperlin.com/blog/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I just released a long due update to package &lt;code&gt;BatchGetSymbols&lt;/code&gt;. The files are under review in CRAN and you should get the update soon. Meanwhile, you can install the new version from Github:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if (!require(devtools)) install.packages(&amp;#39;devtools&amp;#39;)
devtools::install_github(&amp;#39;msperlin/BatchGetSymbols&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The main innovations are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Clever cache system&lt;/strong&gt;: By default, every new download of data will be saved in a local file located in a directory chosen by user. Every new request of data is compared to the available local information. If data is missing, the function only downloads the piece of data that is missing. This make the call to function &lt;code&gt;BatchGetSymbols&lt;/code&gt; a lot faster! When updating an existing dataset of prices, the function only downloads the missing part of the data.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Returns calculation&lt;/strong&gt;: Function now returns a return vector in &lt;code&gt;df.tickers&lt;/code&gt;. Returns are used a lot more than prices in research. No reason why they should be keep out of the output.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Wide format&lt;/strong&gt;: Added function for converting data to the wide format. In some situations, such as portfolio analysis, the wide format makes a lot of sense and is required for some methodologies.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Ibovespa composition&lt;/strong&gt;: Added function for downloading current Ibovespa composition directly from Bovespa website.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the next chunks of code I show some of the innovations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(BatchGetSymbols)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: rvest&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: xml2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: dplyr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;dplyr&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:stats&amp;#39;:
## 
##     filter, lag&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:base&amp;#39;:
## 
##     intersect, setdiff, setequal, union&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# download Ibovespa stocks
my.tickers &amp;lt;- GetSP500Stocks()$Tickers[1:5] # lets keep it light

# set dates
first.date &amp;lt;- &amp;#39;2017-01-01&amp;#39;
last.date &amp;lt;- &amp;#39;2019-01-01&amp;#39;

# set folder for cache system
my.temp.cache.folder &amp;lt;- &amp;#39;BGS_CACHE&amp;#39;

# get data and time it
time.nocache &amp;lt;- system.time({
my.l &amp;lt;- BatchGetSymbols(tickers = my.tickers, first.date, last.date, 
                        cache.folder = my.temp.cache.folder, do.cache = FALSE)
})&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Running BatchGetSymbols for:&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##    tickers =MMM, ABT, ABBV, ABMD, ACN
##    Downloading data for benchmark ticker
## ^GSPC | yahoo (1|1)
## MMM | yahoo (1|5) - Got 100% of valid prices | Well done!
## ABT | yahoo (2|5) - Got 100% of valid prices | Good job!
## ABBV | yahoo (3|5) - Got 100% of valid prices | Youre doing good!
## ABMD | yahoo (4|5) - Got 100% of valid prices | Youre doing good!
## ACN | yahoo (5|5) - Got 100% of valid prices | You got it!&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;time.withcache &amp;lt;- system.time({
my.l &amp;lt;- BatchGetSymbols(tickers = my.tickers, first.date, last.date, 
                        cache.folder = my.temp.cache.folder, do.cache = TRUE)
})&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Running BatchGetSymbols for:
##    tickers =MMM, ABT, ABBV, ABMD, ACN
##    Downloading data for benchmark ticker
## ^GSPC | yahoo (1|1) | Not Cached | Saving cache
## MMM | yahoo (1|5) | Not Cached | Saving cache - Got 100% of valid prices | Looking good!
## ABT | yahoo (2|5) | Not Cached | Saving cache - Got 100% of valid prices | Good stuff!
## ABBV | yahoo (3|5) | Not Cached | Saving cache - Got 100% of valid prices | Got it!
## ABMD | yahoo (4|5) | Not Cached | Saving cache - Got 100% of valid prices | Looking good!
## ACN | yahoo (5|5) | Not Cached | Saving cache - Got 100% of valid prices | Good stuff!&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cat(&amp;#39;\nTime with no cache:&amp;#39;, time.nocache[&amp;#39;elapsed&amp;#39;])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Time with no cache: 4.094&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cat(&amp;#39;\nTime with cache:&amp;#39;, time.withcache[&amp;#39;elapsed&amp;#39;])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Time with cache: 2.386&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s check the default output with data in the long format:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dplyr::glimpse(my.l)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 2
##  $ df.control: tibble [5 × 6] (S3: tbl_df/tbl/data.frame)
##   ..$ ticker              : chr [1:5] &amp;quot;MMM&amp;quot; &amp;quot;ABT&amp;quot; &amp;quot;ABBV&amp;quot; &amp;quot;ABMD&amp;quot; ...
##   ..$ src                 : chr [1:5] &amp;quot;yahoo&amp;quot; &amp;quot;yahoo&amp;quot; &amp;quot;yahoo&amp;quot; &amp;quot;yahoo&amp;quot; ...
##   ..$ download.status     : chr [1:5] &amp;quot;OK&amp;quot; &amp;quot;OK&amp;quot; &amp;quot;OK&amp;quot; &amp;quot;OK&amp;quot; ...
##   ..$ total.obs           : int [1:5] 502 502 502 502 502
##   ..$ perc.benchmark.dates: num [1:5] 1 1 1 1 1
##   ..$ threshold.decision  : chr [1:5] &amp;quot;KEEP&amp;quot; &amp;quot;KEEP&amp;quot; &amp;quot;KEEP&amp;quot; &amp;quot;KEEP&amp;quot; ...
##  $ df.tickers:&amp;#39;data.frame&amp;#39;:  2510 obs. of  10 variables:
##   ..$ price.open         : num [1:2510] 179 178 178 177 178 ...
##   ..$ price.high         : num [1:2510] 180 179 179 179 178 ...
##   ..$ price.low          : num [1:2510] 177 178 177 176 177 ...
##   ..$ price.close        : num [1:2510] 178 178 178 178 177 ...
##   ..$ volume             : num [1:2510] 2509300 1542000 1447800 1625000 1622600 ...
##   ..$ price.adjusted     : num [1:2510] 162 163 162 163 162 ...
##   ..$ ref.date           : Date[1:2510], format: &amp;quot;2017-01-03&amp;quot; &amp;quot;2017-01-04&amp;quot; ...
##   ..$ ticker             : chr [1:2510] &amp;quot;MMM&amp;quot; &amp;quot;MMM&amp;quot; &amp;quot;MMM&amp;quot; &amp;quot;MMM&amp;quot; ...
##   ..$ ret.adjusted.prices: num [1:2510] NA 0.00152 -0.00342 0.00293 -0.00539 ...
##   ..$ ret.closing.prices : num [1:2510] NA 0.00152 -0.00342 0.00293 -0.00539 ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And change the format of the long dataframe to wide:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;l.wide &amp;lt;- reshape.wide(my.l$df.tickers) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we check the matrix of prices:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(head(l.wide$price.adjusted))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     ref.date     ABBV   ABMD      ABT      ACN      MMM
## 1 2017-01-03 52.55166 112.36 36.55642 109.8161 162.4736
## 2 2017-01-04 53.29267 115.74 36.84662 110.0802 162.7200
## 3 2017-01-05 53.69685 114.81 37.16491 108.4300 162.1634
## 4 2017-01-06 53.71369 115.42 38.17595 109.6653 162.6379
## 5 2017-01-09 54.06735 117.11 38.13851 108.4394 161.7619
## 6 2017-01-10 53.94946 112.24 38.65339 108.4960 161.1322&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and matrix of returns:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(head(l.wide$ret.adjusted.prices))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     ref.date          ABBV         ABMD           ABT           ACN
## 1 2017-01-03            NA           NA            NA            NA
## 2 2017-01-04  0.0141005055  0.030081853  0.0079383861  0.0024043005
## 3 2017-01-05  0.0075841391 -0.008035252  0.0086381596 -0.0149906200
## 4 2017-01-06  0.0003136497  0.005313126  0.0272041565  0.0113923084
## 5 2017-01-09  0.0065841132  0.014642203 -0.0009806436 -0.0111779967
## 6 2017-01-10 -0.0021804289 -0.041584860  0.0135001858  0.0005216922
##            MMM
## 1           NA
## 2  0.001516547
## 3 -0.003420851
## 4  0.002926172
## 5 -0.005386333
## 6 -0.003892474&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Can we predict stock prices with Prophet?</title>
      <link>https://www.msperlin.com/post/2017-03-05-prophet-and_stock-market/</link>
      <pubDate>Sun, 05 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://www.msperlin.com/post/2017-03-05-prophet-and_stock-market/</guid>
      <description>


&lt;p&gt;Facebook recently released a API package allowing access to its forecasting model called &lt;a href=&#34;http://blog.revolutionanalytics.com/2017/02/facebook-prophet.html&#34;&gt;prophet&lt;/a&gt;. According to the underling post:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;It&amp;#39;s not your traditional ARIMA-style time series model. It&amp;#39;s closer in spirit to a  Bayesian-influenced generalized additive model, a regression of smooth terms. The model is resistant   to the effects of outliers, and supports data collected over an irregular time scale (ingliding presence of missing data) without the need for interpolation. The underlying calculation engine is Stan; the R and Python packages simply provide a convenient interface.  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After reading it, I got really curious about the predictive performance of this method for stock prices. That is, &lt;strong&gt;can we predict stock price movements based on prophet?&lt;/strong&gt; In this post I will investigate this research question using a database of prices for the SP500 components.&lt;/p&gt;
&lt;p&gt;Before describing the code and results, it is noteworthy to point out that forecasting stock returns is really hard! There is a significant body of literature trying to forecast prices and to prove (or not) that financial markets are efficient in pricing publicly available information, including historical prices. This is the so called efficient market hypothesis. I have studied it, tried to trade for myself for a while when I was a Msc student, advised several graduate students on it, and the results are mostly the same: it is very difficult to find a trade signal that works well and is sustainable in real life.&lt;/p&gt;
&lt;p&gt;This means that most of the variation in prices is due to random factors that cannot be anticipated. The explanation is simple, prices move according to investor’s expectation from available information. Every time that new (random) information, true or not, reaches the market, investor’s update their beliefs and trade accordingly. So, unless, new information or market expectation have a particular pattern, price changes will be mostly random.&lt;/p&gt;
&lt;p&gt;Even with a body of evidence against our research, it is still interesting to see how we could apply &lt;code&gt;prophet&lt;/code&gt; in a trading setup.&lt;/p&gt;
&lt;div id=&#34;the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The data&lt;/h2&gt;
&lt;p&gt;First, let’s download stock prices for some components of the SP500 index since 2010.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(BatchGetSymbols)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: rvest&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: xml2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: dplyr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;dplyr&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:stats&amp;#39;:
## 
##     filter, lag&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:base&amp;#39;:
## 
##     intersect, setdiff, setequal, union&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(100)

all.stocks &amp;lt;- GetSP500Stocks()$Ticker
my.stocks &amp;lt;- sample(all.stocks, 20)

first.date &amp;lt;- as.Date(&amp;#39;2015-01-01&amp;#39;)
last.date &amp;lt;- as.Date(&amp;#39;2019-01-01&amp;#39;)
df.stocks &amp;lt;- BatchGetSymbols(my.stocks, 
                             first.date = first.date, 
                             last.date = last.date)[[2]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Running BatchGetSymbols for:&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##    tickers =FTV, ZBH, OXY, C, XLNX, VZ, BEN, WY, ROL, VTR, TSN, ABMD, MKC, MDLZ, CNP, PVH, ADBE, EXPD, L, UNM
##    Downloading data for benchmark ticker
## ^GSPC | yahoo (1|1) | Found cache file
## FTV | yahoo (1|20) | Found cache file - Got 62% of valid prices | OUT: not enough data (thresh.bad.data = 75%)
## ZBH | yahoo (2|20) | Found cache file - Got 100% of valid prices | OK!
## OXY | yahoo (3|20) | Found cache file - Got 100% of valid prices | Got it!
## C | yahoo (4|20) | Found cache file - Got 100% of valid prices | You got it!
## XLNX | yahoo (5|20) | Found cache file - Got 100% of valid prices | OK!
## VZ | yahoo (6|20) | Found cache file - Got 100% of valid prices | Got it!
## BEN | yahoo (7|20) | Found cache file - Got 100% of valid prices | Feels good!
## WY | yahoo (8|20) | Found cache file - Got 100% of valid prices | Looking good!
## ROL | yahoo (9|20) | Found cache file - Got 100% of valid prices | Got it!
## VTR | yahoo (10|20) | Found cache file - Got 100% of valid prices | OK!
## TSN | yahoo (11|20) | Found cache file - Got 100% of valid prices | Feels good!
## ABMD | yahoo (12|20) | Found cache file - Got 100% of valid prices | Feels good!
## MKC | yahoo (13|20) | Found cache file - Got 100% of valid prices | Got it!
## MDLZ | yahoo (14|20) | Found cache file - Got 100% of valid prices | Feels good!
## CNP | yahoo (15|20) | Found cache file - Got 100% of valid prices | Got it!
## PVH | yahoo (16|20) | Found cache file - Got 100% of valid prices | Looking good!
## ADBE | yahoo (17|20) | Found cache file - Got 100% of valid prices | OK!
## EXPD | yahoo (18|20) | Found cache file - Got 100% of valid prices | You got it!
## L | yahoo (19|20) | Found cache file - Got 100% of valid prices | Good job!
## UNM | yahoo (20|20) | Found cache file - Got 100% of valid prices | Looking good!&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s understand how prophet works. I was happy to see that the interface is quite simple, you offer a time series with input &lt;code&gt;y&lt;/code&gt; and a date vector with &lt;code&gt;ds&lt;/code&gt;. If no further custom option is set, you are good to go. My only complain with &lt;code&gt;prophet&lt;/code&gt; is that that the function outputs lots of messages. They really should add a &lt;code&gt;quiet&lt;/code&gt; option, so that the user doesn’t have to use &lt;code&gt;capture.output&lt;/code&gt; to silent it. Have a look in the next example with a dummy series:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(prophet)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: Rcpp&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: rlang&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;rlang&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &amp;#39;package:xml2&amp;#39;:
## 
##     as_list&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df.est &amp;lt;- data.frame(y = rnorm(100), ds = Sys.Date() + 1:100)

m &amp;lt;- prophet(df = df.est)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Disabling yearly seasonality. Run prophet with yearly.seasonality=TRUE to override this.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The next step is to think about how to structure a function for our research problem. Our study has two steps, first we will set a &lt;em&gt;training&lt;/em&gt; (in-sample) period, estimate the model and make forecasts. After that, we use the &lt;em&gt;out-of-sample&lt;/em&gt; data to test the accuracy of the model.&lt;/p&gt;
&lt;p&gt;The whole procedure of estimating and forecasting will be encapsulated in a single R function. This is not the best way of doing it but, for our simple example, it will suffice. My function will take as input a dataframe and the number of out-of-sample forecasts. Based on the adjusted closing prices, we calculate returns and feed &lt;code&gt;1:(nrow(df)-nfor)&lt;/code&gt; rows for the estimation. The last &lt;code&gt;nfor&lt;/code&gt; rows are used for testing the accuracy of the model. For example, if I have a vector with 1000 returns and &lt;code&gt;nfor=5&lt;/code&gt;, I use observations from &lt;code&gt;1:995&lt;/code&gt; for estimating the model and &lt;code&gt;996:1000&lt;/code&gt; for testing the forecasts. The function returns a dataframe with the predictions for each horizon, its error, among other things. Here’s the function definition:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;est.model.and.forecast &amp;lt;- function(df.in, nfor=5){
  # Estimated model using prophet and forecast it
  #
  # Args:
  #   df.in - A dataframe with columns price.adjusted and ref.date
  #   nfor - Number of out-of-sample forecasts
  #
  # Returns:
  #   A dataframe with forecasts and errors for each horizon.
  
  require(prophet)
  require(dplyr)
  
  my.ticker &amp;lt;- df.in$ticker[1]
  
  #cat(&amp;#39;\nProcessing &amp;#39;, my.ticker)
  
  df.in &amp;lt;- df.in %&amp;gt;%
    select(ref.date, ret.adjusted.prices)
  
  names(df.in) &amp;lt;- c(&amp;#39;ds&amp;#39;, &amp;#39;y&amp;#39;)
  
  idx &amp;lt;- nrow(df.in) - nfor
  
  df.est &amp;lt;- df.in[1:idx, ]
  df.for &amp;lt;- df.in[(idx + 1):nrow(df.in), ]
  
  capture.output(
    m &amp;lt;- prophet(df = df.est)
  )
  
  # forecast 50 days ahead (it also includes non trading days)
  df.pred &amp;lt;- predict(m,
                     make_future_dataframe(m,
                                           periods = nfor + 50))
  
  df.pred$ds &amp;lt;- as.Date(df.pred$ds)
  df.for &amp;lt;- merge(df.for, df.pred, by = &amp;#39;ds&amp;#39;)
  df.for &amp;lt;- select(df.for, ds, y, yhat)
  
  # forecast statistics
  df.for$eps &amp;lt;- with(df.for,y - yhat)
  df.for$abs.eps &amp;lt;- with(df.for,abs(y - yhat))
  df.for$perc.eps &amp;lt;- with(df.for,(y - yhat)/y)
  df.for$nfor &amp;lt;- 1:nrow(df.for)
  df.for$ticker &amp;lt;- my.ticker
  
  return(df.for)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s try it out using the &lt;code&gt;by&lt;/code&gt; function to apply it for each stock in our sample. All results are later combined in a single dataframe with function &lt;code&gt;do.call&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;out.l &amp;lt;- by(data = df.stocks,
            INDICES = df.stocks$ticker, 
            FUN = est.model.and.forecast, nfor = 5)

my.result &amp;lt;- do.call(rbind, out.l)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Lets have a look in the resulting dataframe:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(my.result)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                ds            y         yhat         eps    abs.eps  perc.eps
## ABMD.1 2018-12-24 -0.031726969 -0.005299687 -0.02642728 0.02642728 0.8329596
## ABMD.2 2018-12-26  0.093781188 -0.002497698  0.09627889 0.09627889 1.0266333
## ABMD.3 2018-12-27  0.026769487 -0.005186820  0.03195631 0.03195631 1.1937587
## ABMD.4 2018-12-28  0.007919663 -0.001131558  0.00905122 0.00905122 1.1428795
## ABMD.5 2018-12-31  0.021592217 -0.003278144  0.02487036 0.02487036 1.1518206
## ADBE.1 2018-12-24 -0.017432945 -0.005505203 -0.01192774 0.01192774 0.6842070
##        nfor ticker
## ABMD.1    1   ABMD
## ABMD.2    2   ABMD
## ABMD.3    3   ABMD
## ABMD.4    4   ABMD
## ABMD.5    5   ABMD
## ADBE.1    1   ADBE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this object you’ll find the forecasts (yhat), the actual values (y), the absolute and normalized error (abs.eps, perc.eps).&lt;/p&gt;
&lt;p&gt;For ou first analysis, let’s have a look on the effect of the forecasting horizon over the absolute error distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

p &amp;lt;- ggplot(my.result, aes(x=factor(nfor), 
                           y=abs.eps))
p &amp;lt;- p + geom_boxplot()

print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/blog/post/2017-03-05-Prophet-and_stock-market_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We do find some positive dependency. As the horizon increases, the forecasting algorithm makes more mistakes. Surprisingly, this pattern is not found for &lt;code&gt;nfor=5&lt;/code&gt; and &lt;code&gt;nfor=4&lt;/code&gt;. It might be interesting to add more data and check if this effect is robust.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;encopassing-test&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Encopassing test&lt;/h2&gt;
&lt;p&gt;A simple and powerful test for verifying the accuracy of a prediction algorithm is the encompassing test. The idea is to estimate the following linear model with the real returns (&lt;span class=&#34;math inline&#34;&gt;\(R_t\)&lt;/span&gt;) and its predictions (&lt;span class=&#34;math inline&#34;&gt;\(\hat{R} _t\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_t = \alpha + \beta\hat{y_t} + \epsilon _t\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;If the model provides good forecasts, we can expect that &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; is equal to zero (no bias) and &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; is equal to 1. If both conditions are true, we have that &lt;span class=&#34;math inline&#34;&gt;\(R_t = \hat{R} _t + \epsilon _t\)&lt;/span&gt;$, meaning that our forecasting model provides an unbiased estimator of the predicted variable. In a formal research, we could use a Wald test to verify this hypothesis jointly.&lt;/p&gt;
&lt;p&gt;First, lets find the result of the encompassing test for all forecasts.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm.model &amp;lt;- lm(formula = y ~yhat, data = my.result)
summary(lm.model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = y ~ yhat, data = my.result)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.055237 -0.012307 -0.000287  0.008360  0.086257 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)  
## (Intercept) 0.007954   0.004063   1.957   0.0533 .
## yhat        0.171995   1.132177   0.152   0.8796  
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.02675 on 93 degrees of freedom
## Multiple R-squared:  0.0002481,  Adjusted R-squared:  -0.0105 
## F-statistic: 0.02308 on 1 and 93 DF,  p-value: 0.8796&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, it didn’t work very well. The constant is significant, which indicates a bias. The value of 0.1719945 is not very close to 1. But, it could be the case that the different horizon have different results. A longer horizon, with bad forecasts, will be affecting short horizons with good forecasts. Lets use &lt;code&gt;dplyr&lt;/code&gt; to separate our model according to &lt;code&gt;nfor&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;models &amp;lt;- my.result %&amp;gt;%
  group_by(nfor) %&amp;gt;%
  do(ols.model = lm(data = ., formula = y ~ yhat ))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We report the results with &lt;code&gt;texreg::screenreg&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;texreg::screenreg(models$ols.model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ==============================================================
##              Model 1    Model 2    Model 3  Model 4  Model 5  
## --------------------------------------------------------------
## (Intercept)  -0.04 ***   0.05 ***   0.01    -0.00     0.01 ***
##              (0.00)     (0.01)     (0.00)   (0.00)   (0.00)   
## yhat         -2.32 **   -0.14      -1.01    -0.19    -0.22    
##              (0.77)     (2.82)     (0.87)   (0.51)   (0.72)   
## --------------------------------------------------------------
## R^2           0.35       0.00       0.07     0.01     0.01    
## Adj. R^2      0.31      -0.06       0.02    -0.05    -0.05    
## Num. obs.    19         19         19       19       19       
## RMSE          0.01       0.02       0.01     0.01     0.01    
## ==============================================================
## *** p &amp;lt; 0.001, ** p &amp;lt; 0.01, * p &amp;lt; 0.05&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Well, the R2 shows some evidence that shorter horizons have better results in the encompassing test. But, we got some negative betas! This means that, for some horizons, it might be better to take the opposite suggestion of the forecast!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;trading-based-on-forecasts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Trading based on forecasts&lt;/h2&gt;
&lt;p&gt;In a practical trading applications, it might not be of interest to forecast actual returns. If you are trading according to these forecasts, you are probably more worried about the direction of the forecasts and not its nominal error. A model can have bad nominal forecasts, but be good in predicting the sign of the next price movement. If this is the case, you can still make money even though your model fails in the encompassing test.&lt;/p&gt;
&lt;p&gt;Let’s try it out with a simple trading strategy for all different horizons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;buy in end of day &lt;em&gt;t&lt;/em&gt; if forecast in &lt;em&gt;t+1&lt;/em&gt; is positive and sell at the end of &lt;em&gt;t+1&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;short-sell in the end of day &lt;em&gt;t&lt;/em&gt; when forecast for &lt;em&gt;t+1&lt;/em&gt; is negative and buy it back in the end of &lt;em&gt;t+1&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The total profit will be given by:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my.profit &amp;lt;- sum(with(my.result, (yhat&amp;gt;0)*y + (yhat&amp;lt;0)*-y))
print(my.profit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.7584576&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Not bad! Doesn’t look like much, but remember that we have a few trading days and this return might be due to a sistematic effect in the market. Let’s see how this result compares to random trading signals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n.sim &amp;lt;- 10000

monkey.ret &amp;lt;- numeric(length = n.sim)
for (i in seq(n.sim)) {
  rnd.vec &amp;lt;- rnorm(length(my.result$y))
  
  monkey.ret[i] &amp;lt;- sum( (rnd.vec&amp;gt;0)*my.result$y + (rnd.vec&amp;lt;0)*-my.result$y )
  
} 

temp.df &amp;lt;- data.frame(monkey.ret, my.profit)
p &amp;lt;- ggplot(temp.df, aes(monkey.ret)) 
p &amp;lt;- p + geom_histogram()
p &amp;lt;- p + geom_vline(aes(xintercept =  my.profit),size=2)
p &amp;lt;- p + labs(x=&amp;#39;Returns from random trading signals&amp;#39;)
print(p)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.msperlin.com/blog/post/2017-03-05-Prophet-and_stock-market_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The previous histogram shows the total return from randomnly generated signals in 10^{4} simulations. The vertical line is the result from using &lt;code&gt;prophet&lt;/code&gt;. As you can see, it is a bit higher than the average of the distribution. The total return from &lt;code&gt;prophet&lt;/code&gt; is lower than the return of the naive strategy in 99.72 percent of the simulations. This is not a bad result. But, notice that we didnt add trading or liquidity costs to the analysis, which will make the total returns worse.&lt;/p&gt;
&lt;p&gt;The main results of this simple study are clear: &lt;strong&gt;&lt;code&gt;prophet&lt;/code&gt; is bad at point forecasts for returns, specially for longer horizons, but does quite better in directional predictions&lt;/strong&gt;. It might be interesting to test it further, with more data, adding trading costs, other forecasting setups, and see if the results hold.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
